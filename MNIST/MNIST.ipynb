{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-1xNKXx6TBQp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rRSXyp6THwR",
        "outputId": "edd158a8-0f57-48d7-be07-55ffef562fac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1c33d3b56f0>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_epochs = 8\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "log_interval = 10\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hDDVrKZmVTbS"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_HKx24x7V_4d"
      },
      "outputs": [],
      "source": [
        "#Building the Network\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = torch.tanh(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "taugfbRTWCo-"
      },
      "outputs": [],
      "source": [
        "network = Net()\n",
        "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
        "loss_f=nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the initial weights to measure later their contribution:\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XKYJb4e7WLNG"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y2MhJ3U3WNTW"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "  network.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output = network(data)\n",
        "    loss = loss_f(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        100. * batch_idx / len(train_loader), loss.item()))\n",
        "      train_losses.append(loss.item())\n",
        "      train_counter.append(\n",
        "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r9W0MBhnWPfg"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "  network.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      output = network(data)\n",
        "      test_loss += loss_f(output,target)\n",
        "        \n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= 10 #10 is the amount of test batches\n",
        "  test_losses.append(test_loss)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "BJo6gYxIWSUC",
        "outputId": "9cd112a3-872f-4d2c-c351-b99e8929a6dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3235, Accuracy: 1078/10000 (11%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.363499\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.336838\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.316885\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.218455\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.250370\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.156506\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.172863\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.127754\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.060148\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.994088\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.927737\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.894865\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.889777\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.793910\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.840935\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.726499\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.642938\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.558005\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.638720\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.529726\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.506492\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.401595\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.293669\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.326661\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.245325\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.314261\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.118168\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.261299\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.275408\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 1.260875\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.220363\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 1.191774\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.163188\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.929438\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.107278\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 1.021673\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.940492\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.924671\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.907587\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.878436\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.837975\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.881099\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.963611\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.748538\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.909228\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.771669\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.741191\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.680635\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.688741\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.762408\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.856383\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.734438\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.774801\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.686214\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.825851\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.819527\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.643549\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.552637\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.607346\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.637908\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.763162\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.711450\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.650788\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.564143\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.628079\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.748718\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.614943\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.651056\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.641986\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.648364\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.540054\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.598541\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.591671\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.548572\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.776622\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.721617\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.552154\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.560589\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.532908\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.528886\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.747017\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.634058\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.520744\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.523875\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.550281\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.448715\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.611415\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.411465\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.667540\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.607017\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.368775\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.399225\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.621205\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.498920\n",
            "\n",
            "Test set: Avg. loss: 0.3096, Accuracy: 9154/10000 (92%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.646917\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.405618\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.336086\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.448633\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.387375\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.629533\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.421848\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.589694\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.484210\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.458117\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.522112\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.549374\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.469922\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.550385\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.487983\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.632175\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.575158\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.494307\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.340406\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.487090\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.462607\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.522901\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.547962\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.481986\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.444250\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.432699\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.485333\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.454608\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.362949\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.435560\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.406499\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.411684\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.433076\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.391470\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.596254\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.288055\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.369596\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.541601\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.500946\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.323130\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.421382\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.419678\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.332820\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.297437\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.339759\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.339824\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.379375\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.400515\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.400098\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.340437\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.423837\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.489696\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.360134\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.272814\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.482036\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.328095\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.276416\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.321831\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.376352\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.471284\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.359851\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.377042\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.353164\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.437280\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.364529\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.227294\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.301434\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.374747\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.287358\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.372482\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.302750\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.222862\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.219857\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.354510\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.283438\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.435695\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.402450\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.368867\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.323973\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.305502\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.190126\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.301606\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.309330\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.300374\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.372464\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.352059\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.358129\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.276438\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.248826\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.295128\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.414075\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.305835\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.242525\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.410224\n",
            "\n",
            "Test set: Avg. loss: 0.1798, Accuracy: 9454/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.222608\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.248725\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.304618\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.192299\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.269797\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.315529\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.281760\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.353098\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.254120\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.252638\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.326731\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.390628\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.154020\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.242280\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.125071\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.197879\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.304553\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.400774\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.318585\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.216023\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.223387\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.165704\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.425925\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.204490\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.243855\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.275898\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.235870\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.407219\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.267064\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.537600\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.259582\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.183842\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.292913\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.383555\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.324730\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.247792\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.512457\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.357018\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.375680\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.354576\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.194172\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.286128\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.211489\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.195998\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.298799\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.282271\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.353576\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.447838\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.211043\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.226930\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.324517\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.467907\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.278993\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.480006\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.436277\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.224160\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.238552\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.150155\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.156020\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.327698\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.188959\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.221107\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.327813\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.185512\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.219591\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.332370\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.318486\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.255695\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.351931\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.218023\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.258199\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.280188\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.241291\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.322960\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.305339\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.241343\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.266593\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.202249\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.250469\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.240155\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.217708\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.427012\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.168860\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.262751\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.194132\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.110197\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.291257\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.444403\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.413520\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.370449\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.223453\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.192750\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.274073\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.172299\n",
            "\n",
            "Test set: Avg. loss: 0.1318, Accuracy: 9571/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.400794\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.199818\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.176956\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.300612\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.183999\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.226615\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.218751\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.231402\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.281725\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.306601\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.157642\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.374839\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.123280\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.144664\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.198943\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.197949\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.153466\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.484294\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.342511\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.152644\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.246025\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.233534\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.293914\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.279717\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.177252\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.306556\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.301602\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.167496\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.333372\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.175230\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.310214\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.149743\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.240538\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.183511\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.237555\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.226332\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.269053\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.372631\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.237741\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.225279\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.358308\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.245766\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.159417\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.133787\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.145177\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.188966\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.184121\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.176098\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.165808\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.315024\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.157695\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.292907\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.227581\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.242522\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.352125\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.150890\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.139828\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.169853\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.261281\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.167205\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.215828\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.147446\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.187371\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.433289\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.127581\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.294611\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.298807\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.313361\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.273554\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.152431\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.197265\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.181465\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.206670\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.186491\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.208961\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.304180\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.273219\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.228356\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.214724\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.137525\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.278223\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.327951\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.219410\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.169532\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.061543\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.196849\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.174829\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.316313\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.111704\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.314767\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.109753\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.210297\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.225729\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.301335\n",
            "\n",
            "Test set: Avg. loss: 0.1084, Accuracy: 9656/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.274373\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.095850\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.163570\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.184391\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.135697\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.168953\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.166268\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.098844\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.143124\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.069485\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.207949\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.371676\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.204340\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.143213\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.142115\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.100216\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.267920\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.235787\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.189610\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.298401\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.228730\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.223544\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.215784\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.102952\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.165565\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.196182\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.118240\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.240821\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.193519\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.145769\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.128862\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.115917\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.227884\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.157466\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.167246\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.104703\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.172465\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.194249\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.238059\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.208533\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.158752\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.224673\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.194393\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.187085\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.161839\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.186708\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.266976\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.137318\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.172592\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.105054\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.115482\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.275592\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.199219\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.160243\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.268057\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.334636\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.087592\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.248334\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.391354\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.201233\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.175642\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.331913\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.232991\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.181243\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.255845\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.217573\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.146548\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.181139\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.124011\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.120043\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.248060\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.217519\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.241930\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.171499\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.121193\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.259022\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.152647\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.449481\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.164734\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.349173\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.145057\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.205807\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.280252\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.133334\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.283690\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.110546\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.166989\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.125808\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.069278\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.112178\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.714047\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.348652\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.196547\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.128832\n",
            "\n",
            "Test set: Avg. loss: 0.0974, Accuracy: 9699/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.295163\n",
            "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.279494\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.075816\n",
            "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.236113\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.178469\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.136573\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.143850\n",
            "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.174626\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.081395\n",
            "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.140998\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.283044\n",
            "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.159669\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.142842\n",
            "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.143315\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.262614\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.191811\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.217609\n",
            "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.129154\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.277154\n",
            "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.229298\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.285733\n",
            "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.122423\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.156831\n",
            "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.154122\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.118893\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.140799\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.125582\n",
            "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.155077\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.242691\n",
            "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.099087\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.230857\n",
            "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.065922\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.103582\n",
            "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.196242\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.316643\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.212580\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.188256\n",
            "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.219513\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.093307\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.179538\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.125373\n",
            "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.260306\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.133578\n",
            "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.203719\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.207052\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.218191\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.162783\n",
            "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.204621\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.100470\n",
            "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.234411\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.058310\n",
            "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.166243\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.198023\n",
            "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.234108\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.155592\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.207819\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.325327\n",
            "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.143417\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.261487\n",
            "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.319845\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.084977\n",
            "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.326257\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.126420\n",
            "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.193745\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.141294\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.132572\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.210409\n",
            "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.124466\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.080802\n",
            "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.421005\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.219887\n",
            "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.172088\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.107561\n",
            "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.083324\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.088339\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.094813\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.101120\n",
            "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.083916\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.079451\n",
            "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.211774\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.201693\n",
            "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.268857\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.204092\n",
            "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.157061\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.215922\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.198500\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.143673\n",
            "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.104617\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.272630\n",
            "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.071981\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.169588\n",
            "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.197359\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.161189\n",
            "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.263453\n",
            "\n",
            "Test set: Avg. loss: 0.0875, Accuracy: 9715/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.059031\n",
            "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.125202\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.086627\n",
            "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.192058\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.146515\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.116226\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.279960\n",
            "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.056425\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.085248\n",
            "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.130269\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.122918\n",
            "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.175869\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.394267\n",
            "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.329101\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.246072\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.101387\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.172467\n",
            "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.182985\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.095986\n",
            "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.115316\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.182339\n",
            "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.174518\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.066254\n",
            "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.073003\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.197901\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.102945\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.138768\n",
            "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.359190\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.194526\n",
            "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.190719\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.142974\n",
            "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.080401\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.220881\n",
            "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.192484\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.198480\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.065539\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.281823\n",
            "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.190507\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.130220\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.156230\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.232771\n",
            "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.182640\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.188716\n",
            "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.102084\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.230905\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.286285\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.161430\n",
            "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.134303\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.254028\n",
            "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.152002\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.228385\n",
            "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.174526\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.182771\n",
            "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.072776\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.200418\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.228037\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.117972\n",
            "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.228410\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.120624\n",
            "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.154117\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.246330\n",
            "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.276791\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.138757\n",
            "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.104508\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.220978\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.150748\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.097144\n",
            "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.130393\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.258582\n",
            "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.203985\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.231660\n",
            "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.315672\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.237539\n",
            "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.106069\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.135278\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.202250\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.191638\n",
            "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.197398\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.217880\n",
            "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.205081\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.174375\n",
            "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.226414\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.053311\n",
            "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.043121\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.149351\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.257099\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.094513\n",
            "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.271923\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.227855\n",
            "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.262098\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.172528\n",
            "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.082107\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.232068\n",
            "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.089399\n",
            "\n",
            "Test set: Avg. loss: 0.0771, Accuracy: 9748/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.111965\n",
            "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.209177\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.165995\n",
            "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.266933\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.249956\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.076366\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.141594\n",
            "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.110225\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.105673\n",
            "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.176448\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.131128\n",
            "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.162338\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.111969\n",
            "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.104662\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.112262\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.153935\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.168438\n",
            "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.165832\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.163023\n",
            "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.144464\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.272688\n",
            "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.167225\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.109314\n",
            "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.125376\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.083827\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.150141\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.219615\n",
            "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.202002\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.084861\n",
            "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.241839\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.114230\n",
            "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.121833\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.200073\n",
            "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.091721\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.391256\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.174269\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.191835\n",
            "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.115799\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.149086\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.157712\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.207110\n",
            "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.130727\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.043840\n",
            "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.265387\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.084505\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.219484\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.140860\n",
            "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.432050\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.135711\n",
            "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.163583\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.175684\n",
            "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.174578\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.092184\n",
            "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.182292\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.098283\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.277825\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.052278\n",
            "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.121817\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.138862\n",
            "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.254685\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.146059\n",
            "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.153490\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.194241\n",
            "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.098059\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.176506\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.149809\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.079377\n",
            "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.177618\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.177697\n",
            "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.171913\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.168028\n",
            "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.176169\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.079206\n",
            "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.045922\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.086748\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.176821\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.116912\n",
            "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.117158\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.140910\n",
            "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.054012\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.165273\n",
            "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.172341\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.133635\n",
            "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.129052\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.054571\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.117019\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.066538\n",
            "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.223389\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.099526\n",
            "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.155427\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.249276\n",
            "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.039006\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.122610\n",
            "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.139764\n",
            "\n",
            "Test set: Avg. loss: 0.0748, Accuracy: 9758/10000 (98%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_counter, train_losses, color='blue', zorder=1)\n",
        "plt.scatter(test_counter, test_losses, color='red', zorder=2)\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.xlabel('number of training examples seen')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    network.fc1.weight[:] = fc1_init\n",
        "    #network.fc2.weight[:] = fc2_init\n",
        "    #network.conv1.weight[:] = conv1_init\n",
        "    #network.conv2.weight[:] = conv2_init"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "f1ab1c4420ee77e47dd796c1f0390d3d33956bdbe2bfd523727aad7b6e0efa70"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
