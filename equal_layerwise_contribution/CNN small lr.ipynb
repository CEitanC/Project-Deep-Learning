{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yNw44bANatMy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import new_alg_v1 as na\n",
        "import new_alg_v2 as na2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "# MNIST dataset\n",
        "from torchvision.datasets import MNIST, FashionMNIST\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def define_dataloaders(n_examples_train, n_examples_test, batch_size, classes=np.arange(10), zscore_images=True):\n",
        "    # MNIST data, batch training\n",
        "    #batch_size = n_examples_train\n",
        "\n",
        "    # Choose the classes (at most 10)\n",
        "    assert max(classes) <= 9\n",
        "\n",
        "    # Transformation for the images\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                  transforms.Normalize((0.5,), (0.5,)),\n",
        "                                  ])\n",
        "    trainset = MNIST(data_dir, download=True, train=True, transform=transform)\n",
        "    testset = MNIST(data_dir, download=True, train=False, transform=transform)\n",
        "\n",
        "    # Obtain training and test data. \n",
        "    # Note that both datasets are sorted, but the train and test loaders will shuffle them during training.\n",
        "    n_examples_tt = [n_examples_train, n_examples_test]\n",
        "    for i_d, (n_examples_i, dataset) in enumerate(zip(n_examples_tt, [trainset, testset])):\n",
        "        n_per_class = n_examples_i // len(classes)\n",
        "        data_orig = dataset.data.detach().clone()\n",
        "        targets_orig = dataset.targets.detach().clone()\n",
        "        for i_c, class_i in enumerate(classes):\n",
        "            mask = targets_orig == class_i\n",
        "            i0 = i_c * n_per_class\n",
        "            i1 = (i_c+1) * n_per_class\n",
        "            dataset.data[i0:i1] = data_orig[mask][:n_per_class]\n",
        "            dataset.targets[i0:i1] = targets_orig[mask][:n_per_class]\n",
        "        # Fill the remaining slots with random classes from the available choices\n",
        "        n_remain = n_examples_i - i1 \n",
        "        for i in range(n_remain):\n",
        "            class_i = np.random.choice(classes)\n",
        "            mask = targets_orig == class_i\n",
        "            idx_i = np.random.choice(torch.where(mask)[0].cpu())\n",
        "            dataset.data[i1+i] = data_orig[idx_i]\n",
        "            dataset.targets[i1+i] = targets_orig[idx_i]\n",
        "\n",
        "        # Cut off\n",
        "        dataset.data = dataset.data[:n_examples_i]\n",
        "        dataset.targets = dataset.targets[:n_examples_i]\n",
        "\n",
        "    # Batch-loader\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=n_examples_test, shuffle=False, num_workers=0)\n",
        "\n",
        "    return trainloader, testloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Settings:\n",
        "- no dropout\n",
        "- no momentum\n",
        "- increased number of fetures/filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "momentum = 0\n",
        "n_epochs = 100\n",
        "log_interval = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Building the Network\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, bias=False)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, bias=False)\n",
        "        self.fc1 = nn.Linear(320, 50, bias=False)\n",
        "        self.fc2 = nn.Linear(50, 10, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = torch.tanh(F.max_pool2d((self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = '/files/'\n",
        "batch_size = 1\n",
        "n_examples_train = 1024\n",
        "n_examples_test = 1024\n",
        "train_loader, test_loader =  define_dataloaders(n_examples_train, n_examples_test, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def single_batch_train():\n",
        "  network.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output = network(data)\n",
        "    loss = loss_f(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test():\n",
        "  network.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      output = network(data)\n",
        "      test_loss += loss_f(output,target)\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader)\n",
        "  test_losses.append(test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# lr = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inital loss =  2.299668550491333\n",
            "after one batch =  2.3098104000091553\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.01\n",
        "network = Net()\n",
        "optimizer = na2.new_alg(network.parameters(), lr=learning_rate, momentum=momentum)\n",
        "loss_f=nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "\n",
        "test()\n",
        "single_batch_train()\n",
        "test()\n",
        "\n",
        "conv1_final = network.conv1.weight.clone()\n",
        "conv2_final = network.conv2.weight.clone()\n",
        "fc1_final = network.fc1.weight.clone()\n",
        "fc2_final = network.fc2.weight.clone()\n",
        "\n",
        "#init weights conv1\n",
        "with torch.no_grad():\n",
        "  network.conv1.weight[:] = conv1_init\n",
        "\n",
        "test()\n",
        "loss_conv1 = test_losses[-1]\n",
        "\n",
        "#init weights conv2\n",
        "with torch.no_grad():\n",
        "  network.conv1.weight[:] = conv1_final\n",
        "  network.conv2.weight[:] = conv2_init\n",
        "\n",
        "test()\n",
        "loss_conv2 = test_losses[-1]\n",
        "\n",
        "#init weights fc1\n",
        "with torch.no_grad():\n",
        "  network.conv2.weight[:] = conv2_final\n",
        "  network.fc1.weight[:] = fc1_init\n",
        "\n",
        "test()\n",
        "loss_fc1 = test_losses[-1]\n",
        "\n",
        "#init weights fc2\n",
        "with torch.no_grad():\n",
        "  network.fc1.weight[:] = fc1_final\n",
        "  network.fc2.weight[:] = fc2_init\n",
        "\n",
        "test()\n",
        "loss_fc2 = test_losses[-1]\n",
        "\n",
        "\n",
        "IL = test_losses[0]\n",
        "FL = test_losses[1]\n",
        "print(\"inital loss = \", float(IL))\n",
        "print(\"after one batch = \", float(FL))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# $\\chi_l$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xl1 =  0.3683294951915741\n",
            "Xl2 =  0.4725186824798584\n",
            "Xl3 =  0.6582584977149963\n",
            "Xl4 =  0.5561380386352539\n"
          ]
        }
      ],
      "source": [
        "dL = FL - IL\n",
        "Xl1 = (FL - loss_conv1)/dL\n",
        "Xl2 = (FL-loss_conv2)/dL\n",
        "Xl3 = (FL-loss_fc1)/dL\n",
        "Xl4 = (FL-loss_fc2)/dL\n",
        "print(\"Xl1 = \", float(Xl1))\n",
        "print(\"Xl2 = \", float(Xl2))\n",
        "print(\"Xl3 = \", float(Xl3))\n",
        "print(\"Xl4 = \", float(Xl4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# lr = 0.005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inital loss =  2.2989132404327393\n",
            "after one batch =  2.3022348880767822\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.005\n",
        "network = Net()\n",
        "optimizer = na2.new_alg(network.parameters(), lr=learning_rate, momentum=momentum)\n",
        "loss_f=nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "\n",
        "test()\n",
        "single_batch_train()\n",
        "test()\n",
        "\n",
        "conv1_final = network.conv1.weight.clone()\n",
        "conv2_final = network.conv2.weight.clone()\n",
        "fc1_final = network.fc1.weight.clone()\n",
        "fc2_final = network.fc2.weight.clone()\n",
        "\n",
        "#init weights conv1\n",
        "with torch.no_grad():\n",
        "  network.conv1.weight[:] = conv1_init\n",
        "\n",
        "test()\n",
        "loss_conv1 = test_losses[-1]\n",
        "\n",
        "#init weights conv2\n",
        "with torch.no_grad():\n",
        "  network.conv1.weight[:] = conv1_final\n",
        "  network.conv2.weight[:] = conv2_init\n",
        "\n",
        "test()\n",
        "loss_conv2 = test_losses[-1]\n",
        "\n",
        "#init weights fc1\n",
        "with torch.no_grad():\n",
        "  network.conv2.weight[:] = conv2_final\n",
        "  network.fc1.weight[:] = fc1_init\n",
        "\n",
        "test()\n",
        "loss_fc1 = test_losses[-1]\n",
        "\n",
        "#init weights fc2\n",
        "with torch.no_grad():\n",
        "  network.fc1.weight[:] = fc1_final\n",
        "  network.fc2.weight[:] = fc2_init\n",
        "\n",
        "test()\n",
        "loss_fc2 = test_losses[-1]\n",
        "\n",
        "IL = test_losses[0]\n",
        "FL = test_losses[1]\n",
        "print(\"inital loss = \", float(IL))\n",
        "print(\"after one batch = \", float(FL))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# $\\chi_l$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xl1 =  0.5442147850990295\n",
            "Xl2 =  0.3392908275127411\n",
            "Xl3 =  0.26500144600868225\n",
            "Xl4 =  0.17312660813331604\n"
          ]
        }
      ],
      "source": [
        "dL = FL - IL\n",
        "Xl1 = (FL - loss_conv1)/dL\n",
        "Xl2 = (FL-loss_conv2)/dL\n",
        "Xl3 = (FL-loss_fc1)/dL\n",
        "Xl4 = (FL-loss_fc2)/dL\n",
        "print(\"Xl1 = \", float(Xl1))\n",
        "print(\"Xl2 = \", float(Xl2))\n",
        "print(\"Xl3 = \", float(Xl3))\n",
        "print(\"Xl4 = \", float(Xl4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "lrs = np.logspace(-2,-8,20)\n",
        "n_lr = len(lrs)\n",
        "Xs = np.zeros((n_lr, 4))\n",
        "\n",
        "for i_l, lr in enumerate(lrs):\n",
        "  learning_rate = lr\n",
        "  network = Net()\n",
        "  optimizer = na2.new_alg(network.parameters(), lr=learning_rate, momentum=momentum)\n",
        "  loss_f=nn.CrossEntropyLoss()\n",
        "\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "\n",
        "  conv1_init = network.conv1.weight.clone()\n",
        "  conv2_init = network.conv2.weight.clone()\n",
        "  fc1_init = network.fc1.weight.clone()\n",
        "  fc2_init = network.fc2.weight.clone()\n",
        "\n",
        "  test()\n",
        "  single_batch_train()\n",
        "  test()\n",
        "\n",
        "  conv1_final = network.conv1.weight.clone()\n",
        "  conv2_final = network.conv2.weight.clone()\n",
        "  fc1_final = network.fc1.weight.clone()\n",
        "  fc2_final = network.fc2.weight.clone()\n",
        "\n",
        "  #init weights conv1\n",
        "  with torch.no_grad():\n",
        "    network.conv1.weight[:] = conv1_init\n",
        "\n",
        "  test()\n",
        "  loss_conv1 = test_losses[-1]\n",
        "\n",
        "  #init weights conv2\n",
        "  with torch.no_grad():\n",
        "    network.conv1.weight[:] = conv1_final\n",
        "    network.conv2.weight[:] = conv2_init\n",
        "\n",
        "  test()\n",
        "  loss_conv2 = test_losses[-1]\n",
        "\n",
        "  #init weights fc1\n",
        "  with torch.no_grad():\n",
        "    network.conv2.weight[:] = conv2_final\n",
        "    network.fc1.weight[:] = fc1_init\n",
        "\n",
        "  test()\n",
        "  loss_fc1 = test_losses[-1]\n",
        "\n",
        "  #init weights fc2\n",
        "  with torch.no_grad():\n",
        "    network.fc1.weight[:] = fc1_final\n",
        "    network.fc2.weight[:] = fc2_init\n",
        "\n",
        "  test()\n",
        "  loss_fc2 = test_losses[-1]\n",
        "\n",
        "\n",
        "  IL = test_losses[0]\n",
        "  FL = test_losses[1]\n",
        "\n",
        "\n",
        "  dL = FL - IL\n",
        "  Xl1 = (FL - loss_conv1)/dL\n",
        "  Xl2 = (FL-loss_conv2)/dL\n",
        "  Xl3 = (FL-loss_fc1)/dL\n",
        "  Xl4 = (FL-loss_fc2)/dL\n",
        "  Xs[i_l] = Xl1, Xl2, Xl3, Xl4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 14.278055095672608)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "dX = np.abs(Xs - 1/4)\n",
        "plt.plot(lrs, Xs)\n",
        "plt.xscale('log')\n",
        "plt.ylim(0, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['conv1.weight', 'conv2.weight', 'fc1.weight', 'fc2.weight'])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(network.named_parameters()).keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inital loss =  2.305448293685913\n",
            "after one batch =  2.305149555206299\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.001\n",
        "network = Net()\n",
        "optimizer = na2.new_alg(network.parameters(), lr=learning_rate, momentum=momentum)\n",
        "loss_f=nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "\n",
        "test()\n",
        "single_batch_train()\n",
        "test()\n",
        "\n",
        "conv1_final = network.conv1.weight.clone()\n",
        "conv2_final = network.conv2.weight.clone()\n",
        "fc1_final = network.fc1.weight.clone()\n",
        "fc2_final = network.fc2.weight.clone()\n",
        "\n",
        "#init weights conv1\n",
        "with torch.no_grad():\n",
        "  network.conv1.weight[:] = conv1_init\n",
        "\n",
        "test()\n",
        "loss_conv1 = test_losses[-1]\n",
        "\n",
        "#init weights conv2\n",
        "with torch.no_grad():\n",
        "  network.conv1.weight[:] = conv1_final\n",
        "  network.conv2.weight[:] = conv2_init\n",
        "\n",
        "test()\n",
        "loss_conv2 = test_losses[-1]\n",
        "\n",
        "#init weights fc1\n",
        "with torch.no_grad():\n",
        "  network.conv2.weight[:] = conv2_final\n",
        "  network.fc1.weight[:] = fc1_init\n",
        "\n",
        "test()\n",
        "loss_fc1 = test_losses[-1]\n",
        "\n",
        "#init weights fc2\n",
        "with torch.no_grad():\n",
        "  network.fc1.weight[:] = fc1_final\n",
        "  network.fc2.weight[:] = fc2_init\n",
        "\n",
        "test()\n",
        "loss_fc2 = test_losses[-1]\n",
        "\n",
        "IL = test_losses[0]\n",
        "FL = test_losses[1]\n",
        "print(\"inital loss = \", float(IL))\n",
        "print(\"after one batch = \", float(FL))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# $\\chi_l$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xl1 =  -0.4429369568824768\n",
            "Xl2 =  0.27374300360679626\n",
            "Xl3 =  0.5027933120727539\n",
            "Xl4 =  0.5259377360343933\n"
          ]
        }
      ],
      "source": [
        "dL = FL - IL\n",
        "Xl1 = (FL - loss_conv1)/dL\n",
        "Xl2 = (FL-loss_conv2)/dL\n",
        "Xl3 = (FL-loss_fc1)/dL\n",
        "Xl4 = (FL-loss_fc2)/dL\n",
        "print(\"Xl1 = \", float(Xl1))\n",
        "print(\"Xl2 = \", float(Xl2))\n",
        "print(\"Xl3 = \", float(Xl3))\n",
        "print(\"Xl4 = \", float(Xl4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# lr = 0.0005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inital loss =  2.307868719100952\n",
            "after one batch =  2.307664155960083\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.0005\n",
        "network = Net()\n",
        "optimizer = na2.new_alg(network.parameters(), lr=learning_rate, momentum=momentum)\n",
        "loss_f=nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "\n",
        "test()\n",
        "single_batch_train()\n",
        "test()\n",
        "\n",
        "conv1_final = network.conv1.weight.clone()\n",
        "conv2_final = network.conv2.weight.clone()\n",
        "fc1_final = network.fc1.weight.clone()\n",
        "fc2_final = network.fc2.weight.clone()\n",
        "\n",
        "#init weights conv1\n",
        "with torch.no_grad():\n",
        "  network.conv1.weight[:] = conv1_init\n",
        "\n",
        "test()\n",
        "loss_conv1 = test_losses[-1]\n",
        "\n",
        "#init weights conv2\n",
        "with torch.no_grad():\n",
        "  network.conv1.weight[:] = conv1_final\n",
        "  network.conv2.weight[:] = conv2_init\n",
        "\n",
        "test()\n",
        "loss_conv2 = test_losses[-1]\n",
        "\n",
        "#init weights fc1\n",
        "with torch.no_grad():\n",
        "  network.conv2.weight[:] = conv2_final\n",
        "  network.fc1.weight[:] = fc1_init\n",
        "\n",
        "test()\n",
        "loss_fc1 = test_losses[-1]\n",
        "\n",
        "#init weights fc2\n",
        "with torch.no_grad():\n",
        "  network.fc1.weight[:] = fc1_final\n",
        "  network.fc2.weight[:] = fc2_init\n",
        "\n",
        "test()\n",
        "loss_fc2 = test_losses[-1]\n",
        "\n",
        "IL = test_losses[0]\n",
        "FL = test_losses[1]\n",
        "print(\"inital loss = \", float(IL))\n",
        "print(\"after one batch = \", float(FL))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# $\\chi_l$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xl1 =  0.21212121844291687\n",
            "Xl2 =  0.308857798576355\n",
            "Xl3 =  0.2482517510652542\n",
            "Xl4 =  0.1818181872367859\n"
          ]
        }
      ],
      "source": [
        "dL = FL - IL\n",
        "Xl1 = (FL - loss_conv1)/dL\n",
        "Xl2 = (FL-loss_conv2)/dL\n",
        "Xl3 = (FL-loss_fc1)/dL\n",
        "Xl4 = (FL-loss_fc2)/dL\n",
        "print(\"Xl1 = \", float(Xl1))\n",
        "print(\"Xl2 = \", float(Xl2))\n",
        "print(\"Xl3 = \", float(Xl3))\n",
        "print(\"Xl4 = \", float(Xl4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# lr = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inital loss =  2.290337562561035\n",
            "after one batch =  2.2903664112091064\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.0001\n",
        "network = Net()\n",
        "optimizer = na2.new_alg(network.parameters(), lr=learning_rate, momentum=momentum)\n",
        "loss_f=nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "\n",
        "test()\n",
        "single_batch_train()\n",
        "test()\n",
        "\n",
        "conv1_final = network.conv1.weight.clone()\n",
        "conv2_final = network.conv2.weight.clone()\n",
        "fc1_final = network.fc1.weight.clone()\n",
        "fc2_final = network.fc2.weight.clone()\n",
        "\n",
        "#init weights conv1\n",
        "with torch.no_grad():\n",
        "  network.conv1.weight[:] = conv1_init\n",
        "\n",
        "test()\n",
        "loss_conv1 = test_losses[-1]\n",
        "\n",
        "#init weights conv2\n",
        "with torch.no_grad():\n",
        "  network.conv1.weight[:] = conv1_final\n",
        "  network.conv2.weight[:] = conv2_init\n",
        "\n",
        "test()\n",
        "loss_conv2 = test_losses[-1]\n",
        "\n",
        "#init weights fc1\n",
        "with torch.no_grad():\n",
        "  network.conv2.weight[:] = conv2_final\n",
        "  network.fc1.weight[:] = fc1_init\n",
        "\n",
        "test()\n",
        "loss_fc1 = test_losses[-1]\n",
        "\n",
        "#init weights fc2\n",
        "with torch.no_grad():\n",
        "  network.fc1.weight[:] = fc1_final\n",
        "  network.fc2.weight[:] = fc2_init\n",
        "\n",
        "test()\n",
        "loss_fc2 = test_losses[-1]\n",
        "\n",
        "IL = test_losses[0]\n",
        "FL = test_losses[1]\n",
        "print(\"inital loss = \", float(IL))\n",
        "print(\"after one batch = \", float(FL))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# $\\chi_l$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xl1 =  1.165289282798767\n",
            "Xl2 =  0.1487603336572647\n",
            "Xl3 =  -0.1818181872367859\n",
            "Xl4 =  -0.09917355328798294\n"
          ]
        }
      ],
      "source": [
        "dL = FL - IL\n",
        "Xl1 = (FL - loss_conv1)/dL\n",
        "Xl2 = (FL-loss_conv2)/dL\n",
        "Xl3 = (FL-loss_fc1)/dL\n",
        "Xl4 = (FL-loss_fc2)/dL\n",
        "print(\"Xl1 = \", float(Xl1))\n",
        "print(\"Xl2 = \", float(Xl2))\n",
        "print(\"Xl3 = \", float(Xl3))\n",
        "print(\"Xl4 = \", float(Xl4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Loss_Vs_n_output10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
