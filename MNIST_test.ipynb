{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "-1xNKXx6TBQp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import new_alg_v2 as na\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "# MNIST dataset\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "    \n",
        "def define_dataloaders(n_examples_train, n_examples_test, classes=np.arange(10), zscore_images=True):\n",
        "    # MNIST data, batch training\n",
        "    batch_size = n_examples_train\n",
        "    batches_per_epoch_train = n_examples_train / batch_size\n",
        "    batches_per_epoch_test = n_examples_test / batch_size\n",
        "\n",
        "    # Choose the classes (at most 10)\n",
        "    assert max(classes) <= 9\n",
        "\n",
        "    # Transformation for the images\n",
        "    transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])\n",
        "    #transform = transforms.Compose([transforms.ToTensor(),\n",
        "    #                              transforms.Normalize((0.5,), (0.5,)),\n",
        "    #                              ])\n",
        "    trainset = MNIST(data_dir, download=True, train=True, transform=transform)\n",
        "    testset = MNIST(data_dir, download=True, train=False, transform=transform)\n",
        "\n",
        "    # Obtain training and test data. \n",
        "    # Note that both datasets are sorted, but the train and test loaders will shuffle them during training.\n",
        "    n_examples_tt = [n_examples_train, n_examples_test]\n",
        "    for i_d, (n_examples_i, dataset) in enumerate(zip(n_examples_tt, [trainset, testset])):\n",
        "        n_per_class = n_examples_i // len(classes)\n",
        "        data_orig = dataset.data.detach().clone()\n",
        "        targets_orig = dataset.targets.detach().clone()\n",
        "        for i_c, class_i in enumerate(classes):\n",
        "            mask = targets_orig == class_i\n",
        "            i0 = i_c * n_per_class\n",
        "            i1 = (i_c+1) * n_per_class\n",
        "            dataset.data[i0:i1] = data_orig[mask][:n_per_class]\n",
        "            dataset.targets[i0:i1] = targets_orig[mask][:n_per_class]\n",
        "        # Fill the remaining slots with random classes from the available choices\n",
        "        n_remain = n_examples_i - i1 \n",
        "        for i in range(n_remain):\n",
        "            class_i = np.random.choice(classes)\n",
        "            mask = targets_orig == class_i\n",
        "            idx_i = np.random.choice(torch.where(mask)[0][i1:].cpu())\n",
        "            dataset.data[i1+i] = data_orig[idx_i]\n",
        "            dataset.targets[i1+i] = targets_orig[idx_i]\n",
        "\n",
        "        # Cut off\n",
        "        dataset.data = dataset.data[:n_examples_i]\n",
        "        dataset.targets = dataset.targets[:n_examples_i]\n",
        "\n",
        "    # Batch-loader\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    return trainloader, testloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rRSXyp6THwR",
        "outputId": "edd158a8-0f57-48d7-be07-55ffef562fac"
      },
      "outputs": [],
      "source": [
        "n_epochs = 2000\n",
        "learning_rate = 0.01\n",
        "momentum = 0\n",
        "torch.backends.cudnn.enabled = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "_HKx24x7V_4d"
      },
      "outputs": [],
      "source": [
        "## no dopout\n",
        "#Building the Network\n",
        "\n",
        "conv1_out= 10\n",
        "conv2_out=20\n",
        "fc1_in=320\n",
        "fc2_in=50\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, conv1_out, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(conv1_out, conv2_out, kernel_size=5)\n",
        "        #self.conv2_drop = nn.Dropout2d() --- no dropout\n",
        "        self.fc1 = nn.Linear(fc1_in, fc2_in)\n",
        "        self.fc2 = nn.Linear(fc2_in, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(F.max_pool2d(self.conv1(x), 2))\n",
        "        #x = torch.tanh(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = torch.tanh(F.max_pool2d((self.conv2(x)), 2))\n",
        "        x = x.view(-1, fc1_in)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "      #  x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "taugfbRTWCo-"
      },
      "outputs": [],
      "source": [
        "network = Net()\n",
        "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
        "loss_f=nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the initial weights to measure later their contribution:\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "XKYJb4e7WLNG"
      },
      "outputs": [],
      "source": [
        "data_dir = '/files/'\n",
        "n_examples_train = 1000\n",
        "n_examples_test = 500\n",
        "train_loader, test_loader = define_dataloaders(n_examples_train, n_examples_test)\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Y2MhJ3U3WNTW"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "  train_n = 5\n",
        "  network.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output = network(data)\n",
        "    loss = loss_f(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % train_n == 0:\n",
        "      print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
        "          epoch,\n",
        "          loss.item()))\n",
        "    train_losses.append(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "r9W0MBhnWPfg"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "  network.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      output = network(data)\n",
        "      test_loss += loss_f(output,target)\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= 1 #1 is the amount of test batches\n",
        "  test_losses.append(test_loss)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss,\n",
        "    correct,\n",
        "    len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "BJo6gYxIWSUC",
        "outputId": "9cd112a3-872f-4d2c-c351-b99e8929a6dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3017, Accuracy: 55/500 (11%)\n",
            "\n",
            "Train Epoch: 5 \tLoss: 2.299567\n",
            "Train Epoch: 10 \tLoss: 2.291218\n",
            "Train Epoch: 15 \tLoss: 2.282929\n",
            "Train Epoch: 20 \tLoss: 2.274658\n",
            "Train Epoch: 25 \tLoss: 2.266371\n",
            "\n",
            "Test set: Avg. loss: 2.2650, Accuracy: 83/500 (17%)\n",
            "\n",
            "Train Epoch: 30 \tLoss: 2.258003\n",
            "Train Epoch: 35 \tLoss: 2.249528\n",
            "Train Epoch: 40 \tLoss: 2.240916\n",
            "Train Epoch: 45 \tLoss: 2.232136\n",
            "Train Epoch: 50 \tLoss: 2.223114\n",
            "\n",
            "Test set: Avg. loss: 2.2261, Accuracy: 146/500 (29%)\n",
            "\n",
            "Train Epoch: 55 \tLoss: 2.213825\n",
            "Train Epoch: 60 \tLoss: 2.204246\n",
            "Train Epoch: 65 \tLoss: 2.194346\n",
            "Train Epoch: 70 \tLoss: 2.184070\n",
            "Train Epoch: 75 \tLoss: 2.173366\n",
            "\n",
            "Test set: Avg. loss: 2.1802, Accuracy: 217/500 (43%)\n",
            "\n",
            "Train Epoch: 80 \tLoss: 2.162195\n",
            "Train Epoch: 85 \tLoss: 2.150515\n",
            "Train Epoch: 90 \tLoss: 2.138319\n",
            "Train Epoch: 95 \tLoss: 2.125541\n",
            "Train Epoch: 100 \tLoss: 2.112130\n",
            "\n",
            "Test set: Avg. loss: 2.1229, Accuracy: 258/500 (52%)\n",
            "\n",
            "Train Epoch: 105 \tLoss: 2.098078\n",
            "Train Epoch: 110 \tLoss: 2.083364\n",
            "Train Epoch: 115 \tLoss: 2.067940\n",
            "Train Epoch: 120 \tLoss: 2.051770\n",
            "Train Epoch: 125 \tLoss: 2.034869\n",
            "\n",
            "Test set: Avg. loss: 2.0499, Accuracy: 295/500 (59%)\n",
            "\n",
            "Train Epoch: 130 \tLoss: 2.017225\n",
            "Train Epoch: 135 \tLoss: 1.998833\n",
            "Train Epoch: 140 \tLoss: 1.979685\n",
            "Train Epoch: 145 \tLoss: 1.959793\n",
            "Train Epoch: 150 \tLoss: 1.939157\n",
            "\n",
            "Test set: Avg. loss: 1.9592, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 155 \tLoss: 1.917799\n",
            "Train Epoch: 160 \tLoss: 1.895755\n",
            "Train Epoch: 165 \tLoss: 1.873068\n",
            "Train Epoch: 170 \tLoss: 1.849805\n",
            "Train Epoch: 175 \tLoss: 1.826000\n",
            "\n",
            "Test set: Avg. loss: 1.8526, Accuracy: 311/500 (62%)\n",
            "\n",
            "Train Epoch: 180 \tLoss: 1.801706\n",
            "Train Epoch: 185 \tLoss: 1.777020\n",
            "Train Epoch: 190 \tLoss: 1.752029\n",
            "Train Epoch: 195 \tLoss: 1.726800\n",
            "Train Epoch: 200 \tLoss: 1.701394\n",
            "\n",
            "Test set: Avg. loss: 1.7363, Accuracy: 320/500 (64%)\n",
            "\n",
            "Train Epoch: 205 \tLoss: 1.675880\n",
            "Train Epoch: 210 \tLoss: 1.650343\n",
            "Train Epoch: 215 \tLoss: 1.624841\n",
            "Train Epoch: 220 \tLoss: 1.599433\n",
            "Train Epoch: 225 \tLoss: 1.574179\n",
            "\n",
            "Test set: Avg. loss: 1.6188, Accuracy: 329/500 (66%)\n",
            "\n",
            "Train Epoch: 230 \tLoss: 1.549132\n",
            "Train Epoch: 235 \tLoss: 1.524332\n",
            "Train Epoch: 240 \tLoss: 1.499835\n",
            "Train Epoch: 245 \tLoss: 1.475664\n",
            "Train Epoch: 250 \tLoss: 1.451851\n",
            "\n",
            "Test set: Avg. loss: 1.5070, Accuracy: 335/500 (67%)\n",
            "\n",
            "Train Epoch: 255 \tLoss: 1.428428\n",
            "Train Epoch: 260 \tLoss: 1.405416\n",
            "Train Epoch: 265 \tLoss: 1.382819\n",
            "Train Epoch: 270 \tLoss: 1.360646\n",
            "Train Epoch: 275 \tLoss: 1.338914\n",
            "\n",
            "Test set: Avg. loss: 1.4046, Accuracy: 341/500 (68%)\n",
            "\n",
            "Train Epoch: 280 \tLoss: 1.317621\n",
            "Train Epoch: 285 \tLoss: 1.296773\n",
            "Train Epoch: 290 \tLoss: 1.276373\n",
            "Train Epoch: 295 \tLoss: 1.256409\n",
            "Train Epoch: 300 \tLoss: 1.236897\n",
            "\n",
            "Test set: Avg. loss: 1.3126, Accuracy: 353/500 (71%)\n",
            "\n",
            "Train Epoch: 305 \tLoss: 1.217825\n",
            "Train Epoch: 310 \tLoss: 1.199181\n",
            "Train Epoch: 315 \tLoss: 1.180960\n",
            "Train Epoch: 320 \tLoss: 1.163154\n",
            "Train Epoch: 325 \tLoss: 1.145762\n",
            "\n",
            "Test set: Avg. loss: 1.2308, Accuracy: 361/500 (72%)\n",
            "\n",
            "Train Epoch: 330 \tLoss: 1.128775\n",
            "Train Epoch: 335 \tLoss: 1.112179\n",
            "Train Epoch: 340 \tLoss: 1.095967\n",
            "Train Epoch: 345 \tLoss: 1.080134\n",
            "Train Epoch: 350 \tLoss: 1.064676\n",
            "\n",
            "Test set: Avg. loss: 1.1581, Accuracy: 367/500 (73%)\n",
            "\n",
            "Train Epoch: 355 \tLoss: 1.049578\n",
            "Train Epoch: 360 \tLoss: 1.034836\n",
            "Train Epoch: 365 \tLoss: 1.020440\n",
            "Train Epoch: 370 \tLoss: 1.006377\n",
            "Train Epoch: 375 \tLoss: 0.992642\n",
            "\n",
            "Test set: Avg. loss: 1.0936, Accuracy: 374/500 (75%)\n",
            "\n",
            "Train Epoch: 380 \tLoss: 0.979229\n",
            "Train Epoch: 385 \tLoss: 0.966120\n",
            "Train Epoch: 390 \tLoss: 0.953310\n",
            "Train Epoch: 395 \tLoss: 0.940796\n",
            "Train Epoch: 400 \tLoss: 0.928570\n",
            "\n",
            "Test set: Avg. loss: 1.0362, Accuracy: 377/500 (75%)\n",
            "\n",
            "Train Epoch: 405 \tLoss: 0.916625\n",
            "Train Epoch: 410 \tLoss: 0.904957\n",
            "Train Epoch: 415 \tLoss: 0.893553\n",
            "Train Epoch: 420 \tLoss: 0.882404\n",
            "Train Epoch: 425 \tLoss: 0.871505\n",
            "\n",
            "Test set: Avg. loss: 0.9851, Accuracy: 383/500 (77%)\n",
            "\n",
            "Train Epoch: 430 \tLoss: 0.860849\n",
            "Train Epoch: 435 \tLoss: 0.850429\n",
            "Train Epoch: 440 \tLoss: 0.840240\n",
            "Train Epoch: 445 \tLoss: 0.830281\n",
            "Train Epoch: 450 \tLoss: 0.820540\n",
            "\n",
            "Test set: Avg. loss: 0.9393, Accuracy: 388/500 (78%)\n",
            "\n",
            "Train Epoch: 455 \tLoss: 0.811011\n",
            "Train Epoch: 460 \tLoss: 0.801688\n",
            "Train Epoch: 465 \tLoss: 0.792565\n",
            "Train Epoch: 470 \tLoss: 0.783638\n",
            "Train Epoch: 475 \tLoss: 0.774903\n",
            "\n",
            "Test set: Avg. loss: 0.8982, Accuracy: 390/500 (78%)\n",
            "\n",
            "Train Epoch: 480 \tLoss: 0.766352\n",
            "Train Epoch: 485 \tLoss: 0.757978\n",
            "Train Epoch: 490 \tLoss: 0.749777\n",
            "Train Epoch: 495 \tLoss: 0.741747\n",
            "Train Epoch: 500 \tLoss: 0.733885\n",
            "\n",
            "Test set: Avg. loss: 0.8612, Accuracy: 395/500 (79%)\n",
            "\n",
            "Train Epoch: 505 \tLoss: 0.726185\n",
            "Train Epoch: 510 \tLoss: 0.718641\n",
            "Train Epoch: 515 \tLoss: 0.711247\n",
            "Train Epoch: 520 \tLoss: 0.704001\n",
            "Train Epoch: 525 \tLoss: 0.696897\n",
            "\n",
            "Test set: Avg. loss: 0.8277, Accuracy: 403/500 (81%)\n",
            "\n",
            "Train Epoch: 530 \tLoss: 0.689931\n",
            "Train Epoch: 535 \tLoss: 0.683101\n",
            "Train Epoch: 540 \tLoss: 0.676404\n",
            "Train Epoch: 545 \tLoss: 0.669833\n",
            "Train Epoch: 550 \tLoss: 0.663388\n",
            "\n",
            "Test set: Avg. loss: 0.7973, Accuracy: 405/500 (81%)\n",
            "\n",
            "Train Epoch: 555 \tLoss: 0.657066\n",
            "Train Epoch: 560 \tLoss: 0.650863\n",
            "Train Epoch: 565 \tLoss: 0.644777\n",
            "Train Epoch: 570 \tLoss: 0.638803\n",
            "Train Epoch: 575 \tLoss: 0.632941\n",
            "\n",
            "Test set: Avg. loss: 0.7697, Accuracy: 403/500 (81%)\n",
            "\n",
            "Train Epoch: 580 \tLoss: 0.627185\n",
            "Train Epoch: 585 \tLoss: 0.621532\n",
            "Train Epoch: 590 \tLoss: 0.615983\n",
            "Train Epoch: 595 \tLoss: 0.610532\n",
            "Train Epoch: 600 \tLoss: 0.605175\n",
            "\n",
            "Test set: Avg. loss: 0.7444, Accuracy: 406/500 (81%)\n",
            "\n",
            "Train Epoch: 605 \tLoss: 0.599913\n",
            "Train Epoch: 610 \tLoss: 0.594741\n",
            "Train Epoch: 615 \tLoss: 0.589657\n",
            "Train Epoch: 620 \tLoss: 0.584659\n",
            "Train Epoch: 625 \tLoss: 0.579747\n",
            "\n",
            "Test set: Avg. loss: 0.7212, Accuracy: 408/500 (82%)\n",
            "\n",
            "Train Epoch: 630 \tLoss: 0.574917\n",
            "Train Epoch: 635 \tLoss: 0.570168\n",
            "Train Epoch: 640 \tLoss: 0.565498\n",
            "Train Epoch: 645 \tLoss: 0.560905\n",
            "Train Epoch: 650 \tLoss: 0.556387\n",
            "\n",
            "Test set: Avg. loss: 0.6998, Accuracy: 410/500 (82%)\n",
            "\n",
            "Train Epoch: 655 \tLoss: 0.551943\n",
            "Train Epoch: 660 \tLoss: 0.547569\n",
            "Train Epoch: 665 \tLoss: 0.543266\n",
            "Train Epoch: 670 \tLoss: 0.539032\n",
            "Train Epoch: 675 \tLoss: 0.534864\n",
            "\n",
            "Test set: Avg. loss: 0.6802, Accuracy: 413/500 (83%)\n",
            "\n",
            "Train Epoch: 680 \tLoss: 0.530762\n",
            "Train Epoch: 685 \tLoss: 0.526726\n",
            "Train Epoch: 690 \tLoss: 0.522751\n",
            "Train Epoch: 695 \tLoss: 0.518837\n",
            "Train Epoch: 700 \tLoss: 0.514983\n",
            "\n",
            "Test set: Avg. loss: 0.6620, Accuracy: 414/500 (83%)\n",
            "\n",
            "Train Epoch: 705 \tLoss: 0.511188\n",
            "Train Epoch: 710 \tLoss: 0.507450\n",
            "Train Epoch: 715 \tLoss: 0.503767\n",
            "Train Epoch: 720 \tLoss: 0.500140\n",
            "Train Epoch: 725 \tLoss: 0.496566\n",
            "\n",
            "Test set: Avg. loss: 0.6451, Accuracy: 414/500 (83%)\n",
            "\n",
            "Train Epoch: 730 \tLoss: 0.493044\n",
            "Train Epoch: 735 \tLoss: 0.489571\n",
            "Train Epoch: 740 \tLoss: 0.486149\n",
            "Train Epoch: 745 \tLoss: 0.482777\n",
            "Train Epoch: 750 \tLoss: 0.479453\n",
            "\n",
            "Test set: Avg. loss: 0.6294, Accuracy: 416/500 (83%)\n",
            "\n",
            "Train Epoch: 755 \tLoss: 0.476174\n",
            "Train Epoch: 760 \tLoss: 0.472940\n",
            "Train Epoch: 765 \tLoss: 0.469751\n",
            "Train Epoch: 770 \tLoss: 0.466606\n",
            "Train Epoch: 775 \tLoss: 0.463502\n",
            "\n",
            "Test set: Avg. loss: 0.6148, Accuracy: 417/500 (83%)\n",
            "\n",
            "Train Epoch: 780 \tLoss: 0.460439\n",
            "Train Epoch: 785 \tLoss: 0.457417\n",
            "Train Epoch: 790 \tLoss: 0.454435\n",
            "Train Epoch: 795 \tLoss: 0.451490\n",
            "Train Epoch: 800 \tLoss: 0.448582\n",
            "\n",
            "Test set: Avg. loss: 0.6011, Accuracy: 417/500 (83%)\n",
            "\n",
            "Train Epoch: 805 \tLoss: 0.445710\n",
            "Train Epoch: 810 \tLoss: 0.442876\n",
            "Train Epoch: 815 \tLoss: 0.440079\n",
            "Train Epoch: 820 \tLoss: 0.437317\n",
            "Train Epoch: 825 \tLoss: 0.434590\n",
            "\n",
            "Test set: Avg. loss: 0.5883, Accuracy: 417/500 (83%)\n",
            "\n",
            "Train Epoch: 830 \tLoss: 0.431897\n",
            "Train Epoch: 835 \tLoss: 0.429238\n",
            "Train Epoch: 840 \tLoss: 0.426611\n",
            "Train Epoch: 845 \tLoss: 0.424018\n",
            "Train Epoch: 850 \tLoss: 0.421456\n",
            "\n",
            "Test set: Avg. loss: 0.5763, Accuracy: 421/500 (84%)\n",
            "\n",
            "Train Epoch: 855 \tLoss: 0.418924\n",
            "Train Epoch: 860 \tLoss: 0.416423\n",
            "Train Epoch: 865 \tLoss: 0.413951\n",
            "Train Epoch: 870 \tLoss: 0.411507\n",
            "Train Epoch: 875 \tLoss: 0.409091\n",
            "\n",
            "Test set: Avg. loss: 0.5650, Accuracy: 422/500 (84%)\n",
            "\n",
            "Train Epoch: 880 \tLoss: 0.406705\n",
            "Train Epoch: 885 \tLoss: 0.404347\n",
            "Train Epoch: 890 \tLoss: 0.402015\n",
            "Train Epoch: 895 \tLoss: 0.399710\n",
            "Train Epoch: 900 \tLoss: 0.397431\n",
            "\n",
            "Test set: Avg. loss: 0.5544, Accuracy: 422/500 (84%)\n",
            "\n",
            "Train Epoch: 905 \tLoss: 0.395178\n",
            "Train Epoch: 910 \tLoss: 0.392952\n",
            "Train Epoch: 915 \tLoss: 0.390751\n",
            "Train Epoch: 920 \tLoss: 0.388574\n",
            "Train Epoch: 925 \tLoss: 0.386421\n",
            "\n",
            "Test set: Avg. loss: 0.5444, Accuracy: 422/500 (84%)\n",
            "\n",
            "Train Epoch: 930 \tLoss: 0.384293\n",
            "Train Epoch: 935 \tLoss: 0.382188\n",
            "Train Epoch: 940 \tLoss: 0.380105\n",
            "Train Epoch: 945 \tLoss: 0.378046\n",
            "Train Epoch: 950 \tLoss: 0.376007\n",
            "\n",
            "Test set: Avg. loss: 0.5348, Accuracy: 423/500 (85%)\n",
            "\n",
            "Train Epoch: 955 \tLoss: 0.373991\n",
            "Train Epoch: 960 \tLoss: 0.371997\n",
            "Train Epoch: 965 \tLoss: 0.370024\n",
            "Train Epoch: 970 \tLoss: 0.368070\n",
            "Train Epoch: 975 \tLoss: 0.366137\n",
            "\n",
            "Test set: Avg. loss: 0.5258, Accuracy: 423/500 (85%)\n",
            "\n",
            "Train Epoch: 980 \tLoss: 0.364224\n",
            "Train Epoch: 985 \tLoss: 0.362330\n",
            "Train Epoch: 990 \tLoss: 0.360454\n",
            "Train Epoch: 995 \tLoss: 0.358598\n",
            "Train Epoch: 1000 \tLoss: 0.356761\n",
            "\n",
            "Test set: Avg. loss: 0.5173, Accuracy: 422/500 (84%)\n",
            "\n",
            "Train Epoch: 1005 \tLoss: 0.354940\n",
            "Train Epoch: 1010 \tLoss: 0.353137\n",
            "Train Epoch: 1015 \tLoss: 0.351352\n",
            "Train Epoch: 1020 \tLoss: 0.349585\n",
            "Train Epoch: 1025 \tLoss: 0.347835\n",
            "\n",
            "Test set: Avg. loss: 0.5091, Accuracy: 422/500 (84%)\n",
            "\n",
            "Train Epoch: 1030 \tLoss: 0.346103\n",
            "Train Epoch: 1035 \tLoss: 0.344388\n",
            "Train Epoch: 1040 \tLoss: 0.342690\n",
            "Train Epoch: 1045 \tLoss: 0.341008\n",
            "Train Epoch: 1050 \tLoss: 0.339341\n",
            "\n",
            "Test set: Avg. loss: 0.5014, Accuracy: 424/500 (85%)\n",
            "\n",
            "Train Epoch: 1055 \tLoss: 0.337691\n",
            "Train Epoch: 1060 \tLoss: 0.336055\n",
            "Train Epoch: 1065 \tLoss: 0.334433\n",
            "Train Epoch: 1070 \tLoss: 0.332827\n",
            "Train Epoch: 1075 \tLoss: 0.331235\n",
            "\n",
            "Test set: Avg. loss: 0.4940, Accuracy: 424/500 (85%)\n",
            "\n",
            "Train Epoch: 1080 \tLoss: 0.329659\n",
            "Train Epoch: 1085 \tLoss: 0.328097\n",
            "Train Epoch: 1090 \tLoss: 0.326548\n",
            "Train Epoch: 1095 \tLoss: 0.325015\n",
            "Train Epoch: 1100 \tLoss: 0.323495\n",
            "\n",
            "Test set: Avg. loss: 0.4870, Accuracy: 424/500 (85%)\n",
            "\n",
            "Train Epoch: 1105 \tLoss: 0.321989\n",
            "Train Epoch: 1110 \tLoss: 0.320497\n",
            "Train Epoch: 1115 \tLoss: 0.319016\n",
            "Train Epoch: 1120 \tLoss: 0.317549\n",
            "Train Epoch: 1125 \tLoss: 0.316095\n",
            "\n",
            "Test set: Avg. loss: 0.4802, Accuracy: 425/500 (85%)\n",
            "\n",
            "Train Epoch: 1130 \tLoss: 0.314653\n",
            "Train Epoch: 1135 \tLoss: 0.313223\n",
            "Train Epoch: 1140 \tLoss: 0.311805\n",
            "Train Epoch: 1145 \tLoss: 0.310399\n",
            "Train Epoch: 1150 \tLoss: 0.309006\n",
            "\n",
            "Test set: Avg. loss: 0.4737, Accuracy: 425/500 (85%)\n",
            "\n",
            "Train Epoch: 1155 \tLoss: 0.307623\n",
            "Train Epoch: 1160 \tLoss: 0.306253\n",
            "Train Epoch: 1165 \tLoss: 0.304895\n",
            "Train Epoch: 1170 \tLoss: 0.303549\n",
            "Train Epoch: 1175 \tLoss: 0.302213\n",
            "\n",
            "Test set: Avg. loss: 0.4675, Accuracy: 426/500 (85%)\n",
            "\n",
            "Train Epoch: 1180 \tLoss: 0.300889\n",
            "Train Epoch: 1185 \tLoss: 0.299576\n",
            "Train Epoch: 1190 \tLoss: 0.298273\n",
            "Train Epoch: 1195 \tLoss: 0.296980\n",
            "Train Epoch: 1200 \tLoss: 0.295696\n",
            "\n",
            "Test set: Avg. loss: 0.4615, Accuracy: 427/500 (85%)\n",
            "\n",
            "Train Epoch: 1205 \tLoss: 0.294422\n",
            "Train Epoch: 1210 \tLoss: 0.293159\n",
            "Train Epoch: 1215 \tLoss: 0.291906\n",
            "Train Epoch: 1220 \tLoss: 0.290662\n",
            "Train Epoch: 1225 \tLoss: 0.289429\n",
            "\n",
            "Test set: Avg. loss: 0.4557, Accuracy: 427/500 (85%)\n",
            "\n",
            "Train Epoch: 1230 \tLoss: 0.288205\n",
            "Train Epoch: 1235 \tLoss: 0.286991\n",
            "Train Epoch: 1240 \tLoss: 0.285786\n",
            "Train Epoch: 1245 \tLoss: 0.284591\n",
            "Train Epoch: 1250 \tLoss: 0.283405\n",
            "\n",
            "Test set: Avg. loss: 0.4502, Accuracy: 428/500 (86%)\n",
            "\n",
            "Train Epoch: 1255 \tLoss: 0.282229\n",
            "Train Epoch: 1260 \tLoss: 0.281062\n",
            "Train Epoch: 1265 \tLoss: 0.279904\n",
            "Train Epoch: 1270 \tLoss: 0.278755\n",
            "Train Epoch: 1275 \tLoss: 0.277614\n",
            "\n",
            "Test set: Avg. loss: 0.4448, Accuracy: 429/500 (86%)\n",
            "\n",
            "Train Epoch: 1280 \tLoss: 0.276480\n",
            "Train Epoch: 1285 \tLoss: 0.275356\n",
            "Train Epoch: 1290 \tLoss: 0.274239\n",
            "Train Epoch: 1295 \tLoss: 0.273132\n",
            "Train Epoch: 1300 \tLoss: 0.272034\n",
            "\n",
            "Test set: Avg. loss: 0.4397, Accuracy: 429/500 (86%)\n",
            "\n",
            "Train Epoch: 1305 \tLoss: 0.270944\n",
            "Train Epoch: 1310 \tLoss: 0.269861\n",
            "Train Epoch: 1315 \tLoss: 0.268785\n",
            "Train Epoch: 1320 \tLoss: 0.267717\n",
            "Train Epoch: 1325 \tLoss: 0.266656\n",
            "\n",
            "Test set: Avg. loss: 0.4347, Accuracy: 430/500 (86%)\n",
            "\n",
            "Train Epoch: 1330 \tLoss: 0.265603\n",
            "Train Epoch: 1335 \tLoss: 0.264558\n",
            "Train Epoch: 1340 \tLoss: 0.263519\n",
            "Train Epoch: 1345 \tLoss: 0.262487\n",
            "Train Epoch: 1350 \tLoss: 0.261463\n",
            "\n",
            "Test set: Avg. loss: 0.4299, Accuracy: 430/500 (86%)\n",
            "\n",
            "Train Epoch: 1355 \tLoss: 0.260446\n",
            "Train Epoch: 1360 \tLoss: 0.259436\n",
            "Train Epoch: 1365 \tLoss: 0.258433\n",
            "Train Epoch: 1370 \tLoss: 0.257436\n",
            "Train Epoch: 1375 \tLoss: 0.256447\n",
            "\n",
            "Test set: Avg. loss: 0.4252, Accuracy: 430/500 (86%)\n",
            "\n",
            "Train Epoch: 1380 \tLoss: 0.255465\n",
            "Train Epoch: 1385 \tLoss: 0.254490\n",
            "Train Epoch: 1390 \tLoss: 0.253522\n",
            "Train Epoch: 1395 \tLoss: 0.252560\n",
            "Train Epoch: 1400 \tLoss: 0.251604\n",
            "\n",
            "Test set: Avg. loss: 0.4207, Accuracy: 430/500 (86%)\n",
            "\n",
            "Train Epoch: 1405 \tLoss: 0.250654\n",
            "Train Epoch: 1410 \tLoss: 0.249709\n",
            "Train Epoch: 1415 \tLoss: 0.248771\n",
            "Train Epoch: 1420 \tLoss: 0.247840\n",
            "Train Epoch: 1425 \tLoss: 0.246914\n",
            "\n",
            "Test set: Avg. loss: 0.4164, Accuracy: 430/500 (86%)\n",
            "\n",
            "Train Epoch: 1430 \tLoss: 0.245994\n",
            "Train Epoch: 1435 \tLoss: 0.245081\n",
            "Train Epoch: 1440 \tLoss: 0.244173\n",
            "Train Epoch: 1445 \tLoss: 0.243272\n",
            "Train Epoch: 1450 \tLoss: 0.242376\n",
            "\n",
            "Test set: Avg. loss: 0.4122, Accuracy: 431/500 (86%)\n",
            "\n",
            "Train Epoch: 1455 \tLoss: 0.241486\n",
            "Train Epoch: 1460 \tLoss: 0.240601\n",
            "Train Epoch: 1465 \tLoss: 0.239722\n",
            "Train Epoch: 1470 \tLoss: 0.238849\n",
            "Train Epoch: 1475 \tLoss: 0.237981\n",
            "\n",
            "Test set: Avg. loss: 0.4081, Accuracy: 433/500 (87%)\n",
            "\n",
            "Train Epoch: 1480 \tLoss: 0.237119\n",
            "Train Epoch: 1485 \tLoss: 0.236263\n",
            "Train Epoch: 1490 \tLoss: 0.235411\n",
            "Train Epoch: 1495 \tLoss: 0.234564\n",
            "Train Epoch: 1500 \tLoss: 0.233722\n",
            "\n",
            "Test set: Avg. loss: 0.4042, Accuracy: 433/500 (87%)\n",
            "\n",
            "Train Epoch: 1505 \tLoss: 0.232885\n",
            "Train Epoch: 1510 \tLoss: 0.232053\n",
            "Train Epoch: 1515 \tLoss: 0.231226\n",
            "Train Epoch: 1520 \tLoss: 0.230404\n",
            "Train Epoch: 1525 \tLoss: 0.229588\n",
            "\n",
            "Test set: Avg. loss: 0.4003, Accuracy: 435/500 (87%)\n",
            "\n",
            "Train Epoch: 1530 \tLoss: 0.228776\n",
            "Train Epoch: 1535 \tLoss: 0.227969\n",
            "Train Epoch: 1540 \tLoss: 0.227167\n",
            "Train Epoch: 1545 \tLoss: 0.226369\n",
            "Train Epoch: 1550 \tLoss: 0.225577\n",
            "\n",
            "Test set: Avg. loss: 0.3966, Accuracy: 436/500 (87%)\n",
            "\n",
            "Train Epoch: 1555 \tLoss: 0.224791\n",
            "Train Epoch: 1560 \tLoss: 0.224008\n",
            "Train Epoch: 1565 \tLoss: 0.223230\n",
            "Train Epoch: 1570 \tLoss: 0.222458\n",
            "Train Epoch: 1575 \tLoss: 0.221690\n",
            "\n",
            "Test set: Avg. loss: 0.3930, Accuracy: 436/500 (87%)\n",
            "\n",
            "Train Epoch: 1580 \tLoss: 0.220926\n",
            "Train Epoch: 1585 \tLoss: 0.220167\n",
            "Train Epoch: 1590 \tLoss: 0.219412\n",
            "Train Epoch: 1595 \tLoss: 0.218662\n",
            "Train Epoch: 1600 \tLoss: 0.217916\n",
            "\n",
            "Test set: Avg. loss: 0.3895, Accuracy: 437/500 (87%)\n",
            "\n",
            "Train Epoch: 1605 \tLoss: 0.217174\n",
            "Train Epoch: 1610 \tLoss: 0.216436\n",
            "Train Epoch: 1615 \tLoss: 0.215702\n",
            "Train Epoch: 1620 \tLoss: 0.214973\n",
            "Train Epoch: 1625 \tLoss: 0.214247\n",
            "\n",
            "Test set: Avg. loss: 0.3861, Accuracy: 437/500 (87%)\n",
            "\n",
            "Train Epoch: 1630 \tLoss: 0.213526\n",
            "Train Epoch: 1635 \tLoss: 0.212809\n",
            "Train Epoch: 1640 \tLoss: 0.212095\n",
            "Train Epoch: 1645 \tLoss: 0.211386\n",
            "Train Epoch: 1650 \tLoss: 0.210680\n",
            "\n",
            "Test set: Avg. loss: 0.3828, Accuracy: 437/500 (87%)\n",
            "\n",
            "Train Epoch: 1655 \tLoss: 0.209979\n",
            "Train Epoch: 1660 \tLoss: 0.209281\n",
            "Train Epoch: 1665 \tLoss: 0.208587\n",
            "Train Epoch: 1670 \tLoss: 0.207898\n",
            "Train Epoch: 1675 \tLoss: 0.207211\n",
            "\n",
            "Test set: Avg. loss: 0.3795, Accuracy: 437/500 (87%)\n",
            "\n",
            "Train Epoch: 1680 \tLoss: 0.206528\n",
            "Train Epoch: 1685 \tLoss: 0.205849\n",
            "Train Epoch: 1690 \tLoss: 0.205173\n",
            "Train Epoch: 1695 \tLoss: 0.204500\n",
            "Train Epoch: 1700 \tLoss: 0.203831\n",
            "\n",
            "Test set: Avg. loss: 0.3764, Accuracy: 439/500 (88%)\n",
            "\n",
            "Train Epoch: 1705 \tLoss: 0.203165\n",
            "Train Epoch: 1710 \tLoss: 0.202501\n",
            "Train Epoch: 1715 \tLoss: 0.201842\n",
            "Train Epoch: 1720 \tLoss: 0.201186\n",
            "Train Epoch: 1725 \tLoss: 0.200533\n",
            "\n",
            "Test set: Avg. loss: 0.3733, Accuracy: 439/500 (88%)\n",
            "\n",
            "Train Epoch: 1730 \tLoss: 0.199884\n",
            "Train Epoch: 1735 \tLoss: 0.199238\n",
            "Train Epoch: 1740 \tLoss: 0.198595\n",
            "Train Epoch: 1745 \tLoss: 0.197956\n",
            "Train Epoch: 1750 \tLoss: 0.197320\n",
            "\n",
            "Test set: Avg. loss: 0.3704, Accuracy: 440/500 (88%)\n",
            "\n",
            "Train Epoch: 1755 \tLoss: 0.196688\n",
            "Train Epoch: 1760 \tLoss: 0.196058\n",
            "Train Epoch: 1765 \tLoss: 0.195431\n",
            "Train Epoch: 1770 \tLoss: 0.194807\n",
            "Train Epoch: 1775 \tLoss: 0.194186\n",
            "\n",
            "Test set: Avg. loss: 0.3675, Accuracy: 441/500 (88%)\n",
            "\n",
            "Train Epoch: 1780 \tLoss: 0.193568\n",
            "Train Epoch: 1785 \tLoss: 0.192953\n",
            "Train Epoch: 1790 \tLoss: 0.192342\n",
            "Train Epoch: 1795 \tLoss: 0.191733\n",
            "Train Epoch: 1800 \tLoss: 0.191128\n",
            "\n",
            "Test set: Avg. loss: 0.3646, Accuracy: 441/500 (88%)\n",
            "\n",
            "Train Epoch: 1805 \tLoss: 0.190526\n",
            "Train Epoch: 1810 \tLoss: 0.189927\n",
            "Train Epoch: 1815 \tLoss: 0.189331\n",
            "Train Epoch: 1820 \tLoss: 0.188738\n",
            "Train Epoch: 1825 \tLoss: 0.188148\n",
            "\n",
            "Test set: Avg. loss: 0.3619, Accuracy: 441/500 (88%)\n",
            "\n",
            "Train Epoch: 1830 \tLoss: 0.187561\n",
            "Train Epoch: 1835 \tLoss: 0.186976\n",
            "Train Epoch: 1840 \tLoss: 0.186395\n",
            "Train Epoch: 1845 \tLoss: 0.185817\n",
            "Train Epoch: 1850 \tLoss: 0.185241\n",
            "\n",
            "Test set: Avg. loss: 0.3592, Accuracy: 442/500 (88%)\n",
            "\n",
            "Train Epoch: 1855 \tLoss: 0.184669\n",
            "Train Epoch: 1860 \tLoss: 0.184099\n",
            "Train Epoch: 1865 \tLoss: 0.183532\n",
            "Train Epoch: 1870 \tLoss: 0.182969\n",
            "Train Epoch: 1875 \tLoss: 0.182408\n",
            "\n",
            "Test set: Avg. loss: 0.3565, Accuracy: 442/500 (88%)\n",
            "\n",
            "Train Epoch: 1880 \tLoss: 0.181849\n",
            "Train Epoch: 1885 \tLoss: 0.181294\n",
            "Train Epoch: 1890 \tLoss: 0.180741\n",
            "Train Epoch: 1895 \tLoss: 0.180191\n",
            "Train Epoch: 1900 \tLoss: 0.179642\n",
            "\n",
            "Test set: Avg. loss: 0.3540, Accuracy: 442/500 (88%)\n",
            "\n",
            "Train Epoch: 1905 \tLoss: 0.179097\n",
            "Train Epoch: 1910 \tLoss: 0.178553\n",
            "Train Epoch: 1915 \tLoss: 0.178013\n",
            "Train Epoch: 1920 \tLoss: 0.177474\n",
            "Train Epoch: 1925 \tLoss: 0.176939\n",
            "\n",
            "Test set: Avg. loss: 0.3515, Accuracy: 442/500 (88%)\n",
            "\n",
            "Train Epoch: 1930 \tLoss: 0.176406\n",
            "Train Epoch: 1935 \tLoss: 0.175876\n",
            "Train Epoch: 1940 \tLoss: 0.175348\n",
            "Train Epoch: 1945 \tLoss: 0.174823\n",
            "Train Epoch: 1950 \tLoss: 0.174300\n",
            "\n",
            "Test set: Avg. loss: 0.3490, Accuracy: 442/500 (88%)\n",
            "\n",
            "Train Epoch: 1955 \tLoss: 0.173779\n",
            "Train Epoch: 1960 \tLoss: 0.173260\n",
            "Train Epoch: 1965 \tLoss: 0.172744\n",
            "Train Epoch: 1970 \tLoss: 0.172230\n",
            "Train Epoch: 1975 \tLoss: 0.171719\n",
            "\n",
            "Test set: Avg. loss: 0.3466, Accuracy: 443/500 (89%)\n",
            "\n",
            "Train Epoch: 1980 \tLoss: 0.171210\n",
            "Train Epoch: 1985 \tLoss: 0.170703\n",
            "Train Epoch: 1990 \tLoss: 0.170199\n",
            "Train Epoch: 1995 \tLoss: 0.169698\n",
            "Train Epoch: 2000 \tLoss: 0.169198\n",
            "\n",
            "Test set: Avg. loss: 0.3443, Accuracy: 443/500 (89%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_n = 25\n",
        "test()\n",
        "count = []\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  if epoch % test_n == 0:\n",
        "    test()\n",
        "    count.append(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.arange(0,n_epochs)\n",
        "count = np.arange(0,n_epochs+test_n,test_n)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(x, train_losses, color='blue', zorder=1)\n",
        "plt.plot(count, test_losses, color='red', zorder=2)\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.xlabel('number of training examples seen')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the final weights to measure later their contribution:\n",
        "conv_1_final= network.conv1.weight.clone()\n",
        "conv_2_final =network.conv2.weight.clone()\n",
        "fc_1_final= network.fc1.weight.clone()\n",
        "fc_2_final= network.fc2.weight.clone()\n",
        "first_losses=test_losses.copy()\n",
        "test_losses.clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 1.5483, Accuracy: 303/500 (61%)\n",
            "\n",
            "\n",
            "Test set: Avg. loss: 1.0275, Accuracy: 428/500 (86%)\n",
            "\n",
            "\n",
            "Test set: Avg. loss: 0.4434, Accuracy: 430/500 (86%)\n",
            "\n",
            "\n",
            "Test set: Avg. loss: 1.2716, Accuracy: 279/500 (56%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# calculate the contribution of every layer\n",
        "\n",
        "with torch.no_grad():\n",
        "    network.fc1.weight[:] = fc1_init\n",
        "test()\n",
        "\n",
        "with torch.no_grad():\n",
        "    network.fc1.weight[:] = fc_1_final\n",
        "    network.fc2.weight[:] = fc2_init\n",
        "test()\n",
        "\n",
        "with torch.no_grad():\n",
        "    network.fc2.weight[:] = fc_2_final\n",
        "    network.conv1.weight[:] = conv1_init\n",
        "test()\n",
        "\n",
        "with torch.no_grad():\n",
        "    network.conv1.weight[:] = conv_1_final\n",
        "    network.conv2.weight[:] = conv2_init\n",
        "test()\n",
        "\n",
        "with torch.no_grad():\n",
        "    network.conv2.weight[:] = conv_2_final\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fc1 contribution is:  tensor(1.5483)\n",
            "fc2 contribution is:  tensor(1.0275)\n",
            "conv1 contribution is:  tensor(0.4434)\n",
            "conv2 contribution is:  tensor(1.2716)\n"
          ]
        }
      ],
      "source": [
        "print(\"fc1 contribution is: \",test_losses[0])\n",
        "\n",
        "print(\"fc2 contribution is: \",test_losses[1])\n",
        "\n",
        "print(\"conv1 contribution is: \",test_losses[2])\n",
        "\n",
        "print(\"conv2 contribution is: \",test_losses[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3176, Accuracy: 41/500 (8%)\n",
            "\n",
            "Train Epoch: 5 \tLoss: 2.311023\n",
            "Train Epoch: 10 \tLoss: 2.305203\n",
            "Train Epoch: 15 \tLoss: 2.299477\n",
            "Train Epoch: 20 \tLoss: 2.293839\n",
            "Train Epoch: 25 \tLoss: 2.288283\n",
            "\n",
            "Test set: Avg. loss: 2.2909, Accuracy: 54/500 (11%)\n",
            "\n",
            "Train Epoch: 30 \tLoss: 2.282804\n",
            "Train Epoch: 35 \tLoss: 2.277396\n",
            "Train Epoch: 40 \tLoss: 2.272056\n",
            "Train Epoch: 45 \tLoss: 2.266779\n",
            "Train Epoch: 50 \tLoss: 2.261562\n",
            "\n",
            "Test set: Avg. loss: 2.2661, Accuracy: 70/500 (14%)\n",
            "\n",
            "Train Epoch: 55 \tLoss: 2.256400\n",
            "Train Epoch: 60 \tLoss: 2.251292\n",
            "Train Epoch: 65 \tLoss: 2.246234\n",
            "Train Epoch: 70 \tLoss: 2.241223\n",
            "Train Epoch: 75 \tLoss: 2.236258\n",
            "\n",
            "Test set: Avg. loss: 2.2427, Accuracy: 98/500 (20%)\n",
            "\n",
            "Train Epoch: 80 \tLoss: 2.231335\n",
            "Train Epoch: 85 \tLoss: 2.226454\n",
            "Train Epoch: 90 \tLoss: 2.221612\n",
            "Train Epoch: 95 \tLoss: 2.216808\n",
            "Train Epoch: 100 \tLoss: 2.212039\n",
            "\n",
            "Test set: Avg. loss: 2.2204, Accuracy: 141/500 (28%)\n",
            "\n",
            "Train Epoch: 105 \tLoss: 2.207306\n",
            "Train Epoch: 110 \tLoss: 2.202606\n",
            "Train Epoch: 115 \tLoss: 2.197938\n",
            "Train Epoch: 120 \tLoss: 2.193302\n",
            "Train Epoch: 125 \tLoss: 2.188696\n",
            "\n",
            "Test set: Avg. loss: 2.1990, Accuracy: 173/500 (35%)\n",
            "\n",
            "Train Epoch: 130 \tLoss: 2.184120\n",
            "Train Epoch: 135 \tLoss: 2.179573\n",
            "Train Epoch: 140 \tLoss: 2.175053\n",
            "Train Epoch: 145 \tLoss: 2.170561\n",
            "Train Epoch: 150 \tLoss: 2.166095\n",
            "\n",
            "Test set: Avg. loss: 2.1783, Accuracy: 210/500 (42%)\n",
            "\n",
            "Train Epoch: 155 \tLoss: 2.161656\n",
            "Train Epoch: 160 \tLoss: 2.157242\n",
            "Train Epoch: 165 \tLoss: 2.152853\n",
            "Train Epoch: 170 \tLoss: 2.148489\n",
            "Train Epoch: 175 \tLoss: 2.144149\n",
            "\n",
            "Test set: Avg. loss: 2.1583, Accuracy: 236/500 (47%)\n",
            "\n",
            "Train Epoch: 180 \tLoss: 2.139833\n",
            "Train Epoch: 185 \tLoss: 2.135541\n",
            "Train Epoch: 190 \tLoss: 2.131273\n",
            "Train Epoch: 195 \tLoss: 2.127027\n",
            "Train Epoch: 200 \tLoss: 2.122803\n",
            "\n",
            "Test set: Avg. loss: 2.1389, Accuracy: 262/500 (52%)\n",
            "\n",
            "Train Epoch: 205 \tLoss: 2.118603\n",
            "Train Epoch: 210 \tLoss: 2.114424\n",
            "Train Epoch: 215 \tLoss: 2.110268\n",
            "Train Epoch: 220 \tLoss: 2.106133\n",
            "Train Epoch: 225 \tLoss: 2.102021\n",
            "\n",
            "Test set: Avg. loss: 2.1200, Accuracy: 284/500 (57%)\n",
            "\n",
            "Train Epoch: 230 \tLoss: 2.097929\n",
            "Train Epoch: 235 \tLoss: 2.093860\n",
            "Train Epoch: 240 \tLoss: 2.089811\n",
            "Train Epoch: 245 \tLoss: 2.085784\n",
            "Train Epoch: 250 \tLoss: 2.081777\n",
            "\n",
            "Test set: Avg. loss: 2.1016, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 255 \tLoss: 2.077791\n",
            "Train Epoch: 260 \tLoss: 2.073826\n",
            "Train Epoch: 265 \tLoss: 2.069881\n",
            "Train Epoch: 270 \tLoss: 2.065958\n",
            "Train Epoch: 275 \tLoss: 2.062054\n",
            "\n",
            "Test set: Avg. loss: 2.0838, Accuracy: 302/500 (60%)\n",
            "\n",
            "Train Epoch: 280 \tLoss: 2.058171\n",
            "Train Epoch: 285 \tLoss: 2.054308\n",
            "Train Epoch: 290 \tLoss: 2.050465\n",
            "Train Epoch: 295 \tLoss: 2.046642\n",
            "Train Epoch: 300 \tLoss: 2.042840\n",
            "\n",
            "Test set: Avg. loss: 2.0664, Accuracy: 311/500 (62%)\n",
            "\n",
            "Train Epoch: 305 \tLoss: 2.039057\n",
            "Train Epoch: 310 \tLoss: 2.035294\n",
            "Train Epoch: 315 \tLoss: 2.031551\n",
            "Train Epoch: 320 \tLoss: 2.027827\n",
            "Train Epoch: 325 \tLoss: 2.024123\n",
            "\n",
            "Test set: Avg. loss: 2.0495, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 330 \tLoss: 2.020439\n",
            "Train Epoch: 335 \tLoss: 2.016774\n",
            "Train Epoch: 340 \tLoss: 2.013129\n",
            "Train Epoch: 345 \tLoss: 2.009503\n",
            "Train Epoch: 350 \tLoss: 2.005896\n",
            "\n",
            "Test set: Avg. loss: 2.0331, Accuracy: 319/500 (64%)\n",
            "\n",
            "Train Epoch: 355 \tLoss: 2.002309\n",
            "Train Epoch: 360 \tLoss: 1.998740\n",
            "Train Epoch: 365 \tLoss: 1.995191\n",
            "Train Epoch: 370 \tLoss: 1.991661\n",
            "Train Epoch: 375 \tLoss: 1.988149\n",
            "\n",
            "Test set: Avg. loss: 2.0172, Accuracy: 322/500 (64%)\n",
            "\n",
            "Train Epoch: 380 \tLoss: 1.984657\n",
            "Train Epoch: 385 \tLoss: 1.981183\n",
            "Train Epoch: 390 \tLoss: 1.977728\n",
            "Train Epoch: 395 \tLoss: 1.974292\n",
            "Train Epoch: 400 \tLoss: 1.970874\n",
            "\n",
            "Test set: Avg. loss: 2.0017, Accuracy: 324/500 (65%)\n",
            "\n",
            "Train Epoch: 405 \tLoss: 1.967475\n",
            "Train Epoch: 410 \tLoss: 1.964094\n",
            "Train Epoch: 415 \tLoss: 1.960732\n",
            "Train Epoch: 420 \tLoss: 1.957388\n",
            "Train Epoch: 425 \tLoss: 1.954062\n",
            "\n",
            "Test set: Avg. loss: 1.9866, Accuracy: 326/500 (65%)\n",
            "\n",
            "Train Epoch: 430 \tLoss: 1.950754\n",
            "Train Epoch: 435 \tLoss: 1.947464\n",
            "Train Epoch: 440 \tLoss: 1.944192\n",
            "Train Epoch: 445 \tLoss: 1.940938\n",
            "Train Epoch: 450 \tLoss: 1.937702\n",
            "\n",
            "Test set: Avg. loss: 1.9719, Accuracy: 328/500 (66%)\n",
            "\n",
            "Train Epoch: 455 \tLoss: 1.934483\n",
            "Train Epoch: 460 \tLoss: 1.931282\n",
            "Train Epoch: 465 \tLoss: 1.928099\n",
            "Train Epoch: 470 \tLoss: 1.924933\n",
            "Train Epoch: 475 \tLoss: 1.921784\n",
            "\n",
            "Test set: Avg. loss: 1.9577, Accuracy: 327/500 (65%)\n",
            "\n",
            "Train Epoch: 480 \tLoss: 1.918653\n",
            "Train Epoch: 485 \tLoss: 1.915539\n",
            "Train Epoch: 490 \tLoss: 1.912442\n",
            "Train Epoch: 495 \tLoss: 1.909362\n",
            "Train Epoch: 500 \tLoss: 1.906298\n",
            "\n",
            "Test set: Avg. loss: 1.9439, Accuracy: 328/500 (66%)\n",
            "\n",
            "Train Epoch: 505 \tLoss: 1.903252\n",
            "Train Epoch: 510 \tLoss: 1.900222\n",
            "Train Epoch: 515 \tLoss: 1.897209\n",
            "Train Epoch: 520 \tLoss: 1.894213\n",
            "Train Epoch: 525 \tLoss: 1.891233\n",
            "\n",
            "Test set: Avg. loss: 1.9304, Accuracy: 329/500 (66%)\n",
            "\n",
            "Train Epoch: 530 \tLoss: 1.888269\n",
            "Train Epoch: 535 \tLoss: 1.885322\n",
            "Train Epoch: 540 \tLoss: 1.882390\n",
            "Train Epoch: 545 \tLoss: 1.879475\n",
            "Train Epoch: 550 \tLoss: 1.876576\n",
            "\n",
            "Test set: Avg. loss: 1.9174, Accuracy: 331/500 (66%)\n",
            "\n",
            "Train Epoch: 555 \tLoss: 1.873692\n",
            "Train Epoch: 560 \tLoss: 1.870825\n",
            "Train Epoch: 565 \tLoss: 1.867973\n",
            "Train Epoch: 570 \tLoss: 1.865136\n",
            "Train Epoch: 575 \tLoss: 1.862315\n",
            "\n",
            "Test set: Avg. loss: 1.9047, Accuracy: 332/500 (66%)\n",
            "\n",
            "Train Epoch: 580 \tLoss: 1.859510\n",
            "Train Epoch: 585 \tLoss: 1.856719\n",
            "Train Epoch: 590 \tLoss: 1.853944\n",
            "Train Epoch: 595 \tLoss: 1.851185\n",
            "Train Epoch: 600 \tLoss: 1.848440\n",
            "\n",
            "Test set: Avg. loss: 1.8923, Accuracy: 334/500 (67%)\n",
            "\n",
            "Train Epoch: 605 \tLoss: 1.845709\n",
            "Train Epoch: 610 \tLoss: 1.842994\n",
            "Train Epoch: 615 \tLoss: 1.840294\n",
            "Train Epoch: 620 \tLoss: 1.837608\n",
            "Train Epoch: 625 \tLoss: 1.834936\n",
            "\n",
            "Test set: Avg. loss: 1.8803, Accuracy: 334/500 (67%)\n",
            "\n",
            "Train Epoch: 630 \tLoss: 1.832280\n",
            "Train Epoch: 635 \tLoss: 1.829637\n",
            "Train Epoch: 640 \tLoss: 1.827008\n",
            "Train Epoch: 645 \tLoss: 1.824394\n",
            "Train Epoch: 650 \tLoss: 1.821794\n",
            "\n",
            "Test set: Avg. loss: 1.8687, Accuracy: 334/500 (67%)\n",
            "\n",
            "Train Epoch: 655 \tLoss: 1.819208\n",
            "Train Epoch: 660 \tLoss: 1.816635\n",
            "Train Epoch: 665 \tLoss: 1.814077\n",
            "Train Epoch: 670 \tLoss: 1.811532\n",
            "Train Epoch: 675 \tLoss: 1.809001\n",
            "\n",
            "Test set: Avg. loss: 1.8573, Accuracy: 335/500 (67%)\n",
            "\n",
            "Train Epoch: 680 \tLoss: 1.806483\n",
            "Train Epoch: 685 \tLoss: 1.803978\n",
            "Train Epoch: 690 \tLoss: 1.801487\n",
            "Train Epoch: 695 \tLoss: 1.799009\n",
            "Train Epoch: 700 \tLoss: 1.796545\n",
            "\n",
            "Test set: Avg. loss: 1.8463, Accuracy: 338/500 (68%)\n",
            "\n",
            "Train Epoch: 705 \tLoss: 1.794093\n",
            "Train Epoch: 710 \tLoss: 1.791654\n",
            "Train Epoch: 715 \tLoss: 1.789228\n",
            "Train Epoch: 720 \tLoss: 1.786815\n",
            "Train Epoch: 725 \tLoss: 1.784414\n",
            "\n",
            "Test set: Avg. loss: 1.8355, Accuracy: 337/500 (67%)\n",
            "\n",
            "Train Epoch: 730 \tLoss: 1.782027\n",
            "Train Epoch: 735 \tLoss: 1.779651\n",
            "Train Epoch: 740 \tLoss: 1.777288\n",
            "Train Epoch: 745 \tLoss: 1.774938\n",
            "Train Epoch: 750 \tLoss: 1.772599\n",
            "\n",
            "Test set: Avg. loss: 1.8251, Accuracy: 336/500 (67%)\n",
            "\n",
            "Train Epoch: 755 \tLoss: 1.770273\n",
            "Train Epoch: 760 \tLoss: 1.767959\n",
            "Train Epoch: 765 \tLoss: 1.765657\n",
            "Train Epoch: 770 \tLoss: 1.763367\n",
            "Train Epoch: 775 \tLoss: 1.761088\n",
            "\n",
            "Test set: Avg. loss: 1.8149, Accuracy: 339/500 (68%)\n",
            "\n",
            "Train Epoch: 780 \tLoss: 1.758822\n",
            "Train Epoch: 785 \tLoss: 1.756567\n",
            "Train Epoch: 790 \tLoss: 1.754323\n",
            "Train Epoch: 795 \tLoss: 1.752091\n",
            "Train Epoch: 800 \tLoss: 1.749871\n",
            "\n",
            "Test set: Avg. loss: 1.8050, Accuracy: 340/500 (68%)\n",
            "\n",
            "Train Epoch: 805 \tLoss: 1.747662\n",
            "Train Epoch: 810 \tLoss: 1.745464\n",
            "Train Epoch: 815 \tLoss: 1.743278\n",
            "Train Epoch: 820 \tLoss: 1.741102\n",
            "Train Epoch: 825 \tLoss: 1.738938\n",
            "\n",
            "Test set: Avg. loss: 1.7953, Accuracy: 341/500 (68%)\n",
            "\n",
            "Train Epoch: 830 \tLoss: 1.736784\n",
            "Train Epoch: 835 \tLoss: 1.734642\n",
            "Train Epoch: 840 \tLoss: 1.732510\n",
            "Train Epoch: 845 \tLoss: 1.730389\n",
            "Train Epoch: 850 \tLoss: 1.728278\n",
            "\n",
            "Test set: Avg. loss: 1.7859, Accuracy: 342/500 (68%)\n",
            "\n",
            "Train Epoch: 855 \tLoss: 1.726178\n",
            "Train Epoch: 860 \tLoss: 1.724089\n",
            "Train Epoch: 865 \tLoss: 1.722010\n",
            "Train Epoch: 870 \tLoss: 1.719941\n",
            "Train Epoch: 875 \tLoss: 1.717883\n",
            "\n",
            "Test set: Avg. loss: 1.7767, Accuracy: 342/500 (68%)\n",
            "\n",
            "Train Epoch: 880 \tLoss: 1.715835\n",
            "Train Epoch: 885 \tLoss: 1.713797\n",
            "Train Epoch: 890 \tLoss: 1.711769\n",
            "Train Epoch: 895 \tLoss: 1.709752\n",
            "Train Epoch: 900 \tLoss: 1.707744\n",
            "\n",
            "Test set: Avg. loss: 1.7678, Accuracy: 342/500 (68%)\n",
            "\n",
            "Train Epoch: 905 \tLoss: 1.705745\n",
            "Train Epoch: 910 \tLoss: 1.703757\n",
            "Train Epoch: 915 \tLoss: 1.701779\n",
            "Train Epoch: 920 \tLoss: 1.699810\n",
            "Train Epoch: 925 \tLoss: 1.697851\n",
            "\n",
            "Test set: Avg. loss: 1.7591, Accuracy: 342/500 (68%)\n",
            "\n",
            "Train Epoch: 930 \tLoss: 1.695901\n",
            "Train Epoch: 935 \tLoss: 1.693961\n",
            "Train Epoch: 940 \tLoss: 1.692030\n",
            "Train Epoch: 945 \tLoss: 1.690108\n",
            "Train Epoch: 950 \tLoss: 1.688196\n",
            "\n",
            "Test set: Avg. loss: 1.7506, Accuracy: 341/500 (68%)\n",
            "\n",
            "Train Epoch: 955 \tLoss: 1.686293\n",
            "Train Epoch: 960 \tLoss: 1.684399\n",
            "Train Epoch: 965 \tLoss: 1.682514\n",
            "Train Epoch: 970 \tLoss: 1.680638\n",
            "Train Epoch: 975 \tLoss: 1.678771\n",
            "\n",
            "Test set: Avg. loss: 1.7423, Accuracy: 343/500 (69%)\n",
            "\n",
            "Train Epoch: 980 \tLoss: 1.676913\n",
            "Train Epoch: 985 \tLoss: 1.675064\n",
            "Train Epoch: 990 \tLoss: 1.673223\n",
            "Train Epoch: 995 \tLoss: 1.671391\n",
            "Train Epoch: 1000 \tLoss: 1.669568\n",
            "\n",
            "Test set: Avg. loss: 1.7342, Accuracy: 344/500 (69%)\n",
            "\n",
            "Train Epoch: 1005 \tLoss: 1.667754\n",
            "Train Epoch: 1010 \tLoss: 1.665948\n",
            "Train Epoch: 1015 \tLoss: 1.664150\n",
            "Train Epoch: 1020 \tLoss: 1.662361\n",
            "Train Epoch: 1025 \tLoss: 1.660580\n",
            "\n",
            "Test set: Avg. loss: 1.7263, Accuracy: 344/500 (69%)\n",
            "\n",
            "Train Epoch: 1030 \tLoss: 1.658808\n",
            "Train Epoch: 1035 \tLoss: 1.657044\n",
            "Train Epoch: 1040 \tLoss: 1.655288\n",
            "Train Epoch: 1045 \tLoss: 1.653539\n",
            "Train Epoch: 1050 \tLoss: 1.651800\n",
            "\n",
            "Test set: Avg. loss: 1.7186, Accuracy: 345/500 (69%)\n",
            "\n",
            "Train Epoch: 1055 \tLoss: 1.650067\n",
            "Train Epoch: 1060 \tLoss: 1.648344\n",
            "Train Epoch: 1065 \tLoss: 1.646627\n",
            "Train Epoch: 1070 \tLoss: 1.644919\n",
            "Train Epoch: 1075 \tLoss: 1.643219\n",
            "\n",
            "Test set: Avg. loss: 1.7110, Accuracy: 346/500 (69%)\n",
            "\n",
            "Train Epoch: 1080 \tLoss: 1.641526\n",
            "Train Epoch: 1085 \tLoss: 1.639841\n",
            "Train Epoch: 1090 \tLoss: 1.638164\n",
            "Train Epoch: 1095 \tLoss: 1.636494\n",
            "Train Epoch: 1100 \tLoss: 1.634831\n",
            "\n",
            "Test set: Avg. loss: 1.7037, Accuracy: 346/500 (69%)\n",
            "\n",
            "Train Epoch: 1105 \tLoss: 1.633177\n",
            "Train Epoch: 1110 \tLoss: 1.631529\n",
            "Train Epoch: 1115 \tLoss: 1.629889\n",
            "Train Epoch: 1120 \tLoss: 1.628256\n",
            "Train Epoch: 1125 \tLoss: 1.626631\n",
            "\n",
            "Test set: Avg. loss: 1.6965, Accuracy: 346/500 (69%)\n",
            "\n",
            "Train Epoch: 1130 \tLoss: 1.625013\n",
            "Train Epoch: 1135 \tLoss: 1.623402\n",
            "Train Epoch: 1140 \tLoss: 1.621798\n",
            "Train Epoch: 1145 \tLoss: 1.620201\n",
            "Train Epoch: 1150 \tLoss: 1.618612\n",
            "\n",
            "Test set: Avg. loss: 1.6894, Accuracy: 347/500 (69%)\n",
            "\n",
            "Train Epoch: 1155 \tLoss: 1.617029\n",
            "Train Epoch: 1160 \tLoss: 1.615453\n",
            "Train Epoch: 1165 \tLoss: 1.613884\n",
            "Train Epoch: 1170 \tLoss: 1.612322\n",
            "Train Epoch: 1175 \tLoss: 1.610766\n",
            "\n",
            "Test set: Avg. loss: 1.6825, Accuracy: 347/500 (69%)\n",
            "\n",
            "Train Epoch: 1180 \tLoss: 1.609218\n",
            "Train Epoch: 1185 \tLoss: 1.607676\n",
            "Train Epoch: 1190 \tLoss: 1.606141\n",
            "Train Epoch: 1195 \tLoss: 1.604612\n",
            "Train Epoch: 1200 \tLoss: 1.603090\n",
            "\n",
            "Test set: Avg. loss: 1.6758, Accuracy: 347/500 (69%)\n",
            "\n",
            "Train Epoch: 1205 \tLoss: 1.601575\n",
            "Train Epoch: 1210 \tLoss: 1.600066\n",
            "Train Epoch: 1215 \tLoss: 1.598564\n",
            "Train Epoch: 1220 \tLoss: 1.597067\n",
            "Train Epoch: 1225 \tLoss: 1.595578\n",
            "\n",
            "Test set: Avg. loss: 1.6692, Accuracy: 346/500 (69%)\n",
            "\n",
            "Train Epoch: 1230 \tLoss: 1.594094\n",
            "Train Epoch: 1235 \tLoss: 1.592617\n",
            "Train Epoch: 1240 \tLoss: 1.591146\n",
            "Train Epoch: 1245 \tLoss: 1.589682\n",
            "Train Epoch: 1250 \tLoss: 1.588223\n",
            "\n",
            "Test set: Avg. loss: 1.6628, Accuracy: 346/500 (69%)\n",
            "\n",
            "Train Epoch: 1255 \tLoss: 1.586771\n",
            "Train Epoch: 1260 \tLoss: 1.585324\n",
            "Train Epoch: 1265 \tLoss: 1.583884\n",
            "Train Epoch: 1270 \tLoss: 1.582450\n",
            "Train Epoch: 1275 \tLoss: 1.581021\n",
            "\n",
            "Test set: Avg. loss: 1.6565, Accuracy: 347/500 (69%)\n",
            "\n",
            "Train Epoch: 1280 \tLoss: 1.579599\n",
            "Train Epoch: 1285 \tLoss: 1.578182\n",
            "Train Epoch: 1290 \tLoss: 1.576772\n",
            "Train Epoch: 1295 \tLoss: 1.575367\n",
            "Train Epoch: 1300 \tLoss: 1.573968\n",
            "\n",
            "Test set: Avg. loss: 1.6503, Accuracy: 347/500 (69%)\n",
            "\n",
            "Train Epoch: 1305 \tLoss: 1.572574\n",
            "Train Epoch: 1310 \tLoss: 1.571187\n",
            "Train Epoch: 1315 \tLoss: 1.569804\n",
            "Train Epoch: 1320 \tLoss: 1.568428\n",
            "Train Epoch: 1325 \tLoss: 1.567057\n",
            "\n",
            "Test set: Avg. loss: 1.6443, Accuracy: 348/500 (70%)\n",
            "\n",
            "Train Epoch: 1330 \tLoss: 1.565692\n",
            "Train Epoch: 1335 \tLoss: 1.564332\n",
            "Train Epoch: 1340 \tLoss: 1.562978\n",
            "Train Epoch: 1345 \tLoss: 1.561629\n",
            "Train Epoch: 1350 \tLoss: 1.560286\n",
            "\n",
            "Test set: Avg. loss: 1.6383, Accuracy: 348/500 (70%)\n",
            "\n",
            "Train Epoch: 1355 \tLoss: 1.558947\n",
            "Train Epoch: 1360 \tLoss: 1.557615\n",
            "Train Epoch: 1365 \tLoss: 1.556288\n",
            "Train Epoch: 1370 \tLoss: 1.554965\n",
            "Train Epoch: 1375 \tLoss: 1.553648\n",
            "\n",
            "Test set: Avg. loss: 1.6325, Accuracy: 348/500 (70%)\n",
            "\n",
            "Train Epoch: 1380 \tLoss: 1.552336\n",
            "Train Epoch: 1385 \tLoss: 1.551030\n",
            "Train Epoch: 1390 \tLoss: 1.549729\n",
            "Train Epoch: 1395 \tLoss: 1.548432\n",
            "Train Epoch: 1400 \tLoss: 1.547141\n",
            "\n",
            "Test set: Avg. loss: 1.6268, Accuracy: 348/500 (70%)\n",
            "\n",
            "Train Epoch: 1405 \tLoss: 1.545855\n",
            "Train Epoch: 1410 \tLoss: 1.544574\n",
            "Train Epoch: 1415 \tLoss: 1.543298\n",
            "Train Epoch: 1420 \tLoss: 1.542027\n",
            "Train Epoch: 1425 \tLoss: 1.540761\n",
            "\n",
            "Test set: Avg. loss: 1.6213, Accuracy: 349/500 (70%)\n",
            "\n",
            "Train Epoch: 1430 \tLoss: 1.539499\n",
            "Train Epoch: 1435 \tLoss: 1.538243\n",
            "Train Epoch: 1440 \tLoss: 1.536991\n",
            "Train Epoch: 1445 \tLoss: 1.535744\n",
            "Train Epoch: 1450 \tLoss: 1.534502\n",
            "\n",
            "Test set: Avg. loss: 1.6158, Accuracy: 349/500 (70%)\n",
            "\n",
            "Train Epoch: 1455 \tLoss: 1.533265\n",
            "Train Epoch: 1460 \tLoss: 1.532032\n",
            "Train Epoch: 1465 \tLoss: 1.530804\n",
            "Train Epoch: 1470 \tLoss: 1.529581\n",
            "Train Epoch: 1475 \tLoss: 1.528362\n",
            "\n",
            "Test set: Avg. loss: 1.6104, Accuracy: 349/500 (70%)\n",
            "\n",
            "Train Epoch: 1480 \tLoss: 1.527148\n",
            "Train Epoch: 1485 \tLoss: 1.525939\n",
            "Train Epoch: 1490 \tLoss: 1.524734\n",
            "Train Epoch: 1495 \tLoss: 1.523533\n",
            "Train Epoch: 1500 \tLoss: 1.522337\n",
            "\n",
            "Test set: Avg. loss: 1.6052, Accuracy: 350/500 (70%)\n",
            "\n",
            "Train Epoch: 1505 \tLoss: 1.521146\n",
            "Train Epoch: 1510 \tLoss: 1.519959\n",
            "Train Epoch: 1515 \tLoss: 1.518777\n",
            "Train Epoch: 1520 \tLoss: 1.517598\n",
            "Train Epoch: 1525 \tLoss: 1.516425\n",
            "\n",
            "Test set: Avg. loss: 1.6000, Accuracy: 351/500 (70%)\n",
            "\n",
            "Train Epoch: 1530 \tLoss: 1.515255\n",
            "Train Epoch: 1535 \tLoss: 1.514090\n",
            "Train Epoch: 1540 \tLoss: 1.512929\n",
            "Train Epoch: 1545 \tLoss: 1.511772\n",
            "Train Epoch: 1550 \tLoss: 1.510620\n",
            "\n",
            "Test set: Avg. loss: 1.5949, Accuracy: 351/500 (70%)\n",
            "\n",
            "Train Epoch: 1555 \tLoss: 1.509472\n",
            "Train Epoch: 1560 \tLoss: 1.508327\n",
            "Train Epoch: 1565 \tLoss: 1.507188\n",
            "Train Epoch: 1570 \tLoss: 1.506052\n",
            "Train Epoch: 1575 \tLoss: 1.504920\n",
            "\n",
            "Test set: Avg. loss: 1.5900, Accuracy: 351/500 (70%)\n",
            "\n",
            "Train Epoch: 1580 \tLoss: 1.503793\n",
            "Train Epoch: 1585 \tLoss: 1.502669\n",
            "Train Epoch: 1590 \tLoss: 1.501550\n",
            "Train Epoch: 1595 \tLoss: 1.500434\n",
            "Train Epoch: 1600 \tLoss: 1.499323\n",
            "\n",
            "Test set: Avg. loss: 1.5851, Accuracy: 351/500 (70%)\n",
            "\n",
            "Train Epoch: 1605 \tLoss: 1.498215\n",
            "Train Epoch: 1610 \tLoss: 1.497112\n",
            "Train Epoch: 1615 \tLoss: 1.496012\n",
            "Train Epoch: 1620 \tLoss: 1.494917\n",
            "Train Epoch: 1625 \tLoss: 1.493825\n",
            "\n",
            "Test set: Avg. loss: 1.5803, Accuracy: 352/500 (70%)\n",
            "\n",
            "Train Epoch: 1630 \tLoss: 1.492737\n",
            "Train Epoch: 1635 \tLoss: 1.491653\n",
            "Train Epoch: 1640 \tLoss: 1.490573\n",
            "Train Epoch: 1645 \tLoss: 1.489496\n",
            "Train Epoch: 1650 \tLoss: 1.488423\n",
            "\n",
            "Test set: Avg. loss: 1.5756, Accuracy: 354/500 (71%)\n",
            "\n",
            "Train Epoch: 1655 \tLoss: 1.487354\n",
            "Train Epoch: 1660 \tLoss: 1.486289\n",
            "Train Epoch: 1665 \tLoss: 1.485227\n",
            "Train Epoch: 1670 \tLoss: 1.484170\n",
            "Train Epoch: 1675 \tLoss: 1.483115\n",
            "\n",
            "Test set: Avg. loss: 1.5709, Accuracy: 354/500 (71%)\n",
            "\n",
            "Train Epoch: 1680 \tLoss: 1.482065\n",
            "Train Epoch: 1685 \tLoss: 1.481018\n",
            "Train Epoch: 1690 \tLoss: 1.479975\n",
            "Train Epoch: 1695 \tLoss: 1.478935\n",
            "Train Epoch: 1700 \tLoss: 1.477898\n",
            "\n",
            "Test set: Avg. loss: 1.5664, Accuracy: 354/500 (71%)\n",
            "\n",
            "Train Epoch: 1705 \tLoss: 1.476866\n",
            "Train Epoch: 1710 \tLoss: 1.475836\n",
            "Train Epoch: 1715 \tLoss: 1.474811\n",
            "Train Epoch: 1720 \tLoss: 1.473789\n",
            "Train Epoch: 1725 \tLoss: 1.472770\n",
            "\n",
            "Test set: Avg. loss: 1.5619, Accuracy: 355/500 (71%)\n",
            "\n",
            "Train Epoch: 1730 \tLoss: 1.471755\n",
            "Train Epoch: 1735 \tLoss: 1.470743\n",
            "Train Epoch: 1740 \tLoss: 1.469735\n",
            "Train Epoch: 1745 \tLoss: 1.468729\n",
            "Train Epoch: 1750 \tLoss: 1.467728\n",
            "\n",
            "Test set: Avg. loss: 1.5575, Accuracy: 355/500 (71%)\n",
            "\n",
            "Train Epoch: 1755 \tLoss: 1.466730\n",
            "Train Epoch: 1760 \tLoss: 1.465734\n",
            "Train Epoch: 1765 \tLoss: 1.464743\n",
            "Train Epoch: 1770 \tLoss: 1.463754\n",
            "Train Epoch: 1775 \tLoss: 1.462769\n",
            "\n",
            "Test set: Avg. loss: 1.5532, Accuracy: 356/500 (71%)\n",
            "\n",
            "Train Epoch: 1780 \tLoss: 1.461787\n",
            "Train Epoch: 1785 \tLoss: 1.460809\n",
            "Train Epoch: 1790 \tLoss: 1.459834\n",
            "Train Epoch: 1795 \tLoss: 1.458861\n",
            "Train Epoch: 1800 \tLoss: 1.457892\n",
            "\n",
            "Test set: Avg. loss: 1.5490, Accuracy: 357/500 (71%)\n",
            "\n",
            "Train Epoch: 1805 \tLoss: 1.456927\n",
            "Train Epoch: 1810 \tLoss: 1.455964\n",
            "Train Epoch: 1815 \tLoss: 1.455005\n",
            "Train Epoch: 1820 \tLoss: 1.454048\n",
            "Train Epoch: 1825 \tLoss: 1.453095\n",
            "\n",
            "Test set: Avg. loss: 1.5448, Accuracy: 358/500 (72%)\n",
            "\n",
            "Train Epoch: 1830 \tLoss: 1.452145\n",
            "Train Epoch: 1835 \tLoss: 1.451198\n",
            "Train Epoch: 1840 \tLoss: 1.450253\n",
            "Train Epoch: 1845 \tLoss: 1.449312\n",
            "Train Epoch: 1850 \tLoss: 1.448375\n",
            "\n",
            "Test set: Avg. loss: 1.5407, Accuracy: 358/500 (72%)\n",
            "\n",
            "Train Epoch: 1855 \tLoss: 1.447440\n",
            "Train Epoch: 1860 \tLoss: 1.446508\n",
            "Train Epoch: 1865 \tLoss: 1.445579\n",
            "Train Epoch: 1870 \tLoss: 1.444652\n",
            "Train Epoch: 1875 \tLoss: 1.443730\n",
            "\n",
            "Test set: Avg. loss: 1.5366, Accuracy: 358/500 (72%)\n",
            "\n",
            "Train Epoch: 1880 \tLoss: 1.442809\n",
            "Train Epoch: 1885 \tLoss: 1.441892\n",
            "Train Epoch: 1890 \tLoss: 1.440978\n",
            "Train Epoch: 1895 \tLoss: 1.440066\n",
            "Train Epoch: 1900 \tLoss: 1.439158\n",
            "\n",
            "Test set: Avg. loss: 1.5326, Accuracy: 359/500 (72%)\n",
            "\n",
            "Train Epoch: 1905 \tLoss: 1.438252\n",
            "Train Epoch: 1910 \tLoss: 1.437349\n",
            "Train Epoch: 1915 \tLoss: 1.436449\n",
            "Train Epoch: 1920 \tLoss: 1.435552\n",
            "Train Epoch: 1925 \tLoss: 1.434657\n",
            "\n",
            "Test set: Avg. loss: 1.5287, Accuracy: 359/500 (72%)\n",
            "\n",
            "Train Epoch: 1930 \tLoss: 1.433766\n",
            "Train Epoch: 1935 \tLoss: 1.432877\n",
            "Train Epoch: 1940 \tLoss: 1.431991\n",
            "Train Epoch: 1945 \tLoss: 1.431107\n",
            "Train Epoch: 1950 \tLoss: 1.430227\n",
            "\n",
            "Test set: Avg. loss: 1.5249, Accuracy: 360/500 (72%)\n",
            "\n",
            "Train Epoch: 1955 \tLoss: 1.429348\n",
            "Train Epoch: 1960 \tLoss: 1.428473\n",
            "Train Epoch: 1965 \tLoss: 1.427601\n",
            "Train Epoch: 1970 \tLoss: 1.426731\n",
            "Train Epoch: 1975 \tLoss: 1.425864\n",
            "\n",
            "Test set: Avg. loss: 1.5211, Accuracy: 361/500 (72%)\n",
            "\n",
            "Train Epoch: 1980 \tLoss: 1.424999\n",
            "Train Epoch: 1985 \tLoss: 1.424137\n",
            "Train Epoch: 1990 \tLoss: 1.423277\n",
            "Train Epoch: 1995 \tLoss: 1.422421\n",
            "Train Epoch: 2000 \tLoss: 1.421567\n",
            "\n",
            "Test set: Avg. loss: 1.5173, Accuracy: 361/500 (72%)\n",
            "\n",
            "Train Epoch: 2005 \tLoss: 1.420715\n",
            "Train Epoch: 2010 \tLoss: 1.419866\n",
            "Train Epoch: 2015 \tLoss: 1.419019\n",
            "Train Epoch: 2020 \tLoss: 1.418176\n",
            "Train Epoch: 2025 \tLoss: 1.417334\n",
            "\n",
            "Test set: Avg. loss: 1.5136, Accuracy: 361/500 (72%)\n",
            "\n",
            "Train Epoch: 2030 \tLoss: 1.416495\n",
            "Train Epoch: 2035 \tLoss: 1.415659\n",
            "Train Epoch: 2040 \tLoss: 1.414825\n",
            "Train Epoch: 2045 \tLoss: 1.413993\n",
            "Train Epoch: 2050 \tLoss: 1.413164\n",
            "\n",
            "Test set: Avg. loss: 1.5100, Accuracy: 360/500 (72%)\n",
            "\n",
            "Train Epoch: 2055 \tLoss: 1.412338\n",
            "Train Epoch: 2060 \tLoss: 1.411514\n",
            "Train Epoch: 2065 \tLoss: 1.410692\n",
            "Train Epoch: 2070 \tLoss: 1.409873\n",
            "Train Epoch: 2075 \tLoss: 1.409056\n",
            "\n",
            "Test set: Avg. loss: 1.5064, Accuracy: 360/500 (72%)\n",
            "\n",
            "Train Epoch: 2080 \tLoss: 1.408242\n",
            "Train Epoch: 2085 \tLoss: 1.407430\n",
            "Train Epoch: 2090 \tLoss: 1.406620\n",
            "Train Epoch: 2095 \tLoss: 1.405813\n",
            "Train Epoch: 2100 \tLoss: 1.405008\n",
            "\n",
            "Test set: Avg. loss: 1.5029, Accuracy: 360/500 (72%)\n",
            "\n",
            "Train Epoch: 2105 \tLoss: 1.404205\n",
            "Train Epoch: 2110 \tLoss: 1.403405\n",
            "Train Epoch: 2115 \tLoss: 1.402607\n",
            "Train Epoch: 2120 \tLoss: 1.401811\n",
            "Train Epoch: 2125 \tLoss: 1.401018\n",
            "\n",
            "Test set: Avg. loss: 1.4994, Accuracy: 360/500 (72%)\n",
            "\n",
            "Train Epoch: 2130 \tLoss: 1.400227\n",
            "Train Epoch: 2135 \tLoss: 1.399438\n",
            "Train Epoch: 2140 \tLoss: 1.398651\n",
            "Train Epoch: 2145 \tLoss: 1.397867\n",
            "Train Epoch: 2150 \tLoss: 1.397085\n",
            "\n",
            "Test set: Avg. loss: 1.4960, Accuracy: 360/500 (72%)\n",
            "\n",
            "Train Epoch: 2155 \tLoss: 1.396305\n",
            "Train Epoch: 2160 \tLoss: 1.395528\n",
            "Train Epoch: 2165 \tLoss: 1.394752\n",
            "Train Epoch: 2170 \tLoss: 1.393979\n",
            "Train Epoch: 2175 \tLoss: 1.393208\n",
            "\n",
            "Test set: Avg. loss: 1.4926, Accuracy: 360/500 (72%)\n",
            "\n",
            "Train Epoch: 2180 \tLoss: 1.392439\n",
            "Train Epoch: 2185 \tLoss: 1.391672\n",
            "Train Epoch: 2190 \tLoss: 1.390908\n",
            "Train Epoch: 2195 \tLoss: 1.390145\n",
            "Train Epoch: 2200 \tLoss: 1.389385\n",
            "\n",
            "Test set: Avg. loss: 1.4893, Accuracy: 361/500 (72%)\n",
            "\n",
            "Train Epoch: 2205 \tLoss: 1.388627\n",
            "Train Epoch: 2210 \tLoss: 1.387871\n",
            "Train Epoch: 2215 \tLoss: 1.387117\n",
            "Train Epoch: 2220 \tLoss: 1.386365\n",
            "Train Epoch: 2225 \tLoss: 1.385615\n",
            "\n",
            "Test set: Avg. loss: 1.4860, Accuracy: 362/500 (72%)\n",
            "\n",
            "Train Epoch: 2230 \tLoss: 1.384868\n",
            "Train Epoch: 2235 \tLoss: 1.384122\n",
            "Train Epoch: 2240 \tLoss: 1.383379\n",
            "Train Epoch: 2245 \tLoss: 1.382637\n",
            "Train Epoch: 2250 \tLoss: 1.381898\n",
            "\n",
            "Test set: Avg. loss: 1.4828, Accuracy: 362/500 (72%)\n",
            "\n",
            "Train Epoch: 2255 \tLoss: 1.381160\n",
            "Train Epoch: 2260 \tLoss: 1.380425\n",
            "Train Epoch: 2265 \tLoss: 1.379691\n",
            "Train Epoch: 2270 \tLoss: 1.378960\n",
            "Train Epoch: 2275 \tLoss: 1.378230\n",
            "\n",
            "Test set: Avg. loss: 1.4796, Accuracy: 362/500 (72%)\n",
            "\n",
            "Train Epoch: 2280 \tLoss: 1.377503\n",
            "Train Epoch: 2285 \tLoss: 1.376778\n",
            "Train Epoch: 2290 \tLoss: 1.376054\n",
            "Train Epoch: 2295 \tLoss: 1.375332\n",
            "Train Epoch: 2300 \tLoss: 1.374613\n",
            "\n",
            "Test set: Avg. loss: 1.4765, Accuracy: 363/500 (73%)\n",
            "\n",
            "Train Epoch: 2305 \tLoss: 1.373895\n",
            "Train Epoch: 2310 \tLoss: 1.373179\n",
            "Train Epoch: 2315 \tLoss: 1.372466\n",
            "Train Epoch: 2320 \tLoss: 1.371754\n",
            "Train Epoch: 2325 \tLoss: 1.371044\n",
            "\n",
            "Test set: Avg. loss: 1.4734, Accuracy: 363/500 (73%)\n",
            "\n",
            "Train Epoch: 2330 \tLoss: 1.370336\n",
            "Train Epoch: 2335 \tLoss: 1.369630\n",
            "Train Epoch: 2340 \tLoss: 1.368925\n",
            "Train Epoch: 2345 \tLoss: 1.368223\n",
            "Train Epoch: 2350 \tLoss: 1.367522\n",
            "\n",
            "Test set: Avg. loss: 1.4703, Accuracy: 363/500 (73%)\n",
            "\n",
            "Train Epoch: 2355 \tLoss: 1.366823\n",
            "Train Epoch: 2360 \tLoss: 1.366127\n",
            "Train Epoch: 2365 \tLoss: 1.365432\n",
            "Train Epoch: 2370 \tLoss: 1.364738\n",
            "Train Epoch: 2375 \tLoss: 1.364047\n",
            "\n",
            "Test set: Avg. loss: 1.4673, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2380 \tLoss: 1.363357\n",
            "Train Epoch: 2385 \tLoss: 1.362669\n",
            "Train Epoch: 2390 \tLoss: 1.361983\n",
            "Train Epoch: 2395 \tLoss: 1.361299\n",
            "Train Epoch: 2400 \tLoss: 1.360617\n",
            "\n",
            "Test set: Avg. loss: 1.4643, Accuracy: 365/500 (73%)\n",
            "\n",
            "Train Epoch: 2405 \tLoss: 1.359936\n",
            "Train Epoch: 2410 \tLoss: 1.359257\n",
            "Train Epoch: 2415 \tLoss: 1.358580\n",
            "Train Epoch: 2420 \tLoss: 1.357905\n",
            "Train Epoch: 2425 \tLoss: 1.357231\n",
            "\n",
            "Test set: Avg. loss: 1.4614, Accuracy: 365/500 (73%)\n",
            "\n",
            "Train Epoch: 2430 \tLoss: 1.356559\n",
            "Train Epoch: 2435 \tLoss: 1.355889\n",
            "Train Epoch: 2440 \tLoss: 1.355220\n",
            "Train Epoch: 2445 \tLoss: 1.354554\n",
            "Train Epoch: 2450 \tLoss: 1.353889\n",
            "\n",
            "Test set: Avg. loss: 1.4585, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2455 \tLoss: 1.353225\n",
            "Train Epoch: 2460 \tLoss: 1.352564\n",
            "Train Epoch: 2465 \tLoss: 1.351903\n",
            "Train Epoch: 2470 \tLoss: 1.351245\n",
            "Train Epoch: 2475 \tLoss: 1.350589\n",
            "\n",
            "Test set: Avg. loss: 1.4556, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2480 \tLoss: 1.349934\n",
            "Train Epoch: 2485 \tLoss: 1.349280\n",
            "Train Epoch: 2490 \tLoss: 1.348629\n",
            "Train Epoch: 2495 \tLoss: 1.347978\n",
            "Train Epoch: 2500 \tLoss: 1.347330\n",
            "\n",
            "Test set: Avg. loss: 1.4528, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2505 \tLoss: 1.346683\n",
            "Train Epoch: 2510 \tLoss: 1.346038\n",
            "Train Epoch: 2515 \tLoss: 1.345395\n",
            "Train Epoch: 2520 \tLoss: 1.344753\n",
            "Train Epoch: 2525 \tLoss: 1.344113\n",
            "\n",
            "Test set: Avg. loss: 1.4500, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2530 \tLoss: 1.343474\n",
            "Train Epoch: 2535 \tLoss: 1.342837\n",
            "Train Epoch: 2540 \tLoss: 1.342201\n",
            "Train Epoch: 2545 \tLoss: 1.341567\n",
            "Train Epoch: 2550 \tLoss: 1.340935\n",
            "\n",
            "Test set: Avg. loss: 1.4472, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2555 \tLoss: 1.340304\n",
            "Train Epoch: 2560 \tLoss: 1.339674\n",
            "Train Epoch: 2565 \tLoss: 1.339047\n",
            "Train Epoch: 2570 \tLoss: 1.338421\n",
            "Train Epoch: 2575 \tLoss: 1.337796\n",
            "\n",
            "Test set: Avg. loss: 1.4445, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2580 \tLoss: 1.337173\n",
            "Train Epoch: 2585 \tLoss: 1.336551\n",
            "Train Epoch: 2590 \tLoss: 1.335931\n",
            "Train Epoch: 2595 \tLoss: 1.335312\n",
            "Train Epoch: 2600 \tLoss: 1.334695\n",
            "\n",
            "Test set: Avg. loss: 1.4418, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2605 \tLoss: 1.334080\n",
            "Train Epoch: 2610 \tLoss: 1.333465\n",
            "Train Epoch: 2615 \tLoss: 1.332853\n",
            "Train Epoch: 2620 \tLoss: 1.332242\n",
            "Train Epoch: 2625 \tLoss: 1.331632\n",
            "\n",
            "Test set: Avg. loss: 1.4391, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2630 \tLoss: 1.331024\n",
            "Train Epoch: 2635 \tLoss: 1.330417\n",
            "Train Epoch: 2640 \tLoss: 1.329812\n",
            "Train Epoch: 2645 \tLoss: 1.329208\n",
            "Train Epoch: 2650 \tLoss: 1.328605\n",
            "\n",
            "Test set: Avg. loss: 1.4365, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2655 \tLoss: 1.328004\n",
            "Train Epoch: 2660 \tLoss: 1.327405\n",
            "Train Epoch: 2665 \tLoss: 1.326807\n",
            "Train Epoch: 2670 \tLoss: 1.326210\n",
            "Train Epoch: 2675 \tLoss: 1.325615\n",
            "\n",
            "Test set: Avg. loss: 1.4339, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2680 \tLoss: 1.325021\n",
            "Train Epoch: 2685 \tLoss: 1.324428\n",
            "Train Epoch: 2690 \tLoss: 1.323837\n",
            "Train Epoch: 2695 \tLoss: 1.323247\n",
            "Train Epoch: 2700 \tLoss: 1.322659\n",
            "\n",
            "Test set: Avg. loss: 1.4313, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2705 \tLoss: 1.322072\n",
            "Train Epoch: 2710 \tLoss: 1.321487\n",
            "Train Epoch: 2715 \tLoss: 1.320902\n",
            "Train Epoch: 2720 \tLoss: 1.320320\n",
            "Train Epoch: 2725 \tLoss: 1.319738\n",
            "\n",
            "Test set: Avg. loss: 1.4288, Accuracy: 364/500 (73%)\n",
            "\n",
            "Train Epoch: 2730 \tLoss: 1.319158\n",
            "Train Epoch: 2735 \tLoss: 1.318579\n",
            "Train Epoch: 2740 \tLoss: 1.318002\n",
            "Train Epoch: 2745 \tLoss: 1.317426\n",
            "Train Epoch: 2750 \tLoss: 1.316851\n",
            "\n",
            "Test set: Avg. loss: 1.4263, Accuracy: 363/500 (73%)\n",
            "\n",
            "Train Epoch: 2755 \tLoss: 1.316278\n",
            "Train Epoch: 2760 \tLoss: 1.315705\n",
            "Train Epoch: 2765 \tLoss: 1.315135\n",
            "Train Epoch: 2770 \tLoss: 1.314565\n",
            "Train Epoch: 2775 \tLoss: 1.313997\n",
            "\n",
            "Test set: Avg. loss: 1.4238, Accuracy: 365/500 (73%)\n",
            "\n",
            "Train Epoch: 2780 \tLoss: 1.313430\n",
            "Train Epoch: 2785 \tLoss: 1.312865\n",
            "Train Epoch: 2790 \tLoss: 1.312300\n",
            "Train Epoch: 2795 \tLoss: 1.311737\n",
            "Train Epoch: 2800 \tLoss: 1.311176\n",
            "\n",
            "Test set: Avg. loss: 1.4213, Accuracy: 365/500 (73%)\n",
            "\n",
            "Train Epoch: 2805 \tLoss: 1.310615\n",
            "Train Epoch: 2810 \tLoss: 1.310056\n",
            "Train Epoch: 2815 \tLoss: 1.309498\n",
            "Train Epoch: 2820 \tLoss: 1.308941\n",
            "Train Epoch: 2825 \tLoss: 1.308386\n",
            "\n",
            "Test set: Avg. loss: 1.4189, Accuracy: 365/500 (73%)\n",
            "\n",
            "Train Epoch: 2830 \tLoss: 1.307832\n",
            "Train Epoch: 2835 \tLoss: 1.307279\n",
            "Train Epoch: 2840 \tLoss: 1.306727\n",
            "Train Epoch: 2845 \tLoss: 1.306177\n",
            "Train Epoch: 2850 \tLoss: 1.305628\n",
            "\n",
            "Test set: Avg. loss: 1.4165, Accuracy: 365/500 (73%)\n",
            "\n",
            "Train Epoch: 2855 \tLoss: 1.305080\n",
            "Train Epoch: 2860 \tLoss: 1.304533\n",
            "Train Epoch: 2865 \tLoss: 1.303988\n",
            "Train Epoch: 2870 \tLoss: 1.303443\n",
            "Train Epoch: 2875 \tLoss: 1.302900\n",
            "\n",
            "Test set: Avg. loss: 1.4141, Accuracy: 365/500 (73%)\n",
            "\n",
            "Train Epoch: 2880 \tLoss: 1.302359\n",
            "Train Epoch: 2885 \tLoss: 1.301818\n",
            "Train Epoch: 2890 \tLoss: 1.301278\n",
            "Train Epoch: 2895 \tLoss: 1.300740\n",
            "Train Epoch: 2900 \tLoss: 1.300203\n",
            "\n",
            "Test set: Avg. loss: 1.4118, Accuracy: 366/500 (73%)\n",
            "\n",
            "Train Epoch: 2905 \tLoss: 1.299667\n",
            "Train Epoch: 2910 \tLoss: 1.299132\n",
            "Train Epoch: 2915 \tLoss: 1.298599\n",
            "Train Epoch: 2920 \tLoss: 1.298066\n",
            "Train Epoch: 2925 \tLoss: 1.297535\n",
            "\n",
            "Test set: Avg. loss: 1.4095, Accuracy: 366/500 (73%)\n",
            "\n",
            "Train Epoch: 2930 \tLoss: 1.297005\n",
            "Train Epoch: 2935 \tLoss: 1.296476\n",
            "Train Epoch: 2940 \tLoss: 1.295949\n",
            "Train Epoch: 2945 \tLoss: 1.295422\n",
            "Train Epoch: 2950 \tLoss: 1.294896\n",
            "\n",
            "Test set: Avg. loss: 1.4072, Accuracy: 367/500 (73%)\n",
            "\n",
            "Train Epoch: 2955 \tLoss: 1.294372\n",
            "Train Epoch: 2960 \tLoss: 1.293849\n",
            "Train Epoch: 2965 \tLoss: 1.293327\n",
            "Train Epoch: 2970 \tLoss: 1.292806\n",
            "Train Epoch: 2975 \tLoss: 1.292286\n",
            "\n",
            "Test set: Avg. loss: 1.4049, Accuracy: 367/500 (73%)\n",
            "\n",
            "Train Epoch: 2980 \tLoss: 1.291767\n",
            "Train Epoch: 2985 \tLoss: 1.291250\n",
            "Train Epoch: 2990 \tLoss: 1.290733\n",
            "Train Epoch: 2995 \tLoss: 1.290218\n",
            "Train Epoch: 3000 \tLoss: 1.289704\n",
            "\n",
            "Test set: Avg. loss: 1.4027, Accuracy: 367/500 (73%)\n",
            "\n",
            "Train Epoch: 3005 \tLoss: 1.289191\n",
            "Train Epoch: 3010 \tLoss: 1.288679\n",
            "Train Epoch: 3015 \tLoss: 1.288167\n",
            "Train Epoch: 3020 \tLoss: 1.287658\n",
            "Train Epoch: 3025 \tLoss: 1.287149\n",
            "\n",
            "Test set: Avg. loss: 1.4005, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3030 \tLoss: 1.286641\n",
            "Train Epoch: 3035 \tLoss: 1.286134\n",
            "Train Epoch: 3040 \tLoss: 1.285629\n",
            "Train Epoch: 3045 \tLoss: 1.285124\n",
            "Train Epoch: 3050 \tLoss: 1.284621\n",
            "\n",
            "Test set: Avg. loss: 1.3983, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3055 \tLoss: 1.284119\n",
            "Train Epoch: 3060 \tLoss: 1.283617\n",
            "Train Epoch: 3065 \tLoss: 1.283117\n",
            "Train Epoch: 3070 \tLoss: 1.282618\n",
            "Train Epoch: 3075 \tLoss: 1.282119\n",
            "\n",
            "Test set: Avg. loss: 1.3961, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3080 \tLoss: 1.281622\n",
            "Train Epoch: 3085 \tLoss: 1.281126\n",
            "Train Epoch: 3090 \tLoss: 1.280631\n",
            "Train Epoch: 3095 \tLoss: 1.280137\n",
            "Train Epoch: 3100 \tLoss: 1.279644\n",
            "\n",
            "Test set: Avg. loss: 1.3939, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3105 \tLoss: 1.279152\n",
            "Train Epoch: 3110 \tLoss: 1.278661\n",
            "Train Epoch: 3115 \tLoss: 1.278171\n",
            "Train Epoch: 3120 \tLoss: 1.277682\n",
            "Train Epoch: 3125 \tLoss: 1.277194\n",
            "\n",
            "Test set: Avg. loss: 1.3918, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3130 \tLoss: 1.276707\n",
            "Train Epoch: 3135 \tLoss: 1.276221\n",
            "Train Epoch: 3140 \tLoss: 1.275736\n",
            "Train Epoch: 3145 \tLoss: 1.275253\n",
            "Train Epoch: 3150 \tLoss: 1.274770\n",
            "\n",
            "Test set: Avg. loss: 1.3897, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3155 \tLoss: 1.274288\n",
            "Train Epoch: 3160 \tLoss: 1.273807\n",
            "Train Epoch: 3165 \tLoss: 1.273327\n",
            "Train Epoch: 3170 \tLoss: 1.272848\n",
            "Train Epoch: 3175 \tLoss: 1.272369\n",
            "\n",
            "Test set: Avg. loss: 1.3876, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3180 \tLoss: 1.271892\n",
            "Train Epoch: 3185 \tLoss: 1.271416\n",
            "Train Epoch: 3190 \tLoss: 1.270941\n",
            "Train Epoch: 3195 \tLoss: 1.270467\n",
            "Train Epoch: 3200 \tLoss: 1.269994\n",
            "\n",
            "Test set: Avg. loss: 1.3856, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3205 \tLoss: 1.269521\n",
            "Train Epoch: 3210 \tLoss: 1.269050\n",
            "Train Epoch: 3215 \tLoss: 1.268580\n",
            "Train Epoch: 3220 \tLoss: 1.268110\n",
            "Train Epoch: 3225 \tLoss: 1.267641\n",
            "\n",
            "Test set: Avg. loss: 1.3835, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3230 \tLoss: 1.267174\n",
            "Train Epoch: 3235 \tLoss: 1.266708\n",
            "Train Epoch: 3240 \tLoss: 1.266242\n",
            "Train Epoch: 3245 \tLoss: 1.265777\n",
            "Train Epoch: 3250 \tLoss: 1.265313\n",
            "\n",
            "Test set: Avg. loss: 1.3815, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3255 \tLoss: 1.264850\n",
            "Train Epoch: 3260 \tLoss: 1.264388\n",
            "Train Epoch: 3265 \tLoss: 1.263927\n",
            "Train Epoch: 3270 \tLoss: 1.263467\n",
            "Train Epoch: 3275 \tLoss: 1.263007\n",
            "\n",
            "Test set: Avg. loss: 1.3795, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3280 \tLoss: 1.262549\n",
            "Train Epoch: 3285 \tLoss: 1.262092\n",
            "Train Epoch: 3290 \tLoss: 1.261635\n",
            "Train Epoch: 3295 \tLoss: 1.261179\n",
            "Train Epoch: 3300 \tLoss: 1.260725\n",
            "\n",
            "Test set: Avg. loss: 1.3775, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3305 \tLoss: 1.260271\n",
            "Train Epoch: 3310 \tLoss: 1.259818\n",
            "Train Epoch: 3315 \tLoss: 1.259365\n",
            "Train Epoch: 3320 \tLoss: 1.258914\n",
            "Train Epoch: 3325 \tLoss: 1.258464\n",
            "\n",
            "Test set: Avg. loss: 1.3755, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3330 \tLoss: 1.258014\n",
            "Train Epoch: 3335 \tLoss: 1.257566\n",
            "Train Epoch: 3340 \tLoss: 1.257118\n",
            "Train Epoch: 3345 \tLoss: 1.256671\n",
            "Train Epoch: 3350 \tLoss: 1.256225\n",
            "\n",
            "Test set: Avg. loss: 1.3736, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3355 \tLoss: 1.255780\n",
            "Train Epoch: 3360 \tLoss: 1.255336\n",
            "Train Epoch: 3365 \tLoss: 1.254892\n",
            "Train Epoch: 3370 \tLoss: 1.254450\n",
            "Train Epoch: 3375 \tLoss: 1.254008\n",
            "\n",
            "Test set: Avg. loss: 1.3717, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3380 \tLoss: 1.253567\n",
            "Train Epoch: 3385 \tLoss: 1.253127\n",
            "Train Epoch: 3390 \tLoss: 1.252688\n",
            "Train Epoch: 3395 \tLoss: 1.252249\n",
            "Train Epoch: 3400 \tLoss: 1.251812\n",
            "\n",
            "Test set: Avg. loss: 1.3698, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3405 \tLoss: 1.251375\n",
            "Train Epoch: 3410 \tLoss: 1.250939\n",
            "Train Epoch: 3415 \tLoss: 1.250504\n",
            "Train Epoch: 3420 \tLoss: 1.250070\n",
            "Train Epoch: 3425 \tLoss: 1.249637\n",
            "\n",
            "Test set: Avg. loss: 1.3679, Accuracy: 368/500 (74%)\n",
            "\n",
            "Train Epoch: 3430 \tLoss: 1.249204\n",
            "Train Epoch: 3435 \tLoss: 1.248772\n",
            "Train Epoch: 3440 \tLoss: 1.248341\n",
            "Train Epoch: 3445 \tLoss: 1.247911\n",
            "Train Epoch: 3450 \tLoss: 1.247482\n",
            "\n",
            "Test set: Avg. loss: 1.3660, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3455 \tLoss: 1.247054\n",
            "Train Epoch: 3460 \tLoss: 1.246626\n",
            "Train Epoch: 3465 \tLoss: 1.246199\n",
            "Train Epoch: 3470 \tLoss: 1.245773\n",
            "Train Epoch: 3475 \tLoss: 1.245347\n",
            "\n",
            "Test set: Avg. loss: 1.3641, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3480 \tLoss: 1.244923\n",
            "Train Epoch: 3485 \tLoss: 1.244499\n",
            "Train Epoch: 3490 \tLoss: 1.244076\n",
            "Train Epoch: 3495 \tLoss: 1.243654\n",
            "Train Epoch: 3500 \tLoss: 1.243233\n",
            "\n",
            "Test set: Avg. loss: 1.3623, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3505 \tLoss: 1.242812\n",
            "Train Epoch: 3510 \tLoss: 1.242392\n",
            "Train Epoch: 3515 \tLoss: 1.241973\n",
            "Train Epoch: 3520 \tLoss: 1.241555\n",
            "Train Epoch: 3525 \tLoss: 1.241138\n",
            "\n",
            "Test set: Avg. loss: 1.3605, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3530 \tLoss: 1.240721\n",
            "Train Epoch: 3535 \tLoss: 1.240305\n",
            "Train Epoch: 3540 \tLoss: 1.239890\n",
            "Train Epoch: 3545 \tLoss: 1.239475\n",
            "Train Epoch: 3550 \tLoss: 1.239062\n",
            "\n",
            "Test set: Avg. loss: 1.3587, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3555 \tLoss: 1.238649\n",
            "Train Epoch: 3560 \tLoss: 1.238237\n",
            "Train Epoch: 3565 \tLoss: 1.237825\n",
            "Train Epoch: 3570 \tLoss: 1.237414\n",
            "Train Epoch: 3575 \tLoss: 1.237005\n",
            "\n",
            "Test set: Avg. loss: 1.3569, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3580 \tLoss: 1.236596\n",
            "Train Epoch: 3585 \tLoss: 1.236187\n",
            "Train Epoch: 3590 \tLoss: 1.235780\n",
            "Train Epoch: 3595 \tLoss: 1.235372\n",
            "Train Epoch: 3600 \tLoss: 1.234966\n",
            "\n",
            "Test set: Avg. loss: 1.3551, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3605 \tLoss: 1.234561\n",
            "Train Epoch: 3610 \tLoss: 1.234156\n",
            "Train Epoch: 3615 \tLoss: 1.233752\n",
            "Train Epoch: 3620 \tLoss: 1.233349\n",
            "Train Epoch: 3625 \tLoss: 1.232946\n",
            "\n",
            "Test set: Avg. loss: 1.3534, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3630 \tLoss: 1.232544\n",
            "Train Epoch: 3635 \tLoss: 1.232143\n",
            "Train Epoch: 3640 \tLoss: 1.231743\n",
            "Train Epoch: 3645 \tLoss: 1.231343\n",
            "Train Epoch: 3650 \tLoss: 1.230944\n",
            "\n",
            "Test set: Avg. loss: 1.3516, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3655 \tLoss: 1.230546\n",
            "Train Epoch: 3660 \tLoss: 1.230149\n",
            "Train Epoch: 3665 \tLoss: 1.229752\n",
            "Train Epoch: 3670 \tLoss: 1.229355\n",
            "Train Epoch: 3675 \tLoss: 1.228960\n",
            "\n",
            "Test set: Avg. loss: 1.3499, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3680 \tLoss: 1.228565\n",
            "Train Epoch: 3685 \tLoss: 1.228171\n",
            "Train Epoch: 3690 \tLoss: 1.227778\n",
            "Train Epoch: 3695 \tLoss: 1.227385\n",
            "Train Epoch: 3700 \tLoss: 1.226993\n",
            "\n",
            "Test set: Avg. loss: 1.3482, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3705 \tLoss: 1.226602\n",
            "Train Epoch: 3710 \tLoss: 1.226211\n",
            "Train Epoch: 3715 \tLoss: 1.225822\n",
            "Train Epoch: 3720 \tLoss: 1.225433\n",
            "Train Epoch: 3725 \tLoss: 1.225044\n",
            "\n",
            "Test set: Avg. loss: 1.3465, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3730 \tLoss: 1.224656\n",
            "Train Epoch: 3735 \tLoss: 1.224269\n",
            "Train Epoch: 3740 \tLoss: 1.223882\n",
            "Train Epoch: 3745 \tLoss: 1.223497\n",
            "Train Epoch: 3750 \tLoss: 1.223111\n",
            "\n",
            "Test set: Avg. loss: 1.3448, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3755 \tLoss: 1.222727\n",
            "Train Epoch: 3760 \tLoss: 1.222343\n",
            "Train Epoch: 3765 \tLoss: 1.221960\n",
            "Train Epoch: 3770 \tLoss: 1.221578\n",
            "Train Epoch: 3775 \tLoss: 1.221196\n",
            "\n",
            "Test set: Avg. loss: 1.3432, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3780 \tLoss: 1.220815\n",
            "Train Epoch: 3785 \tLoss: 1.220434\n",
            "Train Epoch: 3790 \tLoss: 1.220054\n",
            "Train Epoch: 3795 \tLoss: 1.219675\n",
            "Train Epoch: 3800 \tLoss: 1.219296\n",
            "\n",
            "Test set: Avg. loss: 1.3415, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3805 \tLoss: 1.218919\n",
            "Train Epoch: 3810 \tLoss: 1.218541\n",
            "Train Epoch: 3815 \tLoss: 1.218165\n",
            "Train Epoch: 3820 \tLoss: 1.217789\n",
            "Train Epoch: 3825 \tLoss: 1.217414\n",
            "\n",
            "Test set: Avg. loss: 1.3399, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3830 \tLoss: 1.217039\n",
            "Train Epoch: 3835 \tLoss: 1.216665\n",
            "Train Epoch: 3840 \tLoss: 1.216291\n",
            "Train Epoch: 3845 \tLoss: 1.215919\n",
            "Train Epoch: 3850 \tLoss: 1.215546\n",
            "\n",
            "Test set: Avg. loss: 1.3383, Accuracy: 369/500 (74%)\n",
            "\n",
            "Train Epoch: 3855 \tLoss: 1.215175\n",
            "Train Epoch: 3860 \tLoss: 1.214804\n",
            "Train Epoch: 3865 \tLoss: 1.214434\n",
            "Train Epoch: 3870 \tLoss: 1.214064\n",
            "Train Epoch: 3875 \tLoss: 1.213695\n",
            "\n",
            "Test set: Avg. loss: 1.3366, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3880 \tLoss: 1.213327\n",
            "Train Epoch: 3885 \tLoss: 1.212959\n",
            "Train Epoch: 3890 \tLoss: 1.212592\n",
            "Train Epoch: 3895 \tLoss: 1.212226\n",
            "Train Epoch: 3900 \tLoss: 1.211860\n",
            "\n",
            "Test set: Avg. loss: 1.3351, Accuracy: 370/500 (74%)\n",
            "\n",
            "Train Epoch: 3905 \tLoss: 1.211494\n",
            "Train Epoch: 3910 \tLoss: 1.211130\n",
            "Train Epoch: 3915 \tLoss: 1.210766\n",
            "Train Epoch: 3920 \tLoss: 1.210402\n",
            "Train Epoch: 3925 \tLoss: 1.210039\n",
            "\n",
            "Test set: Avg. loss: 1.3335, Accuracy: 372/500 (74%)\n",
            "\n",
            "Train Epoch: 3930 \tLoss: 1.209677\n",
            "Train Epoch: 3935 \tLoss: 1.209315\n",
            "Train Epoch: 3940 \tLoss: 1.208954\n",
            "Train Epoch: 3945 \tLoss: 1.208594\n",
            "Train Epoch: 3950 \tLoss: 1.208234\n",
            "\n",
            "Test set: Avg. loss: 1.3319, Accuracy: 372/500 (74%)\n",
            "\n",
            "Train Epoch: 3955 \tLoss: 1.207875\n",
            "Train Epoch: 3960 \tLoss: 1.207516\n",
            "Train Epoch: 3965 \tLoss: 1.207158\n",
            "Train Epoch: 3970 \tLoss: 1.206801\n",
            "Train Epoch: 3975 \tLoss: 1.206444\n",
            "\n",
            "Test set: Avg. loss: 1.3303, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 3980 \tLoss: 1.206087\n",
            "Train Epoch: 3985 \tLoss: 1.205732\n",
            "Train Epoch: 3990 \tLoss: 1.205377\n",
            "Train Epoch: 3995 \tLoss: 1.205022\n",
            "Train Epoch: 4000 \tLoss: 1.204668\n",
            "\n",
            "Test set: Avg. loss: 1.3288, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4005 \tLoss: 1.204315\n",
            "Train Epoch: 4010 \tLoss: 1.203962\n",
            "Train Epoch: 4015 \tLoss: 1.203610\n",
            "Train Epoch: 4020 \tLoss: 1.203258\n",
            "Train Epoch: 4025 \tLoss: 1.202907\n",
            "\n",
            "Test set: Avg. loss: 1.3273, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4030 \tLoss: 1.202556\n",
            "Train Epoch: 4035 \tLoss: 1.202206\n",
            "Train Epoch: 4040 \tLoss: 1.201857\n",
            "Train Epoch: 4045 \tLoss: 1.201508\n",
            "Train Epoch: 4050 \tLoss: 1.201160\n",
            "\n",
            "Test set: Avg. loss: 1.3258, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4055 \tLoss: 1.200812\n",
            "Train Epoch: 4060 \tLoss: 1.200465\n",
            "Train Epoch: 4065 \tLoss: 1.200119\n",
            "Train Epoch: 4070 \tLoss: 1.199772\n",
            "Train Epoch: 4075 \tLoss: 1.199427\n",
            "\n",
            "Test set: Avg. loss: 1.3243, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4080 \tLoss: 1.199082\n",
            "Train Epoch: 4085 \tLoss: 1.198738\n",
            "Train Epoch: 4090 \tLoss: 1.198394\n",
            "Train Epoch: 4095 \tLoss: 1.198051\n",
            "Train Epoch: 4100 \tLoss: 1.197708\n",
            "\n",
            "Test set: Avg. loss: 1.3228, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4105 \tLoss: 1.197366\n",
            "Train Epoch: 4110 \tLoss: 1.197024\n",
            "Train Epoch: 4115 \tLoss: 1.196683\n",
            "Train Epoch: 4120 \tLoss: 1.196343\n",
            "Train Epoch: 4125 \tLoss: 1.196003\n",
            "\n",
            "Test set: Avg. loss: 1.3213, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4130 \tLoss: 1.195663\n",
            "Train Epoch: 4135 \tLoss: 1.195324\n",
            "Train Epoch: 4140 \tLoss: 1.194986\n",
            "Train Epoch: 4145 \tLoss: 1.194648\n",
            "Train Epoch: 4150 \tLoss: 1.194311\n",
            "\n",
            "Test set: Avg. loss: 1.3198, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4155 \tLoss: 1.193974\n",
            "Train Epoch: 4160 \tLoss: 1.193638\n",
            "Train Epoch: 4165 \tLoss: 1.193302\n",
            "Train Epoch: 4170 \tLoss: 1.192967\n",
            "Train Epoch: 4175 \tLoss: 1.192632\n",
            "\n",
            "Test set: Avg. loss: 1.3184, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4180 \tLoss: 1.192298\n",
            "Train Epoch: 4185 \tLoss: 1.191965\n",
            "Train Epoch: 4190 \tLoss: 1.191632\n",
            "Train Epoch: 4195 \tLoss: 1.191299\n",
            "Train Epoch: 4200 \tLoss: 1.190967\n",
            "\n",
            "Test set: Avg. loss: 1.3169, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4205 \tLoss: 1.190636\n",
            "Train Epoch: 4210 \tLoss: 1.190304\n",
            "Train Epoch: 4215 \tLoss: 1.189974\n",
            "Train Epoch: 4220 \tLoss: 1.189644\n",
            "Train Epoch: 4225 \tLoss: 1.189314\n",
            "\n",
            "Test set: Avg. loss: 1.3155, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4230 \tLoss: 1.188986\n",
            "Train Epoch: 4235 \tLoss: 1.188657\n",
            "Train Epoch: 4240 \tLoss: 1.188329\n",
            "Train Epoch: 4245 \tLoss: 1.188002\n",
            "Train Epoch: 4250 \tLoss: 1.187675\n",
            "\n",
            "Test set: Avg. loss: 1.3140, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4255 \tLoss: 1.187349\n",
            "Train Epoch: 4260 \tLoss: 1.187023\n",
            "Train Epoch: 4265 \tLoss: 1.186697\n",
            "Train Epoch: 4270 \tLoss: 1.186372\n",
            "Train Epoch: 4275 \tLoss: 1.186048\n",
            "\n",
            "Test set: Avg. loss: 1.3126, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4280 \tLoss: 1.185724\n",
            "Train Epoch: 4285 \tLoss: 1.185401\n",
            "Train Epoch: 4290 \tLoss: 1.185078\n",
            "Train Epoch: 4295 \tLoss: 1.184755\n",
            "Train Epoch: 4300 \tLoss: 1.184433\n",
            "\n",
            "Test set: Avg. loss: 1.3112, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4305 \tLoss: 1.184112\n",
            "Train Epoch: 4310 \tLoss: 1.183791\n",
            "Train Epoch: 4315 \tLoss: 1.183471\n",
            "Train Epoch: 4320 \tLoss: 1.183151\n",
            "Train Epoch: 4325 \tLoss: 1.182831\n",
            "\n",
            "Test set: Avg. loss: 1.3098, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4330 \tLoss: 1.182512\n",
            "Train Epoch: 4335 \tLoss: 1.182194\n",
            "Train Epoch: 4340 \tLoss: 1.181875\n",
            "Train Epoch: 4345 \tLoss: 1.181558\n",
            "Train Epoch: 4350 \tLoss: 1.181241\n",
            "\n",
            "Test set: Avg. loss: 1.3085, Accuracy: 372/500 (74%)\n",
            "\n",
            "Train Epoch: 4355 \tLoss: 1.180924\n",
            "Train Epoch: 4360 \tLoss: 1.180608\n",
            "Train Epoch: 4365 \tLoss: 1.180292\n",
            "Train Epoch: 4370 \tLoss: 1.179977\n",
            "Train Epoch: 4375 \tLoss: 1.179663\n",
            "\n",
            "Test set: Avg. loss: 1.3071, Accuracy: 372/500 (74%)\n",
            "\n",
            "Train Epoch: 4380 \tLoss: 1.179348\n",
            "Train Epoch: 4385 \tLoss: 1.179035\n",
            "Train Epoch: 4390 \tLoss: 1.178721\n",
            "Train Epoch: 4395 \tLoss: 1.178409\n",
            "Train Epoch: 4400 \tLoss: 1.178096\n",
            "\n",
            "Test set: Avg. loss: 1.3057, Accuracy: 372/500 (74%)\n",
            "\n",
            "Train Epoch: 4405 \tLoss: 1.177784\n",
            "Train Epoch: 4410 \tLoss: 1.177473\n",
            "Train Epoch: 4415 \tLoss: 1.177162\n",
            "Train Epoch: 4420 \tLoss: 1.176852\n",
            "Train Epoch: 4425 \tLoss: 1.176541\n",
            "\n",
            "Test set: Avg. loss: 1.3044, Accuracy: 372/500 (74%)\n",
            "\n",
            "Train Epoch: 4430 \tLoss: 1.176232\n",
            "Train Epoch: 4435 \tLoss: 1.175923\n",
            "Train Epoch: 4440 \tLoss: 1.175614\n",
            "Train Epoch: 4445 \tLoss: 1.175306\n",
            "Train Epoch: 4450 \tLoss: 1.174998\n",
            "\n",
            "Test set: Avg. loss: 1.3030, Accuracy: 372/500 (74%)\n",
            "\n",
            "Train Epoch: 4455 \tLoss: 1.174691\n",
            "Train Epoch: 4460 \tLoss: 1.174384\n",
            "Train Epoch: 4465 \tLoss: 1.174078\n",
            "Train Epoch: 4470 \tLoss: 1.173772\n",
            "Train Epoch: 4475 \tLoss: 1.173466\n",
            "\n",
            "Test set: Avg. loss: 1.3017, Accuracy: 372/500 (74%)\n",
            "\n",
            "Train Epoch: 4480 \tLoss: 1.173161\n",
            "Train Epoch: 4485 \tLoss: 1.172857\n",
            "Train Epoch: 4490 \tLoss: 1.172553\n",
            "Train Epoch: 4495 \tLoss: 1.172249\n",
            "Train Epoch: 4500 \tLoss: 1.171946\n",
            "\n",
            "Test set: Avg. loss: 1.3004, Accuracy: 372/500 (74%)\n",
            "\n",
            "Train Epoch: 4505 \tLoss: 1.171643\n",
            "Train Epoch: 4510 \tLoss: 1.171341\n",
            "Train Epoch: 4515 \tLoss: 1.171039\n",
            "Train Epoch: 4520 \tLoss: 1.170737\n",
            "Train Epoch: 4525 \tLoss: 1.170436\n",
            "\n",
            "Test set: Avg. loss: 1.2991, Accuracy: 372/500 (74%)\n",
            "\n",
            "Train Epoch: 4530 \tLoss: 1.170135\n",
            "Train Epoch: 4535 \tLoss: 1.169835\n",
            "Train Epoch: 4540 \tLoss: 1.169536\n",
            "Train Epoch: 4545 \tLoss: 1.169236\n",
            "Train Epoch: 4550 \tLoss: 1.168937\n",
            "\n",
            "Test set: Avg. loss: 1.2978, Accuracy: 373/500 (75%)\n",
            "\n",
            "Train Epoch: 4555 \tLoss: 1.168639\n",
            "Train Epoch: 4560 \tLoss: 1.168341\n",
            "Train Epoch: 4565 \tLoss: 1.168043\n",
            "Train Epoch: 4570 \tLoss: 1.167746\n",
            "Train Epoch: 4575 \tLoss: 1.167449\n",
            "\n",
            "Test set: Avg. loss: 1.2965, Accuracy: 374/500 (75%)\n",
            "\n",
            "Train Epoch: 4580 \tLoss: 1.167153\n",
            "Train Epoch: 4585 \tLoss: 1.166857\n",
            "Train Epoch: 4590 \tLoss: 1.166562\n",
            "Train Epoch: 4595 \tLoss: 1.166267\n",
            "Train Epoch: 4600 \tLoss: 1.165972\n",
            "\n",
            "Test set: Avg. loss: 1.2952, Accuracy: 375/500 (75%)\n",
            "\n",
            "Train Epoch: 4605 \tLoss: 1.165678\n",
            "Train Epoch: 4610 \tLoss: 1.165384\n",
            "Train Epoch: 4615 \tLoss: 1.165091\n",
            "Train Epoch: 4620 \tLoss: 1.164798\n",
            "Train Epoch: 4625 \tLoss: 1.164505\n",
            "\n",
            "Test set: Avg. loss: 1.2939, Accuracy: 375/500 (75%)\n",
            "\n",
            "Train Epoch: 4630 \tLoss: 1.164213\n",
            "Train Epoch: 4635 \tLoss: 1.163922\n",
            "Train Epoch: 4640 \tLoss: 1.163630\n",
            "Train Epoch: 4645 \tLoss: 1.163340\n",
            "Train Epoch: 4650 \tLoss: 1.163049\n",
            "\n",
            "Test set: Avg. loss: 1.2927, Accuracy: 375/500 (75%)\n",
            "\n",
            "Train Epoch: 4655 \tLoss: 1.162759\n",
            "Train Epoch: 4660 \tLoss: 1.162470\n",
            "Train Epoch: 4665 \tLoss: 1.162180\n",
            "Train Epoch: 4670 \tLoss: 1.161892\n",
            "Train Epoch: 4675 \tLoss: 1.161603\n",
            "\n",
            "Test set: Avg. loss: 1.2914, Accuracy: 375/500 (75%)\n",
            "\n",
            "Train Epoch: 4680 \tLoss: 1.161315\n",
            "Train Epoch: 4685 \tLoss: 1.161028\n",
            "Train Epoch: 4690 \tLoss: 1.160740\n",
            "Train Epoch: 4695 \tLoss: 1.160454\n",
            "Train Epoch: 4700 \tLoss: 1.160167\n",
            "\n",
            "Test set: Avg. loss: 1.2902, Accuracy: 375/500 (75%)\n",
            "\n",
            "Train Epoch: 4705 \tLoss: 1.159881\n",
            "Train Epoch: 4710 \tLoss: 1.159596\n",
            "Train Epoch: 4715 \tLoss: 1.159311\n",
            "Train Epoch: 4720 \tLoss: 1.159026\n",
            "Train Epoch: 4725 \tLoss: 1.158741\n",
            "\n",
            "Test set: Avg. loss: 1.2889, Accuracy: 375/500 (75%)\n",
            "\n",
            "Train Epoch: 4730 \tLoss: 1.158458\n",
            "Train Epoch: 4735 \tLoss: 1.158174\n",
            "Train Epoch: 4740 \tLoss: 1.157891\n",
            "Train Epoch: 4745 \tLoss: 1.157608\n",
            "Train Epoch: 4750 \tLoss: 1.157325\n",
            "\n",
            "Test set: Avg. loss: 1.2877, Accuracy: 374/500 (75%)\n",
            "\n",
            "Train Epoch: 4755 \tLoss: 1.157043\n",
            "Train Epoch: 4760 \tLoss: 1.156762\n",
            "Train Epoch: 4765 \tLoss: 1.156481\n",
            "Train Epoch: 4770 \tLoss: 1.156200\n",
            "Train Epoch: 4775 \tLoss: 1.155919\n",
            "\n",
            "Test set: Avg. loss: 1.2865, Accuracy: 374/500 (75%)\n",
            "\n",
            "Train Epoch: 4780 \tLoss: 1.155639\n",
            "Train Epoch: 4785 \tLoss: 1.155360\n",
            "Train Epoch: 4790 \tLoss: 1.155080\n",
            "Train Epoch: 4795 \tLoss: 1.154801\n",
            "Train Epoch: 4800 \tLoss: 1.154523\n",
            "\n",
            "Test set: Avg. loss: 1.2853, Accuracy: 374/500 (75%)\n",
            "\n",
            "Train Epoch: 4805 \tLoss: 1.154245\n",
            "Train Epoch: 4810 \tLoss: 1.153967\n",
            "Train Epoch: 4815 \tLoss: 1.153690\n",
            "Train Epoch: 4820 \tLoss: 1.153412\n",
            "Train Epoch: 4825 \tLoss: 1.153136\n",
            "\n",
            "Test set: Avg. loss: 1.2841, Accuracy: 374/500 (75%)\n",
            "\n",
            "Train Epoch: 4830 \tLoss: 1.152859\n",
            "Train Epoch: 4835 \tLoss: 1.152584\n",
            "Train Epoch: 4840 \tLoss: 1.152308\n",
            "Train Epoch: 4845 \tLoss: 1.152033\n",
            "Train Epoch: 4850 \tLoss: 1.151758\n",
            "\n",
            "Test set: Avg. loss: 1.2829, Accuracy: 374/500 (75%)\n",
            "\n",
            "Train Epoch: 4855 \tLoss: 1.151484\n",
            "Train Epoch: 4860 \tLoss: 1.151210\n",
            "Train Epoch: 4865 \tLoss: 1.150936\n",
            "Train Epoch: 4870 \tLoss: 1.150663\n",
            "Train Epoch: 4875 \tLoss: 1.150390\n",
            "\n",
            "Test set: Avg. loss: 1.2817, Accuracy: 374/500 (75%)\n",
            "\n",
            "Train Epoch: 4880 \tLoss: 1.150118\n",
            "Train Epoch: 4885 \tLoss: 1.149845\n",
            "Train Epoch: 4890 \tLoss: 1.149574\n",
            "Train Epoch: 4895 \tLoss: 1.149302\n",
            "Train Epoch: 4900 \tLoss: 1.149031\n",
            "\n",
            "Test set: Avg. loss: 1.2805, Accuracy: 375/500 (75%)\n",
            "\n",
            "Train Epoch: 4905 \tLoss: 1.148760\n",
            "Train Epoch: 4910 \tLoss: 1.148490\n",
            "Train Epoch: 4915 \tLoss: 1.148220\n",
            "Train Epoch: 4920 \tLoss: 1.147951\n",
            "Train Epoch: 4925 \tLoss: 1.147681\n",
            "\n",
            "Test set: Avg. loss: 1.2793, Accuracy: 375/500 (75%)\n",
            "\n",
            "Train Epoch: 4930 \tLoss: 1.147412\n",
            "Train Epoch: 4935 \tLoss: 1.147144\n",
            "Train Epoch: 4940 \tLoss: 1.146876\n",
            "Train Epoch: 4945 \tLoss: 1.146608\n",
            "Train Epoch: 4950 \tLoss: 1.146340\n",
            "\n",
            "Test set: Avg. loss: 1.2782, Accuracy: 375/500 (75%)\n",
            "\n",
            "Train Epoch: 4955 \tLoss: 1.146073\n",
            "Train Epoch: 4960 \tLoss: 1.145807\n",
            "Train Epoch: 4965 \tLoss: 1.145540\n",
            "Train Epoch: 4970 \tLoss: 1.145274\n",
            "Train Epoch: 4975 \tLoss: 1.145009\n",
            "\n",
            "Test set: Avg. loss: 1.2770, Accuracy: 375/500 (75%)\n",
            "\n",
            "Train Epoch: 4980 \tLoss: 1.144743\n",
            "Train Epoch: 4985 \tLoss: 1.144478\n",
            "Train Epoch: 4990 \tLoss: 1.144214\n",
            "Train Epoch: 4995 \tLoss: 1.143949\n",
            "Train Epoch: 5000 \tLoss: 1.143685\n",
            "\n",
            "Test set: Avg. loss: 1.2758, Accuracy: 375/500 (75%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#train only fc1:\n",
        "network = Net()\n",
        "train_losses.clear()\n",
        "test_losses.clear()\n",
        "#count=[]\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
        "\n",
        "#freeze the other layers:\n",
        "network.fc2.weight.requires_grad=False\n",
        "network.fc2.bias.requires_grad=False\n",
        "\n",
        "network.conv2.weight.requires_grad=False\n",
        "network.conv2.bias.requires_grad=False\n",
        "\n",
        "network.conv1.weight.requires_grad=False\n",
        "network.conv1.bias.requires_grad=False\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, network.parameters()), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "\n",
        "# save the initial weights to measure later their contribution:\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()\n",
        "\n",
        "#train\n",
        "test_n = 25\n",
        "test()\n",
        "count = []\n",
        "n_epochs=5000\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  if epoch % test_n == 0:\n",
        "    test()\n",
        "    count.append(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.arange(0,n_epochs)\n",
        "count = np.arange(0,n_epochs+test_n,test_n)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(x, train_losses, color='blue', zorder=1)\n",
        "plt.plot(count, test_losses, color='red', zorder=2)\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.xlabel('number of training examples seen')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3084, Accuracy: 48/500 (10%)\n",
            "\n",
            "Train Epoch: 5 \tLoss: 2.306231\n",
            "Train Epoch: 10 \tLoss: 2.305928\n",
            "Train Epoch: 15 \tLoss: 2.305624\n",
            "Train Epoch: 20 \tLoss: 2.305322\n",
            "Train Epoch: 25 \tLoss: 2.305022\n",
            "\n",
            "Test set: Avg. loss: 2.3071, Accuracy: 49/500 (10%)\n",
            "\n",
            "Train Epoch: 30 \tLoss: 2.304723\n",
            "Train Epoch: 35 \tLoss: 2.304424\n",
            "Train Epoch: 40 \tLoss: 2.304123\n",
            "Train Epoch: 45 \tLoss: 2.303822\n",
            "Train Epoch: 50 \tLoss: 2.303525\n",
            "\n",
            "Test set: Avg. loss: 2.3059, Accuracy: 49/500 (10%)\n",
            "\n",
            "Train Epoch: 55 \tLoss: 2.303227\n",
            "Train Epoch: 60 \tLoss: 2.302928\n",
            "Train Epoch: 65 \tLoss: 2.302629\n",
            "Train Epoch: 70 \tLoss: 2.302330\n",
            "Train Epoch: 75 \tLoss: 2.302034\n",
            "\n",
            "Test set: Avg. loss: 2.3046, Accuracy: 50/500 (10%)\n",
            "\n",
            "Train Epoch: 80 \tLoss: 2.301735\n",
            "Train Epoch: 85 \tLoss: 2.301432\n",
            "Train Epoch: 90 \tLoss: 2.301130\n",
            "Train Epoch: 95 \tLoss: 2.300833\n",
            "Train Epoch: 100 \tLoss: 2.300538\n",
            "\n",
            "Test set: Avg. loss: 2.3034, Accuracy: 50/500 (10%)\n",
            "\n",
            "Train Epoch: 105 \tLoss: 2.300245\n",
            "Train Epoch: 110 \tLoss: 2.299956\n",
            "Train Epoch: 115 \tLoss: 2.299669\n",
            "Train Epoch: 120 \tLoss: 2.299381\n",
            "Train Epoch: 125 \tLoss: 2.299097\n",
            "\n",
            "Test set: Avg. loss: 2.3023, Accuracy: 48/500 (10%)\n",
            "\n",
            "Train Epoch: 130 \tLoss: 2.298813\n",
            "Train Epoch: 135 \tLoss: 2.298533\n",
            "Train Epoch: 140 \tLoss: 2.298250\n",
            "Train Epoch: 145 \tLoss: 2.297963\n",
            "Train Epoch: 150 \tLoss: 2.297677\n",
            "\n",
            "Test set: Avg. loss: 2.3011, Accuracy: 48/500 (10%)\n",
            "\n",
            "Train Epoch: 155 \tLoss: 2.297391\n",
            "Train Epoch: 160 \tLoss: 2.297109\n",
            "Train Epoch: 165 \tLoss: 2.296825\n",
            "Train Epoch: 170 \tLoss: 2.296540\n",
            "Train Epoch: 175 \tLoss: 2.296259\n",
            "\n",
            "Test set: Avg. loss: 2.2999, Accuracy: 48/500 (10%)\n",
            "\n",
            "Train Epoch: 180 \tLoss: 2.295978\n",
            "Train Epoch: 185 \tLoss: 2.295699\n",
            "Train Epoch: 190 \tLoss: 2.295422\n",
            "Train Epoch: 195 \tLoss: 2.295147\n",
            "Train Epoch: 200 \tLoss: 2.294871\n",
            "\n",
            "Test set: Avg. loss: 2.2988, Accuracy: 48/500 (10%)\n",
            "\n",
            "Train Epoch: 205 \tLoss: 2.294593\n",
            "Train Epoch: 210 \tLoss: 2.294314\n",
            "Train Epoch: 215 \tLoss: 2.294035\n",
            "Train Epoch: 220 \tLoss: 2.293757\n",
            "Train Epoch: 225 \tLoss: 2.293480\n",
            "\n",
            "Test set: Avg. loss: 2.2976, Accuracy: 48/500 (10%)\n",
            "\n",
            "Train Epoch: 230 \tLoss: 2.293204\n",
            "Train Epoch: 235 \tLoss: 2.292927\n",
            "Train Epoch: 240 \tLoss: 2.292650\n",
            "Train Epoch: 245 \tLoss: 2.292373\n",
            "Train Epoch: 250 \tLoss: 2.292096\n",
            "\n",
            "Test set: Avg. loss: 2.2964, Accuracy: 51/500 (10%)\n",
            "\n",
            "Train Epoch: 255 \tLoss: 2.291817\n",
            "Train Epoch: 260 \tLoss: 2.291535\n",
            "Train Epoch: 265 \tLoss: 2.291251\n",
            "Train Epoch: 270 \tLoss: 2.290967\n",
            "Train Epoch: 275 \tLoss: 2.290680\n",
            "\n",
            "Test set: Avg. loss: 2.2952, Accuracy: 51/500 (10%)\n",
            "\n",
            "Train Epoch: 280 \tLoss: 2.290395\n",
            "Train Epoch: 285 \tLoss: 2.290112\n",
            "Train Epoch: 290 \tLoss: 2.289825\n",
            "Train Epoch: 295 \tLoss: 2.289541\n",
            "Train Epoch: 300 \tLoss: 2.289256\n",
            "\n",
            "Test set: Avg. loss: 2.2939, Accuracy: 52/500 (10%)\n",
            "\n",
            "Train Epoch: 305 \tLoss: 2.288972\n",
            "Train Epoch: 310 \tLoss: 2.288685\n",
            "Train Epoch: 315 \tLoss: 2.288398\n",
            "Train Epoch: 320 \tLoss: 2.288114\n",
            "Train Epoch: 325 \tLoss: 2.287829\n",
            "\n",
            "Test set: Avg. loss: 2.2927, Accuracy: 52/500 (10%)\n",
            "\n",
            "Train Epoch: 330 \tLoss: 2.287544\n",
            "Train Epoch: 335 \tLoss: 2.287259\n",
            "Train Epoch: 340 \tLoss: 2.286975\n",
            "Train Epoch: 345 \tLoss: 2.286694\n",
            "Train Epoch: 350 \tLoss: 2.286414\n",
            "\n",
            "Test set: Avg. loss: 2.2915, Accuracy: 55/500 (11%)\n",
            "\n",
            "Train Epoch: 355 \tLoss: 2.286134\n",
            "Train Epoch: 360 \tLoss: 2.285857\n",
            "Train Epoch: 365 \tLoss: 2.285580\n",
            "Train Epoch: 370 \tLoss: 2.285303\n",
            "Train Epoch: 375 \tLoss: 2.285032\n",
            "\n",
            "Test set: Avg. loss: 2.2904, Accuracy: 56/500 (11%)\n",
            "\n",
            "Train Epoch: 380 \tLoss: 2.284762\n",
            "Train Epoch: 385 \tLoss: 2.284494\n",
            "Train Epoch: 390 \tLoss: 2.284227\n",
            "Train Epoch: 395 \tLoss: 2.283961\n",
            "Train Epoch: 400 \tLoss: 2.283700\n",
            "\n",
            "Test set: Avg. loss: 2.2893, Accuracy: 55/500 (11%)\n",
            "\n",
            "Train Epoch: 405 \tLoss: 2.283441\n",
            "Train Epoch: 410 \tLoss: 2.283184\n",
            "Train Epoch: 415 \tLoss: 2.282927\n",
            "Train Epoch: 420 \tLoss: 2.282671\n",
            "Train Epoch: 425 \tLoss: 2.282418\n",
            "\n",
            "Test set: Avg. loss: 2.2882, Accuracy: 56/500 (11%)\n",
            "\n",
            "Train Epoch: 430 \tLoss: 2.282163\n",
            "Train Epoch: 435 \tLoss: 2.281909\n",
            "Train Epoch: 440 \tLoss: 2.281653\n",
            "Train Epoch: 445 \tLoss: 2.281397\n",
            "Train Epoch: 450 \tLoss: 2.281144\n",
            "\n",
            "Test set: Avg. loss: 2.2871, Accuracy: 60/500 (12%)\n",
            "\n",
            "Train Epoch: 455 \tLoss: 2.280890\n",
            "Train Epoch: 460 \tLoss: 2.280634\n",
            "Train Epoch: 465 \tLoss: 2.280375\n",
            "Train Epoch: 470 \tLoss: 2.280114\n",
            "Train Epoch: 475 \tLoss: 2.279858\n",
            "\n",
            "Test set: Avg. loss: 2.2861, Accuracy: 62/500 (12%)\n",
            "\n",
            "Train Epoch: 480 \tLoss: 2.279606\n",
            "Train Epoch: 485 \tLoss: 2.279357\n",
            "Train Epoch: 490 \tLoss: 2.279110\n",
            "Train Epoch: 495 \tLoss: 2.278867\n",
            "Train Epoch: 500 \tLoss: 2.278624\n",
            "\n",
            "Test set: Avg. loss: 2.2851, Accuracy: 65/500 (13%)\n",
            "\n",
            "Train Epoch: 505 \tLoss: 2.278382\n",
            "Train Epoch: 510 \tLoss: 2.278145\n",
            "Train Epoch: 515 \tLoss: 2.277910\n",
            "Train Epoch: 520 \tLoss: 2.277674\n",
            "Train Epoch: 525 \tLoss: 2.277441\n",
            "\n",
            "Test set: Avg. loss: 2.2842, Accuracy: 69/500 (14%)\n",
            "\n",
            "Train Epoch: 530 \tLoss: 2.277209\n",
            "Train Epoch: 535 \tLoss: 2.276978\n",
            "Train Epoch: 540 \tLoss: 2.276749\n",
            "Train Epoch: 545 \tLoss: 2.276518\n",
            "Train Epoch: 550 \tLoss: 2.276286\n",
            "\n",
            "Test set: Avg. loss: 2.2833, Accuracy: 69/500 (14%)\n",
            "\n",
            "Train Epoch: 555 \tLoss: 2.276054\n",
            "Train Epoch: 560 \tLoss: 2.275825\n",
            "Train Epoch: 565 \tLoss: 2.275596\n",
            "Train Epoch: 570 \tLoss: 2.275366\n",
            "Train Epoch: 575 \tLoss: 2.275142\n",
            "\n",
            "Test set: Avg. loss: 2.2824, Accuracy: 70/500 (14%)\n",
            "\n",
            "Train Epoch: 580 \tLoss: 2.274920\n",
            "Train Epoch: 585 \tLoss: 2.274702\n",
            "Train Epoch: 590 \tLoss: 2.274486\n",
            "Train Epoch: 595 \tLoss: 2.274271\n",
            "Train Epoch: 600 \tLoss: 2.274057\n",
            "\n",
            "Test set: Avg. loss: 2.2816, Accuracy: 73/500 (15%)\n",
            "\n",
            "Train Epoch: 605 \tLoss: 2.273842\n",
            "Train Epoch: 610 \tLoss: 2.273630\n",
            "Train Epoch: 615 \tLoss: 2.273417\n",
            "Train Epoch: 620 \tLoss: 2.273207\n",
            "Train Epoch: 625 \tLoss: 2.273000\n",
            "\n",
            "Test set: Avg. loss: 2.2808, Accuracy: 74/500 (15%)\n",
            "\n",
            "Train Epoch: 630 \tLoss: 2.272795\n",
            "Train Epoch: 635 \tLoss: 2.272590\n",
            "Train Epoch: 640 \tLoss: 2.272387\n",
            "Train Epoch: 645 \tLoss: 2.272184\n",
            "Train Epoch: 650 \tLoss: 2.271983\n",
            "\n",
            "Test set: Avg. loss: 2.2800, Accuracy: 74/500 (15%)\n",
            "\n",
            "Train Epoch: 655 \tLoss: 2.271785\n",
            "Train Epoch: 660 \tLoss: 2.271589\n",
            "Train Epoch: 665 \tLoss: 2.271395\n",
            "Train Epoch: 670 \tLoss: 2.271204\n",
            "Train Epoch: 675 \tLoss: 2.271013\n",
            "\n",
            "Test set: Avg. loss: 2.2792, Accuracy: 77/500 (15%)\n",
            "\n",
            "Train Epoch: 680 \tLoss: 2.270822\n",
            "Train Epoch: 685 \tLoss: 2.270634\n",
            "Train Epoch: 690 \tLoss: 2.270447\n",
            "Train Epoch: 695 \tLoss: 2.270260\n",
            "Train Epoch: 700 \tLoss: 2.270074\n",
            "\n",
            "Test set: Avg. loss: 2.2785, Accuracy: 83/500 (17%)\n",
            "\n",
            "Train Epoch: 705 \tLoss: 2.269887\n",
            "Train Epoch: 710 \tLoss: 2.269701\n",
            "Train Epoch: 715 \tLoss: 2.269516\n",
            "Train Epoch: 720 \tLoss: 2.269330\n",
            "Train Epoch: 725 \tLoss: 2.269148\n",
            "\n",
            "Test set: Avg. loss: 2.2777, Accuracy: 86/500 (17%)\n",
            "\n",
            "Train Epoch: 730 \tLoss: 2.268967\n",
            "Train Epoch: 735 \tLoss: 2.268788\n",
            "Train Epoch: 740 \tLoss: 2.268610\n",
            "Train Epoch: 745 \tLoss: 2.268434\n",
            "Train Epoch: 750 \tLoss: 2.268258\n",
            "\n",
            "Test set: Avg. loss: 2.2770, Accuracy: 87/500 (17%)\n",
            "\n",
            "Train Epoch: 755 \tLoss: 2.268085\n",
            "Train Epoch: 760 \tLoss: 2.267912\n",
            "Train Epoch: 765 \tLoss: 2.267741\n",
            "Train Epoch: 770 \tLoss: 2.267571\n",
            "Train Epoch: 775 \tLoss: 2.267401\n",
            "\n",
            "Test set: Avg. loss: 2.2763, Accuracy: 86/500 (17%)\n",
            "\n",
            "Train Epoch: 780 \tLoss: 2.267231\n",
            "Train Epoch: 785 \tLoss: 2.267064\n",
            "Train Epoch: 790 \tLoss: 2.266900\n",
            "Train Epoch: 795 \tLoss: 2.266737\n",
            "Train Epoch: 800 \tLoss: 2.266574\n",
            "\n",
            "Test set: Avg. loss: 2.2756, Accuracy: 86/500 (17%)\n",
            "\n",
            "Train Epoch: 805 \tLoss: 2.266413\n",
            "Train Epoch: 810 \tLoss: 2.266252\n",
            "Train Epoch: 815 \tLoss: 2.266093\n",
            "Train Epoch: 820 \tLoss: 2.265937\n",
            "Train Epoch: 825 \tLoss: 2.265782\n",
            "\n",
            "Test set: Avg. loss: 2.2749, Accuracy: 87/500 (17%)\n",
            "\n",
            "Train Epoch: 830 \tLoss: 2.265626\n",
            "Train Epoch: 835 \tLoss: 2.265471\n",
            "Train Epoch: 840 \tLoss: 2.265318\n",
            "Train Epoch: 845 \tLoss: 2.265167\n",
            "Train Epoch: 850 \tLoss: 2.265015\n",
            "\n",
            "Test set: Avg. loss: 2.2742, Accuracy: 89/500 (18%)\n",
            "\n",
            "Train Epoch: 855 \tLoss: 2.264866\n",
            "Train Epoch: 860 \tLoss: 2.264717\n",
            "Train Epoch: 865 \tLoss: 2.264570\n",
            "Train Epoch: 870 \tLoss: 2.264423\n",
            "Train Epoch: 875 \tLoss: 2.264278\n",
            "\n",
            "Test set: Avg. loss: 2.2736, Accuracy: 88/500 (18%)\n",
            "\n",
            "Train Epoch: 880 \tLoss: 2.264135\n",
            "Train Epoch: 885 \tLoss: 2.263994\n",
            "Train Epoch: 890 \tLoss: 2.263854\n",
            "Train Epoch: 895 \tLoss: 2.263715\n",
            "Train Epoch: 900 \tLoss: 2.263575\n",
            "\n",
            "Test set: Avg. loss: 2.2730, Accuracy: 88/500 (18%)\n",
            "\n",
            "Train Epoch: 905 \tLoss: 2.263437\n",
            "Train Epoch: 910 \tLoss: 2.263298\n",
            "Train Epoch: 915 \tLoss: 2.263160\n",
            "Train Epoch: 920 \tLoss: 2.263022\n",
            "Train Epoch: 925 \tLoss: 2.262884\n",
            "\n",
            "Test set: Avg. loss: 2.2724, Accuracy: 91/500 (18%)\n",
            "\n",
            "Train Epoch: 930 \tLoss: 2.262747\n",
            "Train Epoch: 935 \tLoss: 2.262609\n",
            "Train Epoch: 940 \tLoss: 2.262471\n",
            "Train Epoch: 945 \tLoss: 2.262335\n",
            "Train Epoch: 950 \tLoss: 2.262200\n",
            "\n",
            "Test set: Avg. loss: 2.2718, Accuracy: 92/500 (18%)\n",
            "\n",
            "Train Epoch: 955 \tLoss: 2.262067\n",
            "Train Epoch: 960 \tLoss: 2.261935\n",
            "Train Epoch: 965 \tLoss: 2.261805\n",
            "Train Epoch: 970 \tLoss: 2.261676\n",
            "Train Epoch: 975 \tLoss: 2.261547\n",
            "\n",
            "Test set: Avg. loss: 2.2712, Accuracy: 91/500 (18%)\n",
            "\n",
            "Train Epoch: 980 \tLoss: 2.261418\n",
            "Train Epoch: 985 \tLoss: 2.261290\n",
            "Train Epoch: 990 \tLoss: 2.261161\n",
            "Train Epoch: 995 \tLoss: 2.261034\n",
            "Train Epoch: 1000 \tLoss: 2.260908\n",
            "\n",
            "Test set: Avg. loss: 2.2706, Accuracy: 91/500 (18%)\n",
            "\n",
            "Train Epoch: 1005 \tLoss: 2.260782\n",
            "Train Epoch: 1010 \tLoss: 2.260657\n",
            "Train Epoch: 1015 \tLoss: 2.260533\n",
            "Train Epoch: 1020 \tLoss: 2.260410\n",
            "Train Epoch: 1025 \tLoss: 2.260287\n",
            "\n",
            "Test set: Avg. loss: 2.2700, Accuracy: 93/500 (19%)\n",
            "\n",
            "Train Epoch: 1030 \tLoss: 2.260164\n",
            "Train Epoch: 1035 \tLoss: 2.260042\n",
            "Train Epoch: 1040 \tLoss: 2.259921\n",
            "Train Epoch: 1045 \tLoss: 2.259802\n",
            "Train Epoch: 1050 \tLoss: 2.259681\n",
            "\n",
            "Test set: Avg. loss: 2.2694, Accuracy: 95/500 (19%)\n",
            "\n",
            "Train Epoch: 1055 \tLoss: 2.259561\n",
            "Train Epoch: 1060 \tLoss: 2.259440\n",
            "Train Epoch: 1065 \tLoss: 2.259319\n",
            "Train Epoch: 1070 \tLoss: 2.259199\n",
            "Train Epoch: 1075 \tLoss: 2.259078\n",
            "\n",
            "Test set: Avg. loss: 2.2689, Accuracy: 95/500 (19%)\n",
            "\n",
            "Train Epoch: 1080 \tLoss: 2.258960\n",
            "Train Epoch: 1085 \tLoss: 2.258840\n",
            "Train Epoch: 1090 \tLoss: 2.258721\n",
            "Train Epoch: 1095 \tLoss: 2.258602\n",
            "Train Epoch: 1100 \tLoss: 2.258484\n",
            "\n",
            "Test set: Avg. loss: 2.2684, Accuracy: 97/500 (19%)\n",
            "\n",
            "Train Epoch: 1105 \tLoss: 2.258368\n",
            "Train Epoch: 1110 \tLoss: 2.258252\n",
            "Train Epoch: 1115 \tLoss: 2.258137\n",
            "Train Epoch: 1120 \tLoss: 2.258024\n",
            "Train Epoch: 1125 \tLoss: 2.257911\n",
            "\n",
            "Test set: Avg. loss: 2.2678, Accuracy: 98/500 (20%)\n",
            "\n",
            "Train Epoch: 1130 \tLoss: 2.257799\n",
            "Train Epoch: 1135 \tLoss: 2.257688\n",
            "Train Epoch: 1140 \tLoss: 2.257579\n",
            "Train Epoch: 1145 \tLoss: 2.257470\n",
            "Train Epoch: 1150 \tLoss: 2.257361\n",
            "\n",
            "Test set: Avg. loss: 2.2674, Accuracy: 99/500 (20%)\n",
            "\n",
            "Train Epoch: 1155 \tLoss: 2.257253\n",
            "Train Epoch: 1160 \tLoss: 2.257145\n",
            "Train Epoch: 1165 \tLoss: 2.257039\n",
            "Train Epoch: 1170 \tLoss: 2.256933\n",
            "Train Epoch: 1175 \tLoss: 2.256827\n",
            "\n",
            "Test set: Avg. loss: 2.2669, Accuracy: 100/500 (20%)\n",
            "\n",
            "Train Epoch: 1180 \tLoss: 2.256721\n",
            "Train Epoch: 1185 \tLoss: 2.256616\n",
            "Train Epoch: 1190 \tLoss: 2.256510\n",
            "Train Epoch: 1195 \tLoss: 2.256407\n",
            "Train Epoch: 1200 \tLoss: 2.256304\n",
            "\n",
            "Test set: Avg. loss: 2.2664, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1205 \tLoss: 2.256202\n",
            "Train Epoch: 1210 \tLoss: 2.256101\n",
            "Train Epoch: 1215 \tLoss: 2.256001\n",
            "Train Epoch: 1220 \tLoss: 2.255901\n",
            "Train Epoch: 1225 \tLoss: 2.255801\n",
            "\n",
            "Test set: Avg. loss: 2.2659, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1230 \tLoss: 2.255701\n",
            "Train Epoch: 1235 \tLoss: 2.255602\n",
            "Train Epoch: 1240 \tLoss: 2.255502\n",
            "Train Epoch: 1245 \tLoss: 2.255404\n",
            "Train Epoch: 1250 \tLoss: 2.255306\n",
            "\n",
            "Test set: Avg. loss: 2.2655, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1255 \tLoss: 2.255209\n",
            "Train Epoch: 1260 \tLoss: 2.255113\n",
            "Train Epoch: 1265 \tLoss: 2.255017\n",
            "Train Epoch: 1270 \tLoss: 2.254921\n",
            "Train Epoch: 1275 \tLoss: 2.254826\n",
            "\n",
            "Test set: Avg. loss: 2.2650, Accuracy: 102/500 (20%)\n",
            "\n",
            "Train Epoch: 1280 \tLoss: 2.254732\n",
            "Train Epoch: 1285 \tLoss: 2.254638\n",
            "Train Epoch: 1290 \tLoss: 2.254544\n",
            "Train Epoch: 1295 \tLoss: 2.254449\n",
            "Train Epoch: 1300 \tLoss: 2.254355\n",
            "\n",
            "Test set: Avg. loss: 2.2646, Accuracy: 100/500 (20%)\n",
            "\n",
            "Train Epoch: 1305 \tLoss: 2.254261\n",
            "Train Epoch: 1310 \tLoss: 2.254167\n",
            "Train Epoch: 1315 \tLoss: 2.254074\n",
            "Train Epoch: 1320 \tLoss: 2.253980\n",
            "Train Epoch: 1325 \tLoss: 2.253887\n",
            "\n",
            "Test set: Avg. loss: 2.2642, Accuracy: 100/500 (20%)\n",
            "\n",
            "Train Epoch: 1330 \tLoss: 2.253794\n",
            "Train Epoch: 1335 \tLoss: 2.253702\n",
            "Train Epoch: 1340 \tLoss: 2.253609\n",
            "Train Epoch: 1345 \tLoss: 2.253516\n",
            "Train Epoch: 1350 \tLoss: 2.253424\n",
            "\n",
            "Test set: Avg. loss: 2.2638, Accuracy: 100/500 (20%)\n",
            "\n",
            "Train Epoch: 1355 \tLoss: 2.253333\n",
            "Train Epoch: 1360 \tLoss: 2.253242\n",
            "Train Epoch: 1365 \tLoss: 2.253152\n",
            "Train Epoch: 1370 \tLoss: 2.253063\n",
            "Train Epoch: 1375 \tLoss: 2.252974\n",
            "\n",
            "Test set: Avg. loss: 2.2633, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1380 \tLoss: 2.252885\n",
            "Train Epoch: 1385 \tLoss: 2.252796\n",
            "Train Epoch: 1390 \tLoss: 2.252708\n",
            "Train Epoch: 1395 \tLoss: 2.252620\n",
            "Train Epoch: 1400 \tLoss: 2.252532\n",
            "\n",
            "Test set: Avg. loss: 2.2629, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1405 \tLoss: 2.252444\n",
            "Train Epoch: 1410 \tLoss: 2.252358\n",
            "Train Epoch: 1415 \tLoss: 2.252272\n",
            "Train Epoch: 1420 \tLoss: 2.252186\n",
            "Train Epoch: 1425 \tLoss: 2.252100\n",
            "\n",
            "Test set: Avg. loss: 2.2625, Accuracy: 103/500 (21%)\n",
            "\n",
            "Train Epoch: 1430 \tLoss: 2.252014\n",
            "Train Epoch: 1435 \tLoss: 2.251929\n",
            "Train Epoch: 1440 \tLoss: 2.251844\n",
            "Train Epoch: 1445 \tLoss: 2.251761\n",
            "Train Epoch: 1450 \tLoss: 2.251678\n",
            "\n",
            "Test set: Avg. loss: 2.2622, Accuracy: 102/500 (20%)\n",
            "\n",
            "Train Epoch: 1455 \tLoss: 2.251595\n",
            "Train Epoch: 1460 \tLoss: 2.251513\n",
            "Train Epoch: 1465 \tLoss: 2.251429\n",
            "Train Epoch: 1470 \tLoss: 2.251346\n",
            "Train Epoch: 1475 \tLoss: 2.251263\n",
            "\n",
            "Test set: Avg. loss: 2.2618, Accuracy: 102/500 (20%)\n",
            "\n",
            "Train Epoch: 1480 \tLoss: 2.251182\n",
            "Train Epoch: 1485 \tLoss: 2.251100\n",
            "Train Epoch: 1490 \tLoss: 2.251019\n",
            "Train Epoch: 1495 \tLoss: 2.250937\n",
            "Train Epoch: 1500 \tLoss: 2.250856\n",
            "\n",
            "Test set: Avg. loss: 2.2614, Accuracy: 102/500 (20%)\n",
            "\n",
            "Train Epoch: 1505 \tLoss: 2.250774\n",
            "Train Epoch: 1510 \tLoss: 2.250694\n",
            "Train Epoch: 1515 \tLoss: 2.250612\n",
            "Train Epoch: 1520 \tLoss: 2.250532\n",
            "Train Epoch: 1525 \tLoss: 2.250452\n",
            "\n",
            "Test set: Avg. loss: 2.2610, Accuracy: 102/500 (20%)\n",
            "\n",
            "Train Epoch: 1530 \tLoss: 2.250373\n",
            "Train Epoch: 1535 \tLoss: 2.250293\n",
            "Train Epoch: 1540 \tLoss: 2.250215\n",
            "Train Epoch: 1545 \tLoss: 2.250137\n",
            "Train Epoch: 1550 \tLoss: 2.250058\n",
            "\n",
            "Test set: Avg. loss: 2.2607, Accuracy: 102/500 (20%)\n",
            "\n",
            "Train Epoch: 1555 \tLoss: 2.249980\n",
            "Train Epoch: 1560 \tLoss: 2.249903\n",
            "Train Epoch: 1565 \tLoss: 2.249827\n",
            "Train Epoch: 1570 \tLoss: 2.249751\n",
            "Train Epoch: 1575 \tLoss: 2.249675\n",
            "\n",
            "Test set: Avg. loss: 2.2604, Accuracy: 102/500 (20%)\n",
            "\n",
            "Train Epoch: 1580 \tLoss: 2.249599\n",
            "Train Epoch: 1585 \tLoss: 2.249524\n",
            "Train Epoch: 1590 \tLoss: 2.249449\n",
            "Train Epoch: 1595 \tLoss: 2.249373\n",
            "Train Epoch: 1600 \tLoss: 2.249298\n",
            "\n",
            "Test set: Avg. loss: 2.2600, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1605 \tLoss: 2.249222\n",
            "Train Epoch: 1610 \tLoss: 2.249146\n",
            "Train Epoch: 1615 \tLoss: 2.249070\n",
            "Train Epoch: 1620 \tLoss: 2.248994\n",
            "Train Epoch: 1625 \tLoss: 2.248918\n",
            "\n",
            "Test set: Avg. loss: 2.2597, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1630 \tLoss: 2.248843\n",
            "Train Epoch: 1635 \tLoss: 2.248769\n",
            "Train Epoch: 1640 \tLoss: 2.248694\n",
            "Train Epoch: 1645 \tLoss: 2.248620\n",
            "Train Epoch: 1650 \tLoss: 2.248545\n",
            "\n",
            "Test set: Avg. loss: 2.2594, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1655 \tLoss: 2.248472\n",
            "Train Epoch: 1660 \tLoss: 2.248400\n",
            "Train Epoch: 1665 \tLoss: 2.248328\n",
            "Train Epoch: 1670 \tLoss: 2.248258\n",
            "Train Epoch: 1675 \tLoss: 2.248188\n",
            "\n",
            "Test set: Avg. loss: 2.2591, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1680 \tLoss: 2.248118\n",
            "Train Epoch: 1685 \tLoss: 2.248049\n",
            "Train Epoch: 1690 \tLoss: 2.247980\n",
            "Train Epoch: 1695 \tLoss: 2.247910\n",
            "Train Epoch: 1700 \tLoss: 2.247841\n",
            "\n",
            "Test set: Avg. loss: 2.2587, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1705 \tLoss: 2.247772\n",
            "Train Epoch: 1710 \tLoss: 2.247703\n",
            "Train Epoch: 1715 \tLoss: 2.247633\n",
            "Train Epoch: 1720 \tLoss: 2.247564\n",
            "Train Epoch: 1725 \tLoss: 2.247495\n",
            "\n",
            "Test set: Avg. loss: 2.2584, Accuracy: 100/500 (20%)\n",
            "\n",
            "Train Epoch: 1730 \tLoss: 2.247425\n",
            "Train Epoch: 1735 \tLoss: 2.247356\n",
            "Train Epoch: 1740 \tLoss: 2.247288\n",
            "Train Epoch: 1745 \tLoss: 2.247220\n",
            "Train Epoch: 1750 \tLoss: 2.247152\n",
            "\n",
            "Test set: Avg. loss: 2.2581, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1755 \tLoss: 2.247084\n",
            "Train Epoch: 1760 \tLoss: 2.247015\n",
            "Train Epoch: 1765 \tLoss: 2.246947\n",
            "Train Epoch: 1770 \tLoss: 2.246879\n",
            "Train Epoch: 1775 \tLoss: 2.246810\n",
            "\n",
            "Test set: Avg. loss: 2.2578, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1780 \tLoss: 2.246742\n",
            "Train Epoch: 1785 \tLoss: 2.246673\n",
            "Train Epoch: 1790 \tLoss: 2.246604\n",
            "Train Epoch: 1795 \tLoss: 2.246536\n",
            "Train Epoch: 1800 \tLoss: 2.246468\n",
            "\n",
            "Test set: Avg. loss: 2.2575, Accuracy: 100/500 (20%)\n",
            "\n",
            "Train Epoch: 1805 \tLoss: 2.246400\n",
            "Train Epoch: 1810 \tLoss: 2.246333\n",
            "Train Epoch: 1815 \tLoss: 2.246265\n",
            "Train Epoch: 1820 \tLoss: 2.246197\n",
            "Train Epoch: 1825 \tLoss: 2.246129\n",
            "\n",
            "Test set: Avg. loss: 2.2572, Accuracy: 100/500 (20%)\n",
            "\n",
            "Train Epoch: 1830 \tLoss: 2.246061\n",
            "Train Epoch: 1835 \tLoss: 2.245994\n",
            "Train Epoch: 1840 \tLoss: 2.245927\n",
            "Train Epoch: 1845 \tLoss: 2.245860\n",
            "Train Epoch: 1850 \tLoss: 2.245793\n",
            "\n",
            "Test set: Avg. loss: 2.2569, Accuracy: 101/500 (20%)\n",
            "\n",
            "Train Epoch: 1855 \tLoss: 2.245726\n",
            "Train Epoch: 1860 \tLoss: 2.245661\n",
            "Train Epoch: 1865 \tLoss: 2.245596\n",
            "Train Epoch: 1870 \tLoss: 2.245531\n",
            "Train Epoch: 1875 \tLoss: 2.245466\n",
            "\n",
            "Test set: Avg. loss: 2.2566, Accuracy: 103/500 (21%)\n",
            "\n",
            "Train Epoch: 1880 \tLoss: 2.245402\n",
            "Train Epoch: 1885 \tLoss: 2.245338\n",
            "Train Epoch: 1890 \tLoss: 2.245274\n",
            "Train Epoch: 1895 \tLoss: 2.245210\n",
            "Train Epoch: 1900 \tLoss: 2.245147\n",
            "\n",
            "Test set: Avg. loss: 2.2563, Accuracy: 103/500 (21%)\n",
            "\n",
            "Train Epoch: 1905 \tLoss: 2.245084\n",
            "Train Epoch: 1910 \tLoss: 2.245020\n",
            "Train Epoch: 1915 \tLoss: 2.244958\n",
            "Train Epoch: 1920 \tLoss: 2.244896\n",
            "Train Epoch: 1925 \tLoss: 2.244834\n",
            "\n",
            "Test set: Avg. loss: 2.2560, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 1930 \tLoss: 2.244771\n",
            "Train Epoch: 1935 \tLoss: 2.244709\n",
            "Train Epoch: 1940 \tLoss: 2.244647\n",
            "Train Epoch: 1945 \tLoss: 2.244585\n",
            "Train Epoch: 1950 \tLoss: 2.244524\n",
            "\n",
            "Test set: Avg. loss: 2.2557, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 1955 \tLoss: 2.244462\n",
            "Train Epoch: 1960 \tLoss: 2.244400\n",
            "Train Epoch: 1965 \tLoss: 2.244339\n",
            "Train Epoch: 1970 \tLoss: 2.244278\n",
            "Train Epoch: 1975 \tLoss: 2.244218\n",
            "\n",
            "Test set: Avg. loss: 2.2555, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 1980 \tLoss: 2.244158\n",
            "Train Epoch: 1985 \tLoss: 2.244098\n",
            "Train Epoch: 1990 \tLoss: 2.244038\n",
            "Train Epoch: 1995 \tLoss: 2.243978\n",
            "Train Epoch: 2000 \tLoss: 2.243920\n",
            "\n",
            "Test set: Avg. loss: 2.2552, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2005 \tLoss: 2.243861\n",
            "Train Epoch: 2010 \tLoss: 2.243803\n",
            "Train Epoch: 2015 \tLoss: 2.243745\n",
            "Train Epoch: 2020 \tLoss: 2.243685\n",
            "Train Epoch: 2025 \tLoss: 2.243626\n",
            "\n",
            "Test set: Avg. loss: 2.2549, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 2030 \tLoss: 2.243567\n",
            "Train Epoch: 2035 \tLoss: 2.243509\n",
            "Train Epoch: 2040 \tLoss: 2.243450\n",
            "Train Epoch: 2045 \tLoss: 2.243392\n",
            "Train Epoch: 2050 \tLoss: 2.243335\n",
            "\n",
            "Test set: Avg. loss: 2.2546, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 2055 \tLoss: 2.243277\n",
            "Train Epoch: 2060 \tLoss: 2.243218\n",
            "Train Epoch: 2065 \tLoss: 2.243161\n",
            "Train Epoch: 2070 \tLoss: 2.243103\n",
            "Train Epoch: 2075 \tLoss: 2.243045\n",
            "\n",
            "Test set: Avg. loss: 2.2544, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 2080 \tLoss: 2.242987\n",
            "Train Epoch: 2085 \tLoss: 2.242929\n",
            "Train Epoch: 2090 \tLoss: 2.242871\n",
            "Train Epoch: 2095 \tLoss: 2.242814\n",
            "Train Epoch: 2100 \tLoss: 2.242757\n",
            "\n",
            "Test set: Avg. loss: 2.2541, Accuracy: 107/500 (21%)\n",
            "\n",
            "Train Epoch: 2105 \tLoss: 2.242699\n",
            "Train Epoch: 2110 \tLoss: 2.242642\n",
            "Train Epoch: 2115 \tLoss: 2.242584\n",
            "Train Epoch: 2120 \tLoss: 2.242527\n",
            "Train Epoch: 2125 \tLoss: 2.242470\n",
            "\n",
            "Test set: Avg. loss: 2.2539, Accuracy: 107/500 (21%)\n",
            "\n",
            "Train Epoch: 2130 \tLoss: 2.242412\n",
            "Train Epoch: 2135 \tLoss: 2.242355\n",
            "Train Epoch: 2140 \tLoss: 2.242297\n",
            "Train Epoch: 2145 \tLoss: 2.242240\n",
            "Train Epoch: 2150 \tLoss: 2.242183\n",
            "\n",
            "Test set: Avg. loss: 2.2536, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2155 \tLoss: 2.242127\n",
            "Train Epoch: 2160 \tLoss: 2.242070\n",
            "Train Epoch: 2165 \tLoss: 2.242014\n",
            "Train Epoch: 2170 \tLoss: 2.241957\n",
            "Train Epoch: 2175 \tLoss: 2.241902\n",
            "\n",
            "Test set: Avg. loss: 2.2533, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2180 \tLoss: 2.241847\n",
            "Train Epoch: 2185 \tLoss: 2.241792\n",
            "Train Epoch: 2190 \tLoss: 2.241737\n",
            "Train Epoch: 2195 \tLoss: 2.241681\n",
            "Train Epoch: 2200 \tLoss: 2.241627\n",
            "\n",
            "Test set: Avg. loss: 2.2531, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2205 \tLoss: 2.241573\n",
            "Train Epoch: 2210 \tLoss: 2.241518\n",
            "Train Epoch: 2215 \tLoss: 2.241463\n",
            "Train Epoch: 2220 \tLoss: 2.241408\n",
            "Train Epoch: 2225 \tLoss: 2.241354\n",
            "\n",
            "Test set: Avg. loss: 2.2528, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2230 \tLoss: 2.241299\n",
            "Train Epoch: 2235 \tLoss: 2.241244\n",
            "Train Epoch: 2240 \tLoss: 2.241190\n",
            "Train Epoch: 2245 \tLoss: 2.241136\n",
            "Train Epoch: 2250 \tLoss: 2.241082\n",
            "\n",
            "Test set: Avg. loss: 2.2525, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 2255 \tLoss: 2.241028\n",
            "Train Epoch: 2260 \tLoss: 2.240975\n",
            "Train Epoch: 2265 \tLoss: 2.240922\n",
            "Train Epoch: 2270 \tLoss: 2.240869\n",
            "Train Epoch: 2275 \tLoss: 2.240816\n",
            "\n",
            "Test set: Avg. loss: 2.2523, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2280 \tLoss: 2.240764\n",
            "Train Epoch: 2285 \tLoss: 2.240712\n",
            "Train Epoch: 2290 \tLoss: 2.240660\n",
            "Train Epoch: 2295 \tLoss: 2.240608\n",
            "Train Epoch: 2300 \tLoss: 2.240556\n",
            "\n",
            "Test set: Avg. loss: 2.2520, Accuracy: 103/500 (21%)\n",
            "\n",
            "Train Epoch: 2305 \tLoss: 2.240504\n",
            "Train Epoch: 2310 \tLoss: 2.240452\n",
            "Train Epoch: 2315 \tLoss: 2.240401\n",
            "Train Epoch: 2320 \tLoss: 2.240350\n",
            "Train Epoch: 2325 \tLoss: 2.240300\n",
            "\n",
            "Test set: Avg. loss: 2.2518, Accuracy: 103/500 (21%)\n",
            "\n",
            "Train Epoch: 2330 \tLoss: 2.240249\n",
            "Train Epoch: 2335 \tLoss: 2.240199\n",
            "Train Epoch: 2340 \tLoss: 2.240148\n",
            "Train Epoch: 2345 \tLoss: 2.240097\n",
            "Train Epoch: 2350 \tLoss: 2.240047\n",
            "\n",
            "Test set: Avg. loss: 2.2515, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2355 \tLoss: 2.239996\n",
            "Train Epoch: 2360 \tLoss: 2.239946\n",
            "Train Epoch: 2365 \tLoss: 2.239896\n",
            "Train Epoch: 2370 \tLoss: 2.239846\n",
            "Train Epoch: 2375 \tLoss: 2.239796\n",
            "\n",
            "Test set: Avg. loss: 2.2513, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2380 \tLoss: 2.239746\n",
            "Train Epoch: 2385 \tLoss: 2.239697\n",
            "Train Epoch: 2390 \tLoss: 2.239646\n",
            "Train Epoch: 2395 \tLoss: 2.239597\n",
            "Train Epoch: 2400 \tLoss: 2.239547\n",
            "\n",
            "Test set: Avg. loss: 2.2510, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2405 \tLoss: 2.239497\n",
            "Train Epoch: 2410 \tLoss: 2.239448\n",
            "Train Epoch: 2415 \tLoss: 2.239398\n",
            "Train Epoch: 2420 \tLoss: 2.239348\n",
            "Train Epoch: 2425 \tLoss: 2.239299\n",
            "\n",
            "Test set: Avg. loss: 2.2508, Accuracy: 103/500 (21%)\n",
            "\n",
            "Train Epoch: 2430 \tLoss: 2.239249\n",
            "Train Epoch: 2435 \tLoss: 2.239198\n",
            "Train Epoch: 2440 \tLoss: 2.239148\n",
            "Train Epoch: 2445 \tLoss: 2.239098\n",
            "Train Epoch: 2450 \tLoss: 2.239048\n",
            "\n",
            "Test set: Avg. loss: 2.2505, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2455 \tLoss: 2.238999\n",
            "Train Epoch: 2460 \tLoss: 2.238950\n",
            "Train Epoch: 2465 \tLoss: 2.238900\n",
            "Train Epoch: 2470 \tLoss: 2.238851\n",
            "Train Epoch: 2475 \tLoss: 2.238801\n",
            "\n",
            "Test set: Avg. loss: 2.2503, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 2480 \tLoss: 2.238752\n",
            "Train Epoch: 2485 \tLoss: 2.238702\n",
            "Train Epoch: 2490 \tLoss: 2.238652\n",
            "Train Epoch: 2495 \tLoss: 2.238602\n",
            "Train Epoch: 2500 \tLoss: 2.238553\n",
            "\n",
            "Test set: Avg. loss: 2.2500, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 2505 \tLoss: 2.238503\n",
            "Train Epoch: 2510 \tLoss: 2.238453\n",
            "Train Epoch: 2515 \tLoss: 2.238403\n",
            "Train Epoch: 2520 \tLoss: 2.238353\n",
            "Train Epoch: 2525 \tLoss: 2.238303\n",
            "\n",
            "Test set: Avg. loss: 2.2498, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2530 \tLoss: 2.238253\n",
            "Train Epoch: 2535 \tLoss: 2.238204\n",
            "Train Epoch: 2540 \tLoss: 2.238155\n",
            "Train Epoch: 2545 \tLoss: 2.238106\n",
            "Train Epoch: 2550 \tLoss: 2.238057\n",
            "\n",
            "Test set: Avg. loss: 2.2496, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2555 \tLoss: 2.238008\n",
            "Train Epoch: 2560 \tLoss: 2.237960\n",
            "Train Epoch: 2565 \tLoss: 2.237913\n",
            "Train Epoch: 2570 \tLoss: 2.237865\n",
            "Train Epoch: 2575 \tLoss: 2.237817\n",
            "\n",
            "Test set: Avg. loss: 2.2493, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2580 \tLoss: 2.237770\n",
            "Train Epoch: 2585 \tLoss: 2.237722\n",
            "Train Epoch: 2590 \tLoss: 2.237675\n",
            "Train Epoch: 2595 \tLoss: 2.237628\n",
            "Train Epoch: 2600 \tLoss: 2.237580\n",
            "\n",
            "Test set: Avg. loss: 2.2491, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 2605 \tLoss: 2.237533\n",
            "Train Epoch: 2610 \tLoss: 2.237487\n",
            "Train Epoch: 2615 \tLoss: 2.237441\n",
            "Train Epoch: 2620 \tLoss: 2.237395\n",
            "Train Epoch: 2625 \tLoss: 2.237349\n",
            "\n",
            "Test set: Avg. loss: 2.2488, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 2630 \tLoss: 2.237303\n",
            "Train Epoch: 2635 \tLoss: 2.237258\n",
            "Train Epoch: 2640 \tLoss: 2.237213\n",
            "Train Epoch: 2645 \tLoss: 2.237168\n",
            "Train Epoch: 2650 \tLoss: 2.237123\n",
            "\n",
            "Test set: Avg. loss: 2.2486, Accuracy: 106/500 (21%)\n",
            "\n",
            "Train Epoch: 2655 \tLoss: 2.237079\n",
            "Train Epoch: 2660 \tLoss: 2.237034\n",
            "Train Epoch: 2665 \tLoss: 2.236990\n",
            "Train Epoch: 2670 \tLoss: 2.236945\n",
            "Train Epoch: 2675 \tLoss: 2.236901\n",
            "\n",
            "Test set: Avg. loss: 2.2484, Accuracy: 106/500 (21%)\n",
            "\n",
            "Train Epoch: 2680 \tLoss: 2.236857\n",
            "Train Epoch: 2685 \tLoss: 2.236814\n",
            "Train Epoch: 2690 \tLoss: 2.236770\n",
            "Train Epoch: 2695 \tLoss: 2.236728\n",
            "Train Epoch: 2700 \tLoss: 2.236685\n",
            "\n",
            "Test set: Avg. loss: 2.2482, Accuracy: 106/500 (21%)\n",
            "\n",
            "Train Epoch: 2705 \tLoss: 2.236642\n",
            "Train Epoch: 2710 \tLoss: 2.236599\n",
            "Train Epoch: 2715 \tLoss: 2.236556\n",
            "Train Epoch: 2720 \tLoss: 2.236512\n",
            "Train Epoch: 2725 \tLoss: 2.236469\n",
            "\n",
            "Test set: Avg. loss: 2.2479, Accuracy: 106/500 (21%)\n",
            "\n",
            "Train Epoch: 2730 \tLoss: 2.236426\n",
            "Train Epoch: 2735 \tLoss: 2.236382\n",
            "Train Epoch: 2740 \tLoss: 2.236339\n",
            "Train Epoch: 2745 \tLoss: 2.236297\n",
            "Train Epoch: 2750 \tLoss: 2.236254\n",
            "\n",
            "Test set: Avg. loss: 2.2477, Accuracy: 106/500 (21%)\n",
            "\n",
            "Train Epoch: 2755 \tLoss: 2.236211\n",
            "Train Epoch: 2760 \tLoss: 2.236168\n",
            "Train Epoch: 2765 \tLoss: 2.236126\n",
            "Train Epoch: 2770 \tLoss: 2.236084\n",
            "Train Epoch: 2775 \tLoss: 2.236042\n",
            "\n",
            "Test set: Avg. loss: 2.2475, Accuracy: 106/500 (21%)\n",
            "\n",
            "Train Epoch: 2780 \tLoss: 2.236000\n",
            "Train Epoch: 2785 \tLoss: 2.235958\n",
            "Train Epoch: 2790 \tLoss: 2.235915\n",
            "Train Epoch: 2795 \tLoss: 2.235873\n",
            "Train Epoch: 2800 \tLoss: 2.235831\n",
            "\n",
            "Test set: Avg. loss: 2.2472, Accuracy: 106/500 (21%)\n",
            "\n",
            "Train Epoch: 2805 \tLoss: 2.235790\n",
            "Train Epoch: 2810 \tLoss: 2.235748\n",
            "Train Epoch: 2815 \tLoss: 2.235707\n",
            "Train Epoch: 2820 \tLoss: 2.235666\n",
            "Train Epoch: 2825 \tLoss: 2.235625\n",
            "\n",
            "Test set: Avg. loss: 2.2470, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 2830 \tLoss: 2.235584\n",
            "Train Epoch: 2835 \tLoss: 2.235543\n",
            "Train Epoch: 2840 \tLoss: 2.235502\n",
            "Train Epoch: 2845 \tLoss: 2.235461\n",
            "Train Epoch: 2850 \tLoss: 2.235421\n",
            "\n",
            "Test set: Avg. loss: 2.2468, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 2855 \tLoss: 2.235380\n",
            "Train Epoch: 2860 \tLoss: 2.235340\n",
            "Train Epoch: 2865 \tLoss: 2.235299\n",
            "Train Epoch: 2870 \tLoss: 2.235258\n",
            "Train Epoch: 2875 \tLoss: 2.235217\n",
            "\n",
            "Test set: Avg. loss: 2.2466, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 2880 \tLoss: 2.235177\n",
            "Train Epoch: 2885 \tLoss: 2.235136\n",
            "Train Epoch: 2890 \tLoss: 2.235095\n",
            "Train Epoch: 2895 \tLoss: 2.235055\n",
            "Train Epoch: 2900 \tLoss: 2.235015\n",
            "\n",
            "Test set: Avg. loss: 2.2464, Accuracy: 106/500 (21%)\n",
            "\n",
            "Train Epoch: 2905 \tLoss: 2.234975\n",
            "Train Epoch: 2910 \tLoss: 2.234934\n",
            "Train Epoch: 2915 \tLoss: 2.234894\n",
            "Train Epoch: 2920 \tLoss: 2.234854\n",
            "Train Epoch: 2925 \tLoss: 2.234813\n",
            "\n",
            "Test set: Avg. loss: 2.2462, Accuracy: 108/500 (22%)\n",
            "\n",
            "Train Epoch: 2930 \tLoss: 2.234773\n",
            "Train Epoch: 2935 \tLoss: 2.234733\n",
            "Train Epoch: 2940 \tLoss: 2.234693\n",
            "Train Epoch: 2945 \tLoss: 2.234653\n",
            "Train Epoch: 2950 \tLoss: 2.234613\n",
            "\n",
            "Test set: Avg. loss: 2.2460, Accuracy: 108/500 (22%)\n",
            "\n",
            "Train Epoch: 2955 \tLoss: 2.234574\n",
            "Train Epoch: 2960 \tLoss: 2.234535\n",
            "Train Epoch: 2965 \tLoss: 2.234495\n",
            "Train Epoch: 2970 \tLoss: 2.234456\n",
            "Train Epoch: 2975 \tLoss: 2.234418\n",
            "\n",
            "Test set: Avg. loss: 2.2458, Accuracy: 108/500 (22%)\n",
            "\n",
            "Train Epoch: 2980 \tLoss: 2.234379\n",
            "Train Epoch: 2985 \tLoss: 2.234341\n",
            "Train Epoch: 2990 \tLoss: 2.234303\n",
            "Train Epoch: 2995 \tLoss: 2.234264\n",
            "Train Epoch: 3000 \tLoss: 2.234226\n",
            "\n",
            "Test set: Avg. loss: 2.2456, Accuracy: 108/500 (22%)\n",
            "\n",
            "Train Epoch: 3005 \tLoss: 2.234188\n",
            "Train Epoch: 3010 \tLoss: 2.234150\n",
            "Train Epoch: 3015 \tLoss: 2.234113\n",
            "Train Epoch: 3020 \tLoss: 2.234075\n",
            "Train Epoch: 3025 \tLoss: 2.234037\n",
            "\n",
            "Test set: Avg. loss: 2.2454, Accuracy: 109/500 (22%)\n",
            "\n",
            "Train Epoch: 3030 \tLoss: 2.234000\n",
            "Train Epoch: 3035 \tLoss: 2.233962\n",
            "Train Epoch: 3040 \tLoss: 2.233924\n",
            "Train Epoch: 3045 \tLoss: 2.233886\n",
            "Train Epoch: 3050 \tLoss: 2.233849\n",
            "\n",
            "Test set: Avg. loss: 2.2451, Accuracy: 108/500 (22%)\n",
            "\n",
            "Train Epoch: 3055 \tLoss: 2.233811\n",
            "Train Epoch: 3060 \tLoss: 2.233773\n",
            "Train Epoch: 3065 \tLoss: 2.233736\n",
            "Train Epoch: 3070 \tLoss: 2.233698\n",
            "Train Epoch: 3075 \tLoss: 2.233661\n",
            "\n",
            "Test set: Avg. loss: 2.2449, Accuracy: 108/500 (22%)\n",
            "\n",
            "Train Epoch: 3080 \tLoss: 2.233624\n",
            "Train Epoch: 3085 \tLoss: 2.233587\n",
            "Train Epoch: 3090 \tLoss: 2.233550\n",
            "Train Epoch: 3095 \tLoss: 2.233513\n",
            "Train Epoch: 3100 \tLoss: 2.233476\n",
            "\n",
            "Test set: Avg. loss: 2.2447, Accuracy: 109/500 (22%)\n",
            "\n",
            "Train Epoch: 3105 \tLoss: 2.233439\n",
            "Train Epoch: 3110 \tLoss: 2.233402\n",
            "Train Epoch: 3115 \tLoss: 2.233365\n",
            "Train Epoch: 3120 \tLoss: 2.233328\n",
            "Train Epoch: 3125 \tLoss: 2.233291\n",
            "\n",
            "Test set: Avg. loss: 2.2445, Accuracy: 109/500 (22%)\n",
            "\n",
            "Train Epoch: 3130 \tLoss: 2.233255\n",
            "Train Epoch: 3135 \tLoss: 2.233218\n",
            "Train Epoch: 3140 \tLoss: 2.233181\n",
            "Train Epoch: 3145 \tLoss: 2.233144\n",
            "Train Epoch: 3150 \tLoss: 2.233107\n",
            "\n",
            "Test set: Avg. loss: 2.2443, Accuracy: 109/500 (22%)\n",
            "\n",
            "Train Epoch: 3155 \tLoss: 2.233070\n",
            "Train Epoch: 3160 \tLoss: 2.233033\n",
            "Train Epoch: 3165 \tLoss: 2.232996\n",
            "Train Epoch: 3170 \tLoss: 2.232960\n",
            "Train Epoch: 3175 \tLoss: 2.232923\n",
            "\n",
            "Test set: Avg. loss: 2.2441, Accuracy: 109/500 (22%)\n",
            "\n",
            "Train Epoch: 3180 \tLoss: 2.232886\n",
            "Train Epoch: 3185 \tLoss: 2.232849\n",
            "Train Epoch: 3190 \tLoss: 2.232813\n",
            "Train Epoch: 3195 \tLoss: 2.232776\n",
            "Train Epoch: 3200 \tLoss: 2.232740\n",
            "\n",
            "Test set: Avg. loss: 2.2439, Accuracy: 110/500 (22%)\n",
            "\n",
            "Train Epoch: 3205 \tLoss: 2.232704\n",
            "Train Epoch: 3210 \tLoss: 2.232667\n",
            "Train Epoch: 3215 \tLoss: 2.232631\n",
            "Train Epoch: 3220 \tLoss: 2.232595\n",
            "Train Epoch: 3225 \tLoss: 2.232558\n",
            "\n",
            "Test set: Avg. loss: 2.2437, Accuracy: 110/500 (22%)\n",
            "\n",
            "Train Epoch: 3230 \tLoss: 2.232522\n",
            "Train Epoch: 3235 \tLoss: 2.232486\n",
            "Train Epoch: 3240 \tLoss: 2.232450\n",
            "Train Epoch: 3245 \tLoss: 2.232414\n",
            "Train Epoch: 3250 \tLoss: 2.232377\n",
            "\n",
            "Test set: Avg. loss: 2.2435, Accuracy: 109/500 (22%)\n",
            "\n",
            "Train Epoch: 3255 \tLoss: 2.232341\n",
            "Train Epoch: 3260 \tLoss: 2.232304\n",
            "Train Epoch: 3265 \tLoss: 2.232268\n",
            "Train Epoch: 3270 \tLoss: 2.232231\n",
            "Train Epoch: 3275 \tLoss: 2.232194\n",
            "\n",
            "Test set: Avg. loss: 2.2433, Accuracy: 109/500 (22%)\n",
            "\n",
            "Train Epoch: 3280 \tLoss: 2.232158\n",
            "Train Epoch: 3285 \tLoss: 2.232121\n",
            "Train Epoch: 3290 \tLoss: 2.232085\n",
            "Train Epoch: 3295 \tLoss: 2.232048\n",
            "Train Epoch: 3300 \tLoss: 2.232012\n",
            "\n",
            "Test set: Avg. loss: 2.2431, Accuracy: 109/500 (22%)\n",
            "\n",
            "Train Epoch: 3305 \tLoss: 2.231975\n",
            "Train Epoch: 3310 \tLoss: 2.231939\n",
            "Train Epoch: 3315 \tLoss: 2.231902\n",
            "Train Epoch: 3320 \tLoss: 2.231866\n",
            "Train Epoch: 3325 \tLoss: 2.231830\n",
            "\n",
            "Test set: Avg. loss: 2.2429, Accuracy: 110/500 (22%)\n",
            "\n",
            "Train Epoch: 3330 \tLoss: 2.231794\n",
            "Train Epoch: 3335 \tLoss: 2.231758\n",
            "Train Epoch: 3340 \tLoss: 2.231721\n",
            "Train Epoch: 3345 \tLoss: 2.231686\n",
            "Train Epoch: 3350 \tLoss: 2.231650\n",
            "\n",
            "Test set: Avg. loss: 2.2427, Accuracy: 109/500 (22%)\n",
            "\n",
            "Train Epoch: 3355 \tLoss: 2.231615\n",
            "Train Epoch: 3360 \tLoss: 2.231580\n",
            "Train Epoch: 3365 \tLoss: 2.231546\n",
            "Train Epoch: 3370 \tLoss: 2.231512\n",
            "Train Epoch: 3375 \tLoss: 2.231477\n",
            "\n",
            "Test set: Avg. loss: 2.2426, Accuracy: 109/500 (22%)\n",
            "\n",
            "Train Epoch: 3380 \tLoss: 2.231443\n",
            "Train Epoch: 3385 \tLoss: 2.231409\n",
            "Train Epoch: 3390 \tLoss: 2.231375\n",
            "Train Epoch: 3395 \tLoss: 2.231342\n",
            "Train Epoch: 3400 \tLoss: 2.231308\n",
            "\n",
            "Test set: Avg. loss: 2.2424, Accuracy: 110/500 (22%)\n",
            "\n",
            "Train Epoch: 3405 \tLoss: 2.231274\n",
            "Train Epoch: 3410 \tLoss: 2.231240\n",
            "Train Epoch: 3415 \tLoss: 2.231207\n",
            "Train Epoch: 3420 \tLoss: 2.231173\n",
            "Train Epoch: 3425 \tLoss: 2.231140\n",
            "\n",
            "Test set: Avg. loss: 2.2422, Accuracy: 111/500 (22%)\n",
            "\n",
            "Train Epoch: 3430 \tLoss: 2.231107\n",
            "Train Epoch: 3435 \tLoss: 2.231074\n",
            "Train Epoch: 3440 \tLoss: 2.231041\n",
            "Train Epoch: 3445 \tLoss: 2.231008\n",
            "Train Epoch: 3450 \tLoss: 2.230976\n",
            "\n",
            "Test set: Avg. loss: 2.2421, Accuracy: 112/500 (22%)\n",
            "\n",
            "Train Epoch: 3455 \tLoss: 2.230943\n",
            "Train Epoch: 3460 \tLoss: 2.230910\n",
            "Train Epoch: 3465 \tLoss: 2.230878\n",
            "Train Epoch: 3470 \tLoss: 2.230845\n",
            "Train Epoch: 3475 \tLoss: 2.230813\n",
            "\n",
            "Test set: Avg. loss: 2.2419, Accuracy: 112/500 (22%)\n",
            "\n",
            "Train Epoch: 3480 \tLoss: 2.230780\n",
            "Train Epoch: 3485 \tLoss: 2.230747\n",
            "Train Epoch: 3490 \tLoss: 2.230714\n",
            "Train Epoch: 3495 \tLoss: 2.230682\n",
            "Train Epoch: 3500 \tLoss: 2.230650\n",
            "\n",
            "Test set: Avg. loss: 2.2417, Accuracy: 112/500 (22%)\n",
            "\n",
            "Train Epoch: 3505 \tLoss: 2.230617\n",
            "Train Epoch: 3510 \tLoss: 2.230585\n",
            "Train Epoch: 3515 \tLoss: 2.230552\n",
            "Train Epoch: 3520 \tLoss: 2.230520\n",
            "Train Epoch: 3525 \tLoss: 2.230488\n",
            "\n",
            "Test set: Avg. loss: 2.2416, Accuracy: 112/500 (22%)\n",
            "\n",
            "Train Epoch: 3530 \tLoss: 2.230455\n",
            "Train Epoch: 3535 \tLoss: 2.230424\n",
            "Train Epoch: 3540 \tLoss: 2.230391\n",
            "Train Epoch: 3545 \tLoss: 2.230359\n",
            "Train Epoch: 3550 \tLoss: 2.230327\n",
            "\n",
            "Test set: Avg. loss: 2.2414, Accuracy: 112/500 (22%)\n",
            "\n",
            "Train Epoch: 3555 \tLoss: 2.230295\n",
            "Train Epoch: 3560 \tLoss: 2.230263\n",
            "Train Epoch: 3565 \tLoss: 2.230231\n",
            "Train Epoch: 3570 \tLoss: 2.230198\n",
            "Train Epoch: 3575 \tLoss: 2.230166\n",
            "\n",
            "Test set: Avg. loss: 2.2413, Accuracy: 112/500 (22%)\n",
            "\n",
            "Train Epoch: 3580 \tLoss: 2.230134\n",
            "Train Epoch: 3585 \tLoss: 2.230101\n",
            "Train Epoch: 3590 \tLoss: 2.230069\n",
            "Train Epoch: 3595 \tLoss: 2.230036\n",
            "Train Epoch: 3600 \tLoss: 2.230004\n",
            "\n",
            "Test set: Avg. loss: 2.2411, Accuracy: 113/500 (23%)\n",
            "\n",
            "Train Epoch: 3605 \tLoss: 2.229972\n",
            "Train Epoch: 3610 \tLoss: 2.229940\n",
            "Train Epoch: 3615 \tLoss: 2.229907\n",
            "Train Epoch: 3620 \tLoss: 2.229875\n",
            "Train Epoch: 3625 \tLoss: 2.229843\n",
            "\n",
            "Test set: Avg. loss: 2.2410, Accuracy: 113/500 (23%)\n",
            "\n",
            "Train Epoch: 3630 \tLoss: 2.229810\n",
            "Train Epoch: 3635 \tLoss: 2.229779\n",
            "Train Epoch: 3640 \tLoss: 2.229747\n",
            "Train Epoch: 3645 \tLoss: 2.229715\n",
            "Train Epoch: 3650 \tLoss: 2.229684\n",
            "\n",
            "Test set: Avg. loss: 2.2408, Accuracy: 114/500 (23%)\n",
            "\n",
            "Train Epoch: 3655 \tLoss: 2.229652\n",
            "Train Epoch: 3660 \tLoss: 2.229620\n",
            "Train Epoch: 3665 \tLoss: 2.229589\n",
            "Train Epoch: 3670 \tLoss: 2.229557\n",
            "Train Epoch: 3675 \tLoss: 2.229526\n",
            "\n",
            "Test set: Avg. loss: 2.2407, Accuracy: 114/500 (23%)\n",
            "\n",
            "Train Epoch: 3680 \tLoss: 2.229494\n",
            "Train Epoch: 3685 \tLoss: 2.229463\n",
            "Train Epoch: 3690 \tLoss: 2.229432\n",
            "Train Epoch: 3695 \tLoss: 2.229401\n",
            "Train Epoch: 3700 \tLoss: 2.229371\n",
            "\n",
            "Test set: Avg. loss: 2.2405, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 3705 \tLoss: 2.229340\n",
            "Train Epoch: 3710 \tLoss: 2.229309\n",
            "Train Epoch: 3715 \tLoss: 2.229279\n",
            "Train Epoch: 3720 \tLoss: 2.229249\n",
            "Train Epoch: 3725 \tLoss: 2.229218\n",
            "\n",
            "Test set: Avg. loss: 2.2403, Accuracy: 116/500 (23%)\n",
            "\n",
            "Train Epoch: 3730 \tLoss: 2.229188\n",
            "Train Epoch: 3735 \tLoss: 2.229158\n",
            "Train Epoch: 3740 \tLoss: 2.229127\n",
            "Train Epoch: 3745 \tLoss: 2.229097\n",
            "Train Epoch: 3750 \tLoss: 2.229067\n",
            "\n",
            "Test set: Avg. loss: 2.2402, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 3755 \tLoss: 2.229036\n",
            "Train Epoch: 3760 \tLoss: 2.229006\n",
            "Train Epoch: 3765 \tLoss: 2.228976\n",
            "Train Epoch: 3770 \tLoss: 2.228945\n",
            "Train Epoch: 3775 \tLoss: 2.228915\n",
            "\n",
            "Test set: Avg. loss: 2.2400, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 3780 \tLoss: 2.228885\n",
            "Train Epoch: 3785 \tLoss: 2.228854\n",
            "Train Epoch: 3790 \tLoss: 2.228825\n",
            "Train Epoch: 3795 \tLoss: 2.228795\n",
            "Train Epoch: 3800 \tLoss: 2.228766\n",
            "\n",
            "Test set: Avg. loss: 2.2399, Accuracy: 116/500 (23%)\n",
            "\n",
            "Train Epoch: 3805 \tLoss: 2.228736\n",
            "Train Epoch: 3810 \tLoss: 2.228706\n",
            "Train Epoch: 3815 \tLoss: 2.228677\n",
            "Train Epoch: 3820 \tLoss: 2.228648\n",
            "Train Epoch: 3825 \tLoss: 2.228618\n",
            "\n",
            "Test set: Avg. loss: 2.2398, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 3830 \tLoss: 2.228590\n",
            "Train Epoch: 3835 \tLoss: 2.228560\n",
            "Train Epoch: 3840 \tLoss: 2.228531\n",
            "Train Epoch: 3845 \tLoss: 2.228503\n",
            "Train Epoch: 3850 \tLoss: 2.228475\n",
            "\n",
            "Test set: Avg. loss: 2.2396, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 3855 \tLoss: 2.228446\n",
            "Train Epoch: 3860 \tLoss: 2.228417\n",
            "Train Epoch: 3865 \tLoss: 2.228389\n",
            "Train Epoch: 3870 \tLoss: 2.228361\n",
            "Train Epoch: 3875 \tLoss: 2.228333\n",
            "\n",
            "Test set: Avg. loss: 2.2395, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 3880 \tLoss: 2.228304\n",
            "Train Epoch: 3885 \tLoss: 2.228276\n",
            "Train Epoch: 3890 \tLoss: 2.228248\n",
            "Train Epoch: 3895 \tLoss: 2.228220\n",
            "Train Epoch: 3900 \tLoss: 2.228192\n",
            "\n",
            "Test set: Avg. loss: 2.2394, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 3905 \tLoss: 2.228164\n",
            "Train Epoch: 3910 \tLoss: 2.228137\n",
            "Train Epoch: 3915 \tLoss: 2.228109\n",
            "Train Epoch: 3920 \tLoss: 2.228081\n",
            "Train Epoch: 3925 \tLoss: 2.228054\n",
            "\n",
            "Test set: Avg. loss: 2.2392, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 3930 \tLoss: 2.228026\n",
            "Train Epoch: 3935 \tLoss: 2.227998\n",
            "Train Epoch: 3940 \tLoss: 2.227971\n",
            "Train Epoch: 3945 \tLoss: 2.227943\n",
            "Train Epoch: 3950 \tLoss: 2.227916\n",
            "\n",
            "Test set: Avg. loss: 2.2391, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 3955 \tLoss: 2.227888\n",
            "Train Epoch: 3960 \tLoss: 2.227861\n",
            "Train Epoch: 3965 \tLoss: 2.227834\n",
            "Train Epoch: 3970 \tLoss: 2.227806\n",
            "Train Epoch: 3975 \tLoss: 2.227778\n",
            "\n",
            "Test set: Avg. loss: 2.2390, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 3980 \tLoss: 2.227750\n",
            "Train Epoch: 3985 \tLoss: 2.227723\n",
            "Train Epoch: 3990 \tLoss: 2.227694\n",
            "Train Epoch: 3995 \tLoss: 2.227667\n",
            "Train Epoch: 4000 \tLoss: 2.227639\n",
            "\n",
            "Test set: Avg. loss: 2.2389, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 4005 \tLoss: 2.227612\n",
            "Train Epoch: 4010 \tLoss: 2.227584\n",
            "Train Epoch: 4015 \tLoss: 2.227556\n",
            "Train Epoch: 4020 \tLoss: 2.227529\n",
            "Train Epoch: 4025 \tLoss: 2.227501\n",
            "\n",
            "Test set: Avg. loss: 2.2387, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 4030 \tLoss: 2.227474\n",
            "Train Epoch: 4035 \tLoss: 2.227447\n",
            "Train Epoch: 4040 \tLoss: 2.227420\n",
            "Train Epoch: 4045 \tLoss: 2.227393\n",
            "Train Epoch: 4050 \tLoss: 2.227366\n",
            "\n",
            "Test set: Avg. loss: 2.2386, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 4055 \tLoss: 2.227339\n",
            "Train Epoch: 4060 \tLoss: 2.227312\n",
            "Train Epoch: 4065 \tLoss: 2.227285\n",
            "Train Epoch: 4070 \tLoss: 2.227258\n",
            "Train Epoch: 4075 \tLoss: 2.227231\n",
            "\n",
            "Test set: Avg. loss: 2.2385, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 4080 \tLoss: 2.227205\n",
            "Train Epoch: 4085 \tLoss: 2.227178\n",
            "Train Epoch: 4090 \tLoss: 2.227151\n",
            "Train Epoch: 4095 \tLoss: 2.227125\n",
            "Train Epoch: 4100 \tLoss: 2.227099\n",
            "\n",
            "Test set: Avg. loss: 2.2384, Accuracy: 116/500 (23%)\n",
            "\n",
            "Train Epoch: 4105 \tLoss: 2.227072\n",
            "Train Epoch: 4110 \tLoss: 2.227046\n",
            "Train Epoch: 4115 \tLoss: 2.227020\n",
            "Train Epoch: 4120 \tLoss: 2.226993\n",
            "Train Epoch: 4125 \tLoss: 2.226967\n",
            "\n",
            "Test set: Avg. loss: 2.2383, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 4130 \tLoss: 2.226940\n",
            "Train Epoch: 4135 \tLoss: 2.226914\n",
            "Train Epoch: 4140 \tLoss: 2.226888\n",
            "Train Epoch: 4145 \tLoss: 2.226862\n",
            "Train Epoch: 4150 \tLoss: 2.226835\n",
            "\n",
            "Test set: Avg. loss: 2.2381, Accuracy: 115/500 (23%)\n",
            "\n",
            "Train Epoch: 4155 \tLoss: 2.226809\n",
            "Train Epoch: 4160 \tLoss: 2.226783\n",
            "Train Epoch: 4165 \tLoss: 2.226757\n",
            "Train Epoch: 4170 \tLoss: 2.226731\n",
            "Train Epoch: 4175 \tLoss: 2.226705\n",
            "\n",
            "Test set: Avg. loss: 2.2380, Accuracy: 116/500 (23%)\n",
            "\n",
            "Train Epoch: 4180 \tLoss: 2.226679\n",
            "Train Epoch: 4185 \tLoss: 2.226653\n",
            "Train Epoch: 4190 \tLoss: 2.226627\n",
            "Train Epoch: 4195 \tLoss: 2.226601\n",
            "Train Epoch: 4200 \tLoss: 2.226575\n",
            "\n",
            "Test set: Avg. loss: 2.2379, Accuracy: 116/500 (23%)\n",
            "\n",
            "Train Epoch: 4205 \tLoss: 2.226549\n",
            "Train Epoch: 4210 \tLoss: 2.226524\n",
            "Train Epoch: 4215 \tLoss: 2.226498\n",
            "Train Epoch: 4220 \tLoss: 2.226473\n",
            "Train Epoch: 4225 \tLoss: 2.226447\n",
            "\n",
            "Test set: Avg. loss: 2.2378, Accuracy: 116/500 (23%)\n",
            "\n",
            "Train Epoch: 4230 \tLoss: 2.226421\n",
            "Train Epoch: 4235 \tLoss: 2.226396\n",
            "Train Epoch: 4240 \tLoss: 2.226371\n",
            "Train Epoch: 4245 \tLoss: 2.226346\n",
            "Train Epoch: 4250 \tLoss: 2.226320\n",
            "\n",
            "Test set: Avg. loss: 2.2377, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4255 \tLoss: 2.226295\n",
            "Train Epoch: 4260 \tLoss: 2.226269\n",
            "Train Epoch: 4265 \tLoss: 2.226244\n",
            "Train Epoch: 4270 \tLoss: 2.226218\n",
            "Train Epoch: 4275 \tLoss: 2.226193\n",
            "\n",
            "Test set: Avg. loss: 2.2376, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4280 \tLoss: 2.226167\n",
            "Train Epoch: 4285 \tLoss: 2.226142\n",
            "Train Epoch: 4290 \tLoss: 2.226116\n",
            "Train Epoch: 4295 \tLoss: 2.226091\n",
            "Train Epoch: 4300 \tLoss: 2.226066\n",
            "\n",
            "Test set: Avg. loss: 2.2375, Accuracy: 118/500 (24%)\n",
            "\n",
            "Train Epoch: 4305 \tLoss: 2.226041\n",
            "Train Epoch: 4310 \tLoss: 2.226016\n",
            "Train Epoch: 4315 \tLoss: 2.225991\n",
            "Train Epoch: 4320 \tLoss: 2.225966\n",
            "Train Epoch: 4325 \tLoss: 2.225941\n",
            "\n",
            "Test set: Avg. loss: 2.2374, Accuracy: 118/500 (24%)\n",
            "\n",
            "Train Epoch: 4330 \tLoss: 2.225916\n",
            "Train Epoch: 4335 \tLoss: 2.225892\n",
            "Train Epoch: 4340 \tLoss: 2.225867\n",
            "Train Epoch: 4345 \tLoss: 2.225842\n",
            "Train Epoch: 4350 \tLoss: 2.225817\n",
            "\n",
            "Test set: Avg. loss: 2.2373, Accuracy: 118/500 (24%)\n",
            "\n",
            "Train Epoch: 4355 \tLoss: 2.225793\n",
            "Train Epoch: 4360 \tLoss: 2.225768\n",
            "Train Epoch: 4365 \tLoss: 2.225744\n",
            "Train Epoch: 4370 \tLoss: 2.225719\n",
            "Train Epoch: 4375 \tLoss: 2.225695\n",
            "\n",
            "Test set: Avg. loss: 2.2372, Accuracy: 118/500 (24%)\n",
            "\n",
            "Train Epoch: 4380 \tLoss: 2.225670\n",
            "Train Epoch: 4385 \tLoss: 2.225646\n",
            "Train Epoch: 4390 \tLoss: 2.225622\n",
            "Train Epoch: 4395 \tLoss: 2.225597\n",
            "Train Epoch: 4400 \tLoss: 2.225573\n",
            "\n",
            "Test set: Avg. loss: 2.2370, Accuracy: 118/500 (24%)\n",
            "\n",
            "Train Epoch: 4405 \tLoss: 2.225549\n",
            "Train Epoch: 4410 \tLoss: 2.225524\n",
            "Train Epoch: 4415 \tLoss: 2.225500\n",
            "Train Epoch: 4420 \tLoss: 2.225476\n",
            "Train Epoch: 4425 \tLoss: 2.225452\n",
            "\n",
            "Test set: Avg. loss: 2.2369, Accuracy: 118/500 (24%)\n",
            "\n",
            "Train Epoch: 4430 \tLoss: 2.225428\n",
            "Train Epoch: 4435 \tLoss: 2.225404\n",
            "Train Epoch: 4440 \tLoss: 2.225380\n",
            "Train Epoch: 4445 \tLoss: 2.225356\n",
            "Train Epoch: 4450 \tLoss: 2.225332\n",
            "\n",
            "Test set: Avg. loss: 2.2368, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4455 \tLoss: 2.225308\n",
            "Train Epoch: 4460 \tLoss: 2.225284\n",
            "Train Epoch: 4465 \tLoss: 2.225260\n",
            "Train Epoch: 4470 \tLoss: 2.225236\n",
            "Train Epoch: 4475 \tLoss: 2.225212\n",
            "\n",
            "Test set: Avg. loss: 2.2367, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4480 \tLoss: 2.225188\n",
            "Train Epoch: 4485 \tLoss: 2.225164\n",
            "Train Epoch: 4490 \tLoss: 2.225140\n",
            "Train Epoch: 4495 \tLoss: 2.225117\n",
            "Train Epoch: 4500 \tLoss: 2.225093\n",
            "\n",
            "Test set: Avg. loss: 2.2366, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4505 \tLoss: 2.225069\n",
            "Train Epoch: 4510 \tLoss: 2.225045\n",
            "Train Epoch: 4515 \tLoss: 2.225022\n",
            "Train Epoch: 4520 \tLoss: 2.224998\n",
            "Train Epoch: 4525 \tLoss: 2.224975\n",
            "\n",
            "Test set: Avg. loss: 2.2365, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4530 \tLoss: 2.224952\n",
            "Train Epoch: 4535 \tLoss: 2.224929\n",
            "Train Epoch: 4540 \tLoss: 2.224906\n",
            "Train Epoch: 4545 \tLoss: 2.224883\n",
            "Train Epoch: 4550 \tLoss: 2.224860\n",
            "\n",
            "Test set: Avg. loss: 2.2364, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4555 \tLoss: 2.224837\n",
            "Train Epoch: 4560 \tLoss: 2.224814\n",
            "Train Epoch: 4565 \tLoss: 2.224791\n",
            "Train Epoch: 4570 \tLoss: 2.224769\n",
            "Train Epoch: 4575 \tLoss: 2.224746\n",
            "\n",
            "Test set: Avg. loss: 2.2363, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4580 \tLoss: 2.224723\n",
            "Train Epoch: 4585 \tLoss: 2.224700\n",
            "Train Epoch: 4590 \tLoss: 2.224677\n",
            "Train Epoch: 4595 \tLoss: 2.224654\n",
            "Train Epoch: 4600 \tLoss: 2.224631\n",
            "\n",
            "Test set: Avg. loss: 2.2362, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4605 \tLoss: 2.224608\n",
            "Train Epoch: 4610 \tLoss: 2.224586\n",
            "Train Epoch: 4615 \tLoss: 2.224563\n",
            "Train Epoch: 4620 \tLoss: 2.224540\n",
            "Train Epoch: 4625 \tLoss: 2.224517\n",
            "\n",
            "Test set: Avg. loss: 2.2361, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4630 \tLoss: 2.224495\n",
            "Train Epoch: 4635 \tLoss: 2.224472\n",
            "Train Epoch: 4640 \tLoss: 2.224449\n",
            "Train Epoch: 4645 \tLoss: 2.224426\n",
            "Train Epoch: 4650 \tLoss: 2.224403\n",
            "\n",
            "Test set: Avg. loss: 2.2360, Accuracy: 118/500 (24%)\n",
            "\n",
            "Train Epoch: 4655 \tLoss: 2.224381\n",
            "Train Epoch: 4660 \tLoss: 2.224358\n",
            "Train Epoch: 4665 \tLoss: 2.224335\n",
            "Train Epoch: 4670 \tLoss: 2.224313\n",
            "Train Epoch: 4675 \tLoss: 2.224290\n",
            "\n",
            "Test set: Avg. loss: 2.2359, Accuracy: 118/500 (24%)\n",
            "\n",
            "Train Epoch: 4680 \tLoss: 2.224268\n",
            "Train Epoch: 4685 \tLoss: 2.224246\n",
            "Train Epoch: 4690 \tLoss: 2.224223\n",
            "Train Epoch: 4695 \tLoss: 2.224201\n",
            "Train Epoch: 4700 \tLoss: 2.224179\n",
            "\n",
            "Test set: Avg. loss: 2.2358, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4705 \tLoss: 2.224156\n",
            "Train Epoch: 4710 \tLoss: 2.224134\n",
            "Train Epoch: 4715 \tLoss: 2.224112\n",
            "Train Epoch: 4720 \tLoss: 2.224090\n",
            "Train Epoch: 4725 \tLoss: 2.224068\n",
            "\n",
            "Test set: Avg. loss: 2.2357, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4730 \tLoss: 2.224046\n",
            "Train Epoch: 4735 \tLoss: 2.224023\n",
            "Train Epoch: 4740 \tLoss: 2.224001\n",
            "Train Epoch: 4745 \tLoss: 2.223979\n",
            "Train Epoch: 4750 \tLoss: 2.223957\n",
            "\n",
            "Test set: Avg. loss: 2.2356, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4755 \tLoss: 2.223934\n",
            "Train Epoch: 4760 \tLoss: 2.223912\n",
            "Train Epoch: 4765 \tLoss: 2.223890\n",
            "Train Epoch: 4770 \tLoss: 2.223869\n",
            "Train Epoch: 4775 \tLoss: 2.223847\n",
            "\n",
            "Test set: Avg. loss: 2.2355, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4780 \tLoss: 2.223825\n",
            "Train Epoch: 4785 \tLoss: 2.223803\n",
            "Train Epoch: 4790 \tLoss: 2.223782\n",
            "Train Epoch: 4795 \tLoss: 2.223760\n",
            "Train Epoch: 4800 \tLoss: 2.223738\n",
            "\n",
            "Test set: Avg. loss: 2.2354, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4805 \tLoss: 2.223716\n",
            "Train Epoch: 4810 \tLoss: 2.223695\n",
            "Train Epoch: 4815 \tLoss: 2.223673\n",
            "Train Epoch: 4820 \tLoss: 2.223651\n",
            "Train Epoch: 4825 \tLoss: 2.223629\n",
            "\n",
            "Test set: Avg. loss: 2.2353, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4830 \tLoss: 2.223608\n",
            "Train Epoch: 4835 \tLoss: 2.223586\n",
            "Train Epoch: 4840 \tLoss: 2.223565\n",
            "Train Epoch: 4845 \tLoss: 2.223543\n",
            "Train Epoch: 4850 \tLoss: 2.223522\n",
            "\n",
            "Test set: Avg. loss: 2.2352, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4855 \tLoss: 2.223500\n",
            "Train Epoch: 4860 \tLoss: 2.223479\n",
            "Train Epoch: 4865 \tLoss: 2.223457\n",
            "Train Epoch: 4870 \tLoss: 2.223435\n",
            "Train Epoch: 4875 \tLoss: 2.223414\n",
            "\n",
            "Test set: Avg. loss: 2.2351, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4880 \tLoss: 2.223392\n",
            "Train Epoch: 4885 \tLoss: 2.223371\n",
            "Train Epoch: 4890 \tLoss: 2.223349\n",
            "Train Epoch: 4895 \tLoss: 2.223328\n",
            "Train Epoch: 4900 \tLoss: 2.223307\n",
            "\n",
            "Test set: Avg. loss: 2.2349, Accuracy: 119/500 (24%)\n",
            "\n",
            "Train Epoch: 4905 \tLoss: 2.223286\n",
            "Train Epoch: 4910 \tLoss: 2.223264\n",
            "Train Epoch: 4915 \tLoss: 2.223243\n",
            "Train Epoch: 4920 \tLoss: 2.223222\n",
            "Train Epoch: 4925 \tLoss: 2.223200\n",
            "\n",
            "Test set: Avg. loss: 2.2348, Accuracy: 119/500 (24%)\n",
            "\n",
            "Train Epoch: 4930 \tLoss: 2.223179\n",
            "Train Epoch: 4935 \tLoss: 2.223158\n",
            "Train Epoch: 4940 \tLoss: 2.223136\n",
            "Train Epoch: 4945 \tLoss: 2.223115\n",
            "Train Epoch: 4950 \tLoss: 2.223094\n",
            "\n",
            "Test set: Avg. loss: 2.2347, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4955 \tLoss: 2.223072\n",
            "Train Epoch: 4960 \tLoss: 2.223051\n",
            "Train Epoch: 4965 \tLoss: 2.223030\n",
            "Train Epoch: 4970 \tLoss: 2.223008\n",
            "Train Epoch: 4975 \tLoss: 2.222987\n",
            "\n",
            "Test set: Avg. loss: 2.2346, Accuracy: 117/500 (23%)\n",
            "\n",
            "Train Epoch: 4980 \tLoss: 2.222966\n",
            "Train Epoch: 4985 \tLoss: 2.222944\n",
            "Train Epoch: 4990 \tLoss: 2.222923\n",
            "Train Epoch: 4995 \tLoss: 2.222902\n",
            "Train Epoch: 5000 \tLoss: 2.222881\n",
            "\n",
            "Test set: Avg. loss: 2.2345, Accuracy: 116/500 (23%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#train only conv1:\n",
        "network = Net()\n",
        "train_losses.clear()\n",
        "test_losses.clear()\n",
        "#count=[]\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
        "\n",
        "#freeze the other layers:\n",
        "network.fc2.weight.requires_grad=False\n",
        "network.fc2.bias.requires_grad=False\n",
        "\n",
        "network.fc1.weight.requires_grad=False\n",
        "network.fc1.bias.requires_grad=False\n",
        "\n",
        "network.conv2.weight.requires_grad=False\n",
        "network.conv2.bias.requires_grad=False\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, network.parameters()), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "\n",
        "# save the initial weights to measure later their contribution:\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()\n",
        "\n",
        "#train\n",
        "test_n = 25\n",
        "test()\n",
        "count = []\n",
        "n_epochs=5000\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  if epoch % test_n == 0:\n",
        "    test()\n",
        "    count.append(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.arange(0,n_epochs)\n",
        "count = np.arange(0,n_epochs+test_n,test_n)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(x, train_losses, color='blue', zorder=1)\n",
        "plt.plot(count, test_losses, color='red', zorder=2)\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.xlabel('number of training examples seen')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.2920, Accuracy: 83/500 (17%)\n",
            "\n",
            "Train Epoch: 5 \tLoss: 2.292623\n",
            "Train Epoch: 10 \tLoss: 2.291928\n",
            "Train Epoch: 15 \tLoss: 2.291235\n",
            "Train Epoch: 20 \tLoss: 2.290544\n",
            "Train Epoch: 25 \tLoss: 2.289854\n",
            "\n",
            "Test set: Avg. loss: 2.2890, Accuracy: 87/500 (17%)\n",
            "\n",
            "Train Epoch: 30 \tLoss: 2.289167\n",
            "Train Epoch: 35 \tLoss: 2.288481\n",
            "Train Epoch: 40 \tLoss: 2.287798\n",
            "Train Epoch: 45 \tLoss: 2.287116\n",
            "Train Epoch: 50 \tLoss: 2.286435\n",
            "\n",
            "Test set: Avg. loss: 2.2860, Accuracy: 89/500 (18%)\n",
            "\n",
            "Train Epoch: 55 \tLoss: 2.285757\n",
            "Train Epoch: 60 \tLoss: 2.285080\n",
            "Train Epoch: 65 \tLoss: 2.284405\n",
            "Train Epoch: 70 \tLoss: 2.283731\n",
            "Train Epoch: 75 \tLoss: 2.283059\n",
            "\n",
            "Test set: Avg. loss: 2.2831, Accuracy: 90/500 (18%)\n",
            "\n",
            "Train Epoch: 80 \tLoss: 2.282389\n",
            "Train Epoch: 85 \tLoss: 2.281720\n",
            "Train Epoch: 90 \tLoss: 2.281053\n",
            "Train Epoch: 95 \tLoss: 2.280387\n",
            "Train Epoch: 100 \tLoss: 2.279722\n",
            "\n",
            "Test set: Avg. loss: 2.2803, Accuracy: 90/500 (18%)\n",
            "\n",
            "Train Epoch: 105 \tLoss: 2.279059\n",
            "Train Epoch: 110 \tLoss: 2.278397\n",
            "Train Epoch: 115 \tLoss: 2.277737\n",
            "Train Epoch: 120 \tLoss: 2.277078\n",
            "Train Epoch: 125 \tLoss: 2.276420\n",
            "\n",
            "Test set: Avg. loss: 2.2774, Accuracy: 92/500 (18%)\n",
            "\n",
            "Train Epoch: 130 \tLoss: 2.275764\n",
            "Train Epoch: 135 \tLoss: 2.275109\n",
            "Train Epoch: 140 \tLoss: 2.274456\n",
            "Train Epoch: 145 \tLoss: 2.273803\n",
            "Train Epoch: 150 \tLoss: 2.273152\n",
            "\n",
            "Test set: Avg. loss: 2.2746, Accuracy: 96/500 (19%)\n",
            "\n",
            "Train Epoch: 155 \tLoss: 2.272502\n",
            "Train Epoch: 160 \tLoss: 2.271853\n",
            "Train Epoch: 165 \tLoss: 2.271205\n",
            "Train Epoch: 170 \tLoss: 2.270558\n",
            "Train Epoch: 175 \tLoss: 2.269912\n",
            "\n",
            "Test set: Avg. loss: 2.2719, Accuracy: 104/500 (21%)\n",
            "\n",
            "Train Epoch: 180 \tLoss: 2.269268\n",
            "Train Epoch: 185 \tLoss: 2.268625\n",
            "Train Epoch: 190 \tLoss: 2.267983\n",
            "Train Epoch: 195 \tLoss: 2.267341\n",
            "Train Epoch: 200 \tLoss: 2.266701\n",
            "\n",
            "Test set: Avg. loss: 2.2691, Accuracy: 102/500 (20%)\n",
            "\n",
            "Train Epoch: 205 \tLoss: 2.266062\n",
            "Train Epoch: 210 \tLoss: 2.265424\n",
            "Train Epoch: 215 \tLoss: 2.264787\n",
            "Train Epoch: 220 \tLoss: 2.264150\n",
            "Train Epoch: 225 \tLoss: 2.263515\n",
            "\n",
            "Test set: Avg. loss: 2.2664, Accuracy: 105/500 (21%)\n",
            "\n",
            "Train Epoch: 230 \tLoss: 2.262881\n",
            "Train Epoch: 235 \tLoss: 2.262247\n",
            "Train Epoch: 240 \tLoss: 2.261615\n",
            "Train Epoch: 245 \tLoss: 2.260983\n",
            "Train Epoch: 250 \tLoss: 2.260353\n",
            "\n",
            "Test set: Avg. loss: 2.2637, Accuracy: 107/500 (21%)\n",
            "\n",
            "Train Epoch: 255 \tLoss: 2.259723\n",
            "Train Epoch: 260 \tLoss: 2.259094\n",
            "Train Epoch: 265 \tLoss: 2.258465\n",
            "Train Epoch: 270 \tLoss: 2.257838\n",
            "Train Epoch: 275 \tLoss: 2.257212\n",
            "\n",
            "Test set: Avg. loss: 2.2610, Accuracy: 113/500 (23%)\n",
            "\n",
            "Train Epoch: 280 \tLoss: 2.256586\n",
            "Train Epoch: 285 \tLoss: 2.255961\n",
            "Train Epoch: 290 \tLoss: 2.255337\n",
            "Train Epoch: 295 \tLoss: 2.254714\n",
            "Train Epoch: 300 \tLoss: 2.254091\n",
            "\n",
            "Test set: Avg. loss: 2.2584, Accuracy: 116/500 (23%)\n",
            "\n",
            "Train Epoch: 305 \tLoss: 2.253469\n",
            "Train Epoch: 310 \tLoss: 2.252848\n",
            "Train Epoch: 315 \tLoss: 2.252228\n",
            "Train Epoch: 320 \tLoss: 2.251608\n",
            "Train Epoch: 325 \tLoss: 2.250989\n",
            "\n",
            "Test set: Avg. loss: 2.2557, Accuracy: 122/500 (24%)\n",
            "\n",
            "Train Epoch: 330 \tLoss: 2.250372\n",
            "Train Epoch: 335 \tLoss: 2.249754\n",
            "Train Epoch: 340 \tLoss: 2.249137\n",
            "Train Epoch: 345 \tLoss: 2.248521\n",
            "Train Epoch: 350 \tLoss: 2.247906\n",
            "\n",
            "Test set: Avg. loss: 2.2531, Accuracy: 127/500 (25%)\n",
            "\n",
            "Train Epoch: 355 \tLoss: 2.247291\n",
            "Train Epoch: 360 \tLoss: 2.246677\n",
            "Train Epoch: 365 \tLoss: 2.246063\n",
            "Train Epoch: 370 \tLoss: 2.245450\n",
            "Train Epoch: 375 \tLoss: 2.244838\n",
            "\n",
            "Test set: Avg. loss: 2.2505, Accuracy: 130/500 (26%)\n",
            "\n",
            "Train Epoch: 380 \tLoss: 2.244226\n",
            "Train Epoch: 385 \tLoss: 2.243616\n",
            "Train Epoch: 390 \tLoss: 2.243005\n",
            "Train Epoch: 395 \tLoss: 2.242396\n",
            "Train Epoch: 400 \tLoss: 2.241787\n",
            "\n",
            "Test set: Avg. loss: 2.2479, Accuracy: 132/500 (26%)\n",
            "\n",
            "Train Epoch: 405 \tLoss: 2.241178\n",
            "Train Epoch: 410 \tLoss: 2.240570\n",
            "Train Epoch: 415 \tLoss: 2.239963\n",
            "Train Epoch: 420 \tLoss: 2.239356\n",
            "Train Epoch: 425 \tLoss: 2.238749\n",
            "\n",
            "Test set: Avg. loss: 2.2453, Accuracy: 140/500 (28%)\n",
            "\n",
            "Train Epoch: 430 \tLoss: 2.238144\n",
            "Train Epoch: 435 \tLoss: 2.237539\n",
            "Train Epoch: 440 \tLoss: 2.236934\n",
            "Train Epoch: 445 \tLoss: 2.236330\n",
            "Train Epoch: 450 \tLoss: 2.235727\n",
            "\n",
            "Test set: Avg. loss: 2.2427, Accuracy: 148/500 (30%)\n",
            "\n",
            "Train Epoch: 455 \tLoss: 2.235124\n",
            "Train Epoch: 460 \tLoss: 2.234521\n",
            "Train Epoch: 465 \tLoss: 2.233919\n",
            "Train Epoch: 470 \tLoss: 2.233317\n",
            "Train Epoch: 475 \tLoss: 2.232716\n",
            "\n",
            "Test set: Avg. loss: 2.2402, Accuracy: 150/500 (30%)\n",
            "\n",
            "Train Epoch: 480 \tLoss: 2.232116\n",
            "Train Epoch: 485 \tLoss: 2.231516\n",
            "Train Epoch: 490 \tLoss: 2.230917\n",
            "Train Epoch: 495 \tLoss: 2.230318\n",
            "Train Epoch: 500 \tLoss: 2.229719\n",
            "\n",
            "Test set: Avg. loss: 2.2376, Accuracy: 156/500 (31%)\n",
            "\n",
            "Train Epoch: 505 \tLoss: 2.229121\n",
            "Train Epoch: 510 \tLoss: 2.228524\n",
            "Train Epoch: 515 \tLoss: 2.227926\n",
            "Train Epoch: 520 \tLoss: 2.227330\n",
            "Train Epoch: 525 \tLoss: 2.226734\n",
            "\n",
            "Test set: Avg. loss: 2.2351, Accuracy: 162/500 (32%)\n",
            "\n",
            "Train Epoch: 530 \tLoss: 2.226138\n",
            "Train Epoch: 535 \tLoss: 2.225543\n",
            "Train Epoch: 540 \tLoss: 2.224948\n",
            "Train Epoch: 545 \tLoss: 2.224354\n",
            "Train Epoch: 550 \tLoss: 2.223760\n",
            "\n",
            "Test set: Avg. loss: 2.2326, Accuracy: 169/500 (34%)\n",
            "\n",
            "Train Epoch: 555 \tLoss: 2.223166\n",
            "Train Epoch: 560 \tLoss: 2.222574\n",
            "Train Epoch: 565 \tLoss: 2.221981\n",
            "Train Epoch: 570 \tLoss: 2.221389\n",
            "Train Epoch: 575 \tLoss: 2.220797\n",
            "\n",
            "Test set: Avg. loss: 2.2301, Accuracy: 176/500 (35%)\n",
            "\n",
            "Train Epoch: 580 \tLoss: 2.220206\n",
            "Train Epoch: 585 \tLoss: 2.219615\n",
            "Train Epoch: 590 \tLoss: 2.219024\n",
            "Train Epoch: 595 \tLoss: 2.218435\n",
            "Train Epoch: 600 \tLoss: 2.217845\n",
            "\n",
            "Test set: Avg. loss: 2.2275, Accuracy: 176/500 (35%)\n",
            "\n",
            "Train Epoch: 605 \tLoss: 2.217256\n",
            "Train Epoch: 610 \tLoss: 2.216667\n",
            "Train Epoch: 615 \tLoss: 2.216079\n",
            "Train Epoch: 620 \tLoss: 2.215491\n",
            "Train Epoch: 625 \tLoss: 2.214903\n",
            "\n",
            "Test set: Avg. loss: 2.2251, Accuracy: 176/500 (35%)\n",
            "\n",
            "Train Epoch: 630 \tLoss: 2.214315\n",
            "Train Epoch: 635 \tLoss: 2.213729\n",
            "Train Epoch: 640 \tLoss: 2.213142\n",
            "Train Epoch: 645 \tLoss: 2.212556\n",
            "Train Epoch: 650 \tLoss: 2.211971\n",
            "\n",
            "Test set: Avg. loss: 2.2226, Accuracy: 178/500 (36%)\n",
            "\n",
            "Train Epoch: 655 \tLoss: 2.211385\n",
            "Train Epoch: 660 \tLoss: 2.210800\n",
            "Train Epoch: 665 \tLoss: 2.210216\n",
            "Train Epoch: 670 \tLoss: 2.209632\n",
            "Train Epoch: 675 \tLoss: 2.209048\n",
            "\n",
            "Test set: Avg. loss: 2.2201, Accuracy: 179/500 (36%)\n",
            "\n",
            "Train Epoch: 680 \tLoss: 2.208464\n",
            "Train Epoch: 685 \tLoss: 2.207881\n",
            "Train Epoch: 690 \tLoss: 2.207299\n",
            "Train Epoch: 695 \tLoss: 2.206716\n",
            "Train Epoch: 700 \tLoss: 2.206134\n",
            "\n",
            "Test set: Avg. loss: 2.2176, Accuracy: 182/500 (36%)\n",
            "\n",
            "Train Epoch: 705 \tLoss: 2.205553\n",
            "Train Epoch: 710 \tLoss: 2.204972\n",
            "Train Epoch: 715 \tLoss: 2.204391\n",
            "Train Epoch: 720 \tLoss: 2.203810\n",
            "Train Epoch: 725 \tLoss: 2.203230\n",
            "\n",
            "Test set: Avg. loss: 2.2152, Accuracy: 183/500 (37%)\n",
            "\n",
            "Train Epoch: 730 \tLoss: 2.202650\n",
            "Train Epoch: 735 \tLoss: 2.202071\n",
            "Train Epoch: 740 \tLoss: 2.201491\n",
            "Train Epoch: 745 \tLoss: 2.200913\n",
            "Train Epoch: 750 \tLoss: 2.200335\n",
            "\n",
            "Test set: Avg. loss: 2.2127, Accuracy: 187/500 (37%)\n",
            "\n",
            "Train Epoch: 755 \tLoss: 2.199756\n",
            "Train Epoch: 760 \tLoss: 2.199178\n",
            "Train Epoch: 765 \tLoss: 2.198601\n",
            "Train Epoch: 770 \tLoss: 2.198024\n",
            "Train Epoch: 775 \tLoss: 2.197447\n",
            "\n",
            "Test set: Avg. loss: 2.2103, Accuracy: 188/500 (38%)\n",
            "\n",
            "Train Epoch: 780 \tLoss: 2.196871\n",
            "Train Epoch: 785 \tLoss: 2.196295\n",
            "Train Epoch: 790 \tLoss: 2.195719\n",
            "Train Epoch: 795 \tLoss: 2.195144\n",
            "Train Epoch: 800 \tLoss: 2.194569\n",
            "\n",
            "Test set: Avg. loss: 2.2078, Accuracy: 190/500 (38%)\n",
            "\n",
            "Train Epoch: 805 \tLoss: 2.193994\n",
            "Train Epoch: 810 \tLoss: 2.193419\n",
            "Train Epoch: 815 \tLoss: 2.192845\n",
            "Train Epoch: 820 \tLoss: 2.192271\n",
            "Train Epoch: 825 \tLoss: 2.191698\n",
            "\n",
            "Test set: Avg. loss: 2.2054, Accuracy: 192/500 (38%)\n",
            "\n",
            "Train Epoch: 830 \tLoss: 2.191125\n",
            "Train Epoch: 835 \tLoss: 2.190552\n",
            "Train Epoch: 840 \tLoss: 2.189980\n",
            "Train Epoch: 845 \tLoss: 2.189408\n",
            "Train Epoch: 850 \tLoss: 2.188835\n",
            "\n",
            "Test set: Avg. loss: 2.2030, Accuracy: 196/500 (39%)\n",
            "\n",
            "Train Epoch: 855 \tLoss: 2.188264\n",
            "Train Epoch: 860 \tLoss: 2.187693\n",
            "Train Epoch: 865 \tLoss: 2.187122\n",
            "Train Epoch: 870 \tLoss: 2.186551\n",
            "Train Epoch: 875 \tLoss: 2.185981\n",
            "\n",
            "Test set: Avg. loss: 2.2006, Accuracy: 196/500 (39%)\n",
            "\n",
            "Train Epoch: 880 \tLoss: 2.185411\n",
            "Train Epoch: 885 \tLoss: 2.184841\n",
            "Train Epoch: 890 \tLoss: 2.184272\n",
            "Train Epoch: 895 \tLoss: 2.183703\n",
            "Train Epoch: 900 \tLoss: 2.183134\n",
            "\n",
            "Test set: Avg. loss: 2.1981, Accuracy: 200/500 (40%)\n",
            "\n",
            "Train Epoch: 905 \tLoss: 2.182566\n",
            "Train Epoch: 910 \tLoss: 2.181998\n",
            "Train Epoch: 915 \tLoss: 2.181430\n",
            "Train Epoch: 920 \tLoss: 2.180862\n",
            "Train Epoch: 925 \tLoss: 2.180295\n",
            "\n",
            "Test set: Avg. loss: 2.1957, Accuracy: 202/500 (40%)\n",
            "\n",
            "Train Epoch: 930 \tLoss: 2.179728\n",
            "Train Epoch: 935 \tLoss: 2.179162\n",
            "Train Epoch: 940 \tLoss: 2.178595\n",
            "Train Epoch: 945 \tLoss: 2.178029\n",
            "Train Epoch: 950 \tLoss: 2.177464\n",
            "\n",
            "Test set: Avg. loss: 2.1934, Accuracy: 204/500 (41%)\n",
            "\n",
            "Train Epoch: 955 \tLoss: 2.176898\n",
            "Train Epoch: 960 \tLoss: 2.176333\n",
            "Train Epoch: 965 \tLoss: 2.175768\n",
            "Train Epoch: 970 \tLoss: 2.175204\n",
            "Train Epoch: 975 \tLoss: 2.174640\n",
            "\n",
            "Test set: Avg. loss: 2.1910, Accuracy: 208/500 (42%)\n",
            "\n",
            "Train Epoch: 980 \tLoss: 2.174076\n",
            "Train Epoch: 985 \tLoss: 2.173512\n",
            "Train Epoch: 990 \tLoss: 2.172949\n",
            "Train Epoch: 995 \tLoss: 2.172386\n",
            "Train Epoch: 1000 \tLoss: 2.171823\n",
            "\n",
            "Test set: Avg. loss: 2.1886, Accuracy: 212/500 (42%)\n",
            "\n",
            "Train Epoch: 1005 \tLoss: 2.171261\n",
            "Train Epoch: 1010 \tLoss: 2.170698\n",
            "Train Epoch: 1015 \tLoss: 2.170136\n",
            "Train Epoch: 1020 \tLoss: 2.169575\n",
            "Train Epoch: 1025 \tLoss: 2.169014\n",
            "\n",
            "Test set: Avg. loss: 2.1862, Accuracy: 214/500 (43%)\n",
            "\n",
            "Train Epoch: 1030 \tLoss: 2.168453\n",
            "Train Epoch: 1035 \tLoss: 2.167892\n",
            "Train Epoch: 1040 \tLoss: 2.167331\n",
            "Train Epoch: 1045 \tLoss: 2.166771\n",
            "Train Epoch: 1050 \tLoss: 2.166211\n",
            "\n",
            "Test set: Avg. loss: 2.1838, Accuracy: 216/500 (43%)\n",
            "\n",
            "Train Epoch: 1055 \tLoss: 2.165652\n",
            "Train Epoch: 1060 \tLoss: 2.165092\n",
            "Train Epoch: 1065 \tLoss: 2.164534\n",
            "Train Epoch: 1070 \tLoss: 2.163975\n",
            "Train Epoch: 1075 \tLoss: 2.163417\n",
            "\n",
            "Test set: Avg. loss: 2.1815, Accuracy: 219/500 (44%)\n",
            "\n",
            "Train Epoch: 1080 \tLoss: 2.162858\n",
            "Train Epoch: 1085 \tLoss: 2.162301\n",
            "Train Epoch: 1090 \tLoss: 2.161743\n",
            "Train Epoch: 1095 \tLoss: 2.161186\n",
            "Train Epoch: 1100 \tLoss: 2.160629\n",
            "\n",
            "Test set: Avg. loss: 2.1791, Accuracy: 219/500 (44%)\n",
            "\n",
            "Train Epoch: 1105 \tLoss: 2.160072\n",
            "Train Epoch: 1110 \tLoss: 2.159515\n",
            "Train Epoch: 1115 \tLoss: 2.158959\n",
            "Train Epoch: 1120 \tLoss: 2.158403\n",
            "Train Epoch: 1125 \tLoss: 2.157848\n",
            "\n",
            "Test set: Avg. loss: 2.1768, Accuracy: 221/500 (44%)\n",
            "\n",
            "Train Epoch: 1130 \tLoss: 2.157292\n",
            "Train Epoch: 1135 \tLoss: 2.156737\n",
            "Train Epoch: 1140 \tLoss: 2.156183\n",
            "Train Epoch: 1145 \tLoss: 2.155628\n",
            "Train Epoch: 1150 \tLoss: 2.155074\n",
            "\n",
            "Test set: Avg. loss: 2.1744, Accuracy: 225/500 (45%)\n",
            "\n",
            "Train Epoch: 1155 \tLoss: 2.154520\n",
            "Train Epoch: 1160 \tLoss: 2.153966\n",
            "Train Epoch: 1165 \tLoss: 2.153413\n",
            "Train Epoch: 1170 \tLoss: 2.152860\n",
            "Train Epoch: 1175 \tLoss: 2.152307\n",
            "\n",
            "Test set: Avg. loss: 2.1721, Accuracy: 227/500 (45%)\n",
            "\n",
            "Train Epoch: 1180 \tLoss: 2.151754\n",
            "Train Epoch: 1185 \tLoss: 2.151202\n",
            "Train Epoch: 1190 \tLoss: 2.150650\n",
            "Train Epoch: 1195 \tLoss: 2.150098\n",
            "Train Epoch: 1200 \tLoss: 2.149547\n",
            "\n",
            "Test set: Avg. loss: 2.1698, Accuracy: 229/500 (46%)\n",
            "\n",
            "Train Epoch: 1205 \tLoss: 2.148996\n",
            "Train Epoch: 1210 \tLoss: 2.148445\n",
            "Train Epoch: 1215 \tLoss: 2.147894\n",
            "Train Epoch: 1220 \tLoss: 2.147344\n",
            "Train Epoch: 1225 \tLoss: 2.146794\n",
            "\n",
            "Test set: Avg. loss: 2.1674, Accuracy: 230/500 (46%)\n",
            "\n",
            "Train Epoch: 1230 \tLoss: 2.146244\n",
            "Train Epoch: 1235 \tLoss: 2.145694\n",
            "Train Epoch: 1240 \tLoss: 2.145145\n",
            "Train Epoch: 1245 \tLoss: 2.144596\n",
            "Train Epoch: 1250 \tLoss: 2.144047\n",
            "\n",
            "Test set: Avg. loss: 2.1651, Accuracy: 234/500 (47%)\n",
            "\n",
            "Train Epoch: 1255 \tLoss: 2.143499\n",
            "Train Epoch: 1260 \tLoss: 2.142951\n",
            "Train Epoch: 1265 \tLoss: 2.142403\n",
            "Train Epoch: 1270 \tLoss: 2.141855\n",
            "Train Epoch: 1275 \tLoss: 2.141308\n",
            "\n",
            "Test set: Avg. loss: 2.1628, Accuracy: 234/500 (47%)\n",
            "\n",
            "Train Epoch: 1280 \tLoss: 2.140760\n",
            "Train Epoch: 1285 \tLoss: 2.140214\n",
            "Train Epoch: 1290 \tLoss: 2.139667\n",
            "Train Epoch: 1295 \tLoss: 2.139121\n",
            "Train Epoch: 1300 \tLoss: 2.138575\n",
            "\n",
            "Test set: Avg. loss: 2.1605, Accuracy: 236/500 (47%)\n",
            "\n",
            "Train Epoch: 1305 \tLoss: 2.138029\n",
            "Train Epoch: 1310 \tLoss: 2.137484\n",
            "Train Epoch: 1315 \tLoss: 2.136939\n",
            "Train Epoch: 1320 \tLoss: 2.136394\n",
            "Train Epoch: 1325 \tLoss: 2.135849\n",
            "\n",
            "Test set: Avg. loss: 2.1582, Accuracy: 238/500 (48%)\n",
            "\n",
            "Train Epoch: 1330 \tLoss: 2.135304\n",
            "Train Epoch: 1335 \tLoss: 2.134760\n",
            "Train Epoch: 1340 \tLoss: 2.134216\n",
            "Train Epoch: 1345 \tLoss: 2.133673\n",
            "Train Epoch: 1350 \tLoss: 2.133129\n",
            "\n",
            "Test set: Avg. loss: 2.1559, Accuracy: 240/500 (48%)\n",
            "\n",
            "Train Epoch: 1355 \tLoss: 2.132586\n",
            "Train Epoch: 1360 \tLoss: 2.132043\n",
            "Train Epoch: 1365 \tLoss: 2.131501\n",
            "Train Epoch: 1370 \tLoss: 2.130959\n",
            "Train Epoch: 1375 \tLoss: 2.130416\n",
            "\n",
            "Test set: Avg. loss: 2.1536, Accuracy: 242/500 (48%)\n",
            "\n",
            "Train Epoch: 1380 \tLoss: 2.129875\n",
            "Train Epoch: 1385 \tLoss: 2.129333\n",
            "Train Epoch: 1390 \tLoss: 2.128792\n",
            "Train Epoch: 1395 \tLoss: 2.128251\n",
            "Train Epoch: 1400 \tLoss: 2.127710\n",
            "\n",
            "Test set: Avg. loss: 2.1514, Accuracy: 242/500 (48%)\n",
            "\n",
            "Train Epoch: 1405 \tLoss: 2.127170\n",
            "Train Epoch: 1410 \tLoss: 2.126629\n",
            "Train Epoch: 1415 \tLoss: 2.126090\n",
            "Train Epoch: 1420 \tLoss: 2.125550\n",
            "Train Epoch: 1425 \tLoss: 2.125010\n",
            "\n",
            "Test set: Avg. loss: 2.1491, Accuracy: 242/500 (48%)\n",
            "\n",
            "Train Epoch: 1430 \tLoss: 2.124471\n",
            "Train Epoch: 1435 \tLoss: 2.123933\n",
            "Train Epoch: 1440 \tLoss: 2.123394\n",
            "Train Epoch: 1445 \tLoss: 2.122856\n",
            "Train Epoch: 1450 \tLoss: 2.122318\n",
            "\n",
            "Test set: Avg. loss: 2.1468, Accuracy: 243/500 (49%)\n",
            "\n",
            "Train Epoch: 1455 \tLoss: 2.121780\n",
            "Train Epoch: 1460 \tLoss: 2.121242\n",
            "Train Epoch: 1465 \tLoss: 2.120705\n",
            "Train Epoch: 1470 \tLoss: 2.120168\n",
            "Train Epoch: 1475 \tLoss: 2.119631\n",
            "\n",
            "Test set: Avg. loss: 2.1445, Accuracy: 243/500 (49%)\n",
            "\n",
            "Train Epoch: 1480 \tLoss: 2.119094\n",
            "Train Epoch: 1485 \tLoss: 2.118558\n",
            "Train Epoch: 1490 \tLoss: 2.118022\n",
            "Train Epoch: 1495 \tLoss: 2.117486\n",
            "Train Epoch: 1500 \tLoss: 2.116951\n",
            "\n",
            "Test set: Avg. loss: 2.1423, Accuracy: 243/500 (49%)\n",
            "\n",
            "Train Epoch: 1505 \tLoss: 2.116416\n",
            "Train Epoch: 1510 \tLoss: 2.115881\n",
            "Train Epoch: 1515 \tLoss: 2.115346\n",
            "Train Epoch: 1520 \tLoss: 2.114812\n",
            "Train Epoch: 1525 \tLoss: 2.114278\n",
            "\n",
            "Test set: Avg. loss: 2.1400, Accuracy: 247/500 (49%)\n",
            "\n",
            "Train Epoch: 1530 \tLoss: 2.113744\n",
            "Train Epoch: 1535 \tLoss: 2.113210\n",
            "Train Epoch: 1540 \tLoss: 2.112677\n",
            "Train Epoch: 1545 \tLoss: 2.112144\n",
            "Train Epoch: 1550 \tLoss: 2.111611\n",
            "\n",
            "Test set: Avg. loss: 2.1378, Accuracy: 247/500 (49%)\n",
            "\n",
            "Train Epoch: 1555 \tLoss: 2.111078\n",
            "Train Epoch: 1560 \tLoss: 2.110546\n",
            "Train Epoch: 1565 \tLoss: 2.110014\n",
            "Train Epoch: 1570 \tLoss: 2.109482\n",
            "Train Epoch: 1575 \tLoss: 2.108950\n",
            "\n",
            "Test set: Avg. loss: 2.1356, Accuracy: 248/500 (50%)\n",
            "\n",
            "Train Epoch: 1580 \tLoss: 2.108419\n",
            "Train Epoch: 1585 \tLoss: 2.107888\n",
            "Train Epoch: 1590 \tLoss: 2.107358\n",
            "Train Epoch: 1595 \tLoss: 2.106827\n",
            "Train Epoch: 1600 \tLoss: 2.106296\n",
            "\n",
            "Test set: Avg. loss: 2.1333, Accuracy: 250/500 (50%)\n",
            "\n",
            "Train Epoch: 1605 \tLoss: 2.105766\n",
            "Train Epoch: 1610 \tLoss: 2.105237\n",
            "Train Epoch: 1615 \tLoss: 2.104707\n",
            "Train Epoch: 1620 \tLoss: 2.104178\n",
            "Train Epoch: 1625 \tLoss: 2.103649\n",
            "\n",
            "Test set: Avg. loss: 2.1311, Accuracy: 250/500 (50%)\n",
            "\n",
            "Train Epoch: 1630 \tLoss: 2.103120\n",
            "Train Epoch: 1635 \tLoss: 2.102592\n",
            "Train Epoch: 1640 \tLoss: 2.102063\n",
            "Train Epoch: 1645 \tLoss: 2.101535\n",
            "Train Epoch: 1650 \tLoss: 2.101008\n",
            "\n",
            "Test set: Avg. loss: 2.1289, Accuracy: 251/500 (50%)\n",
            "\n",
            "Train Epoch: 1655 \tLoss: 2.100480\n",
            "Train Epoch: 1660 \tLoss: 2.099953\n",
            "Train Epoch: 1665 \tLoss: 2.099426\n",
            "Train Epoch: 1670 \tLoss: 2.098899\n",
            "Train Epoch: 1675 \tLoss: 2.098373\n",
            "\n",
            "Test set: Avg. loss: 2.1267, Accuracy: 252/500 (50%)\n",
            "\n",
            "Train Epoch: 1680 \tLoss: 2.097847\n",
            "Train Epoch: 1685 \tLoss: 2.097321\n",
            "Train Epoch: 1690 \tLoss: 2.096795\n",
            "Train Epoch: 1695 \tLoss: 2.096270\n",
            "Train Epoch: 1700 \tLoss: 2.095745\n",
            "\n",
            "Test set: Avg. loss: 2.1244, Accuracy: 252/500 (50%)\n",
            "\n",
            "Train Epoch: 1705 \tLoss: 2.095220\n",
            "Train Epoch: 1710 \tLoss: 2.094695\n",
            "Train Epoch: 1715 \tLoss: 2.094171\n",
            "Train Epoch: 1720 \tLoss: 2.093647\n",
            "Train Epoch: 1725 \tLoss: 2.093123\n",
            "\n",
            "Test set: Avg. loss: 2.1222, Accuracy: 252/500 (50%)\n",
            "\n",
            "Train Epoch: 1730 \tLoss: 2.092599\n",
            "Train Epoch: 1735 \tLoss: 2.092076\n",
            "Train Epoch: 1740 \tLoss: 2.091553\n",
            "Train Epoch: 1745 \tLoss: 2.091030\n",
            "Train Epoch: 1750 \tLoss: 2.090507\n",
            "\n",
            "Test set: Avg. loss: 2.1200, Accuracy: 253/500 (51%)\n",
            "\n",
            "Train Epoch: 1755 \tLoss: 2.089985\n",
            "Train Epoch: 1760 \tLoss: 2.089463\n",
            "Train Epoch: 1765 \tLoss: 2.088941\n",
            "Train Epoch: 1770 \tLoss: 2.088419\n",
            "Train Epoch: 1775 \tLoss: 2.087898\n",
            "\n",
            "Test set: Avg. loss: 2.1178, Accuracy: 252/500 (50%)\n",
            "\n",
            "Train Epoch: 1780 \tLoss: 2.087377\n",
            "Train Epoch: 1785 \tLoss: 2.086856\n",
            "Train Epoch: 1790 \tLoss: 2.086335\n",
            "Train Epoch: 1795 \tLoss: 2.085815\n",
            "Train Epoch: 1800 \tLoss: 2.085295\n",
            "\n",
            "Test set: Avg. loss: 2.1157, Accuracy: 253/500 (51%)\n",
            "\n",
            "Train Epoch: 1805 \tLoss: 2.084775\n",
            "Train Epoch: 1810 \tLoss: 2.084255\n",
            "Train Epoch: 1815 \tLoss: 2.083736\n",
            "Train Epoch: 1820 \tLoss: 2.083217\n",
            "Train Epoch: 1825 \tLoss: 2.082698\n",
            "\n",
            "Test set: Avg. loss: 2.1135, Accuracy: 255/500 (51%)\n",
            "\n",
            "Train Epoch: 1830 \tLoss: 2.082180\n",
            "Train Epoch: 1835 \tLoss: 2.081661\n",
            "Train Epoch: 1840 \tLoss: 2.081143\n",
            "Train Epoch: 1845 \tLoss: 2.080625\n",
            "Train Epoch: 1850 \tLoss: 2.080108\n",
            "\n",
            "Test set: Avg. loss: 2.1113, Accuracy: 257/500 (51%)\n",
            "\n",
            "Train Epoch: 1855 \tLoss: 2.079590\n",
            "Train Epoch: 1860 \tLoss: 2.079073\n",
            "Train Epoch: 1865 \tLoss: 2.078556\n",
            "Train Epoch: 1870 \tLoss: 2.078040\n",
            "Train Epoch: 1875 \tLoss: 2.077523\n",
            "\n",
            "Test set: Avg. loss: 2.1091, Accuracy: 258/500 (52%)\n",
            "\n",
            "Train Epoch: 1880 \tLoss: 2.077007\n",
            "Train Epoch: 1885 \tLoss: 2.076492\n",
            "Train Epoch: 1890 \tLoss: 2.075976\n",
            "Train Epoch: 1895 \tLoss: 2.075461\n",
            "Train Epoch: 1900 \tLoss: 2.074946\n",
            "\n",
            "Test set: Avg. loss: 2.1070, Accuracy: 261/500 (52%)\n",
            "\n",
            "Train Epoch: 1905 \tLoss: 2.074431\n",
            "Train Epoch: 1910 \tLoss: 2.073917\n",
            "Train Epoch: 1915 \tLoss: 2.073402\n",
            "Train Epoch: 1920 \tLoss: 2.072888\n",
            "Train Epoch: 1925 \tLoss: 2.072374\n",
            "\n",
            "Test set: Avg. loss: 2.1048, Accuracy: 262/500 (52%)\n",
            "\n",
            "Train Epoch: 1930 \tLoss: 2.071861\n",
            "Train Epoch: 1935 \tLoss: 2.071348\n",
            "Train Epoch: 1940 \tLoss: 2.070834\n",
            "Train Epoch: 1945 \tLoss: 2.070322\n",
            "Train Epoch: 1950 \tLoss: 2.069809\n",
            "\n",
            "Test set: Avg. loss: 2.1027, Accuracy: 262/500 (52%)\n",
            "\n",
            "Train Epoch: 1955 \tLoss: 2.069297\n",
            "Train Epoch: 1960 \tLoss: 2.068785\n",
            "Train Epoch: 1965 \tLoss: 2.068273\n",
            "Train Epoch: 1970 \tLoss: 2.067761\n",
            "Train Epoch: 1975 \tLoss: 2.067250\n",
            "\n",
            "Test set: Avg. loss: 2.1005, Accuracy: 262/500 (52%)\n",
            "\n",
            "Train Epoch: 1980 \tLoss: 2.066739\n",
            "Train Epoch: 1985 \tLoss: 2.066228\n",
            "Train Epoch: 1990 \tLoss: 2.065717\n",
            "Train Epoch: 1995 \tLoss: 2.065207\n",
            "Train Epoch: 2000 \tLoss: 2.064697\n",
            "\n",
            "Test set: Avg. loss: 2.0984, Accuracy: 262/500 (52%)\n",
            "\n",
            "Train Epoch: 2005 \tLoss: 2.064187\n",
            "Train Epoch: 2010 \tLoss: 2.063678\n",
            "Train Epoch: 2015 \tLoss: 2.063168\n",
            "Train Epoch: 2020 \tLoss: 2.062659\n",
            "Train Epoch: 2025 \tLoss: 2.062150\n",
            "\n",
            "Test set: Avg. loss: 2.0962, Accuracy: 262/500 (52%)\n",
            "\n",
            "Train Epoch: 2030 \tLoss: 2.061642\n",
            "Train Epoch: 2035 \tLoss: 2.061133\n",
            "Train Epoch: 2040 \tLoss: 2.060625\n",
            "Train Epoch: 2045 \tLoss: 2.060117\n",
            "Train Epoch: 2050 \tLoss: 2.059610\n",
            "\n",
            "Test set: Avg. loss: 2.0941, Accuracy: 263/500 (53%)\n",
            "\n",
            "Train Epoch: 2055 \tLoss: 2.059103\n",
            "Train Epoch: 2060 \tLoss: 2.058595\n",
            "Train Epoch: 2065 \tLoss: 2.058088\n",
            "Train Epoch: 2070 \tLoss: 2.057582\n",
            "Train Epoch: 2075 \tLoss: 2.057076\n",
            "\n",
            "Test set: Avg. loss: 2.0920, Accuracy: 265/500 (53%)\n",
            "\n",
            "Train Epoch: 2080 \tLoss: 2.056569\n",
            "Train Epoch: 2085 \tLoss: 2.056063\n",
            "Train Epoch: 2090 \tLoss: 2.055558\n",
            "Train Epoch: 2095 \tLoss: 2.055053\n",
            "Train Epoch: 2100 \tLoss: 2.054547\n",
            "\n",
            "Test set: Avg. loss: 2.0898, Accuracy: 266/500 (53%)\n",
            "\n",
            "Train Epoch: 2105 \tLoss: 2.054043\n",
            "Train Epoch: 2110 \tLoss: 2.053538\n",
            "Train Epoch: 2115 \tLoss: 2.053033\n",
            "Train Epoch: 2120 \tLoss: 2.052529\n",
            "Train Epoch: 2125 \tLoss: 2.052025\n",
            "\n",
            "Test set: Avg. loss: 2.0877, Accuracy: 267/500 (53%)\n",
            "\n",
            "Train Epoch: 2130 \tLoss: 2.051522\n",
            "Train Epoch: 2135 \tLoss: 2.051018\n",
            "Train Epoch: 2140 \tLoss: 2.050515\n",
            "Train Epoch: 2145 \tLoss: 2.050012\n",
            "Train Epoch: 2150 \tLoss: 2.049509\n",
            "\n",
            "Test set: Avg. loss: 2.0856, Accuracy: 267/500 (53%)\n",
            "\n",
            "Train Epoch: 2155 \tLoss: 2.049007\n",
            "Train Epoch: 2160 \tLoss: 2.048505\n",
            "Train Epoch: 2165 \tLoss: 2.048003\n",
            "Train Epoch: 2170 \tLoss: 2.047501\n",
            "Train Epoch: 2175 \tLoss: 2.047000\n",
            "\n",
            "Test set: Avg. loss: 2.0835, Accuracy: 268/500 (54%)\n",
            "\n",
            "Train Epoch: 2180 \tLoss: 2.046498\n",
            "Train Epoch: 2185 \tLoss: 2.045997\n",
            "Train Epoch: 2190 \tLoss: 2.045497\n",
            "Train Epoch: 2195 \tLoss: 2.044996\n",
            "Train Epoch: 2200 \tLoss: 2.044496\n",
            "\n",
            "Test set: Avg. loss: 2.0814, Accuracy: 268/500 (54%)\n",
            "\n",
            "Train Epoch: 2205 \tLoss: 2.043996\n",
            "Train Epoch: 2210 \tLoss: 2.043496\n",
            "Train Epoch: 2215 \tLoss: 2.042997\n",
            "Train Epoch: 2220 \tLoss: 2.042497\n",
            "Train Epoch: 2225 \tLoss: 2.041998\n",
            "\n",
            "Test set: Avg. loss: 2.0793, Accuracy: 269/500 (54%)\n",
            "\n",
            "Train Epoch: 2230 \tLoss: 2.041500\n",
            "Train Epoch: 2235 \tLoss: 2.041001\n",
            "Train Epoch: 2240 \tLoss: 2.040503\n",
            "Train Epoch: 2245 \tLoss: 2.040005\n",
            "Train Epoch: 2250 \tLoss: 2.039507\n",
            "\n",
            "Test set: Avg. loss: 2.0772, Accuracy: 269/500 (54%)\n",
            "\n",
            "Train Epoch: 2255 \tLoss: 2.039009\n",
            "Train Epoch: 2260 \tLoss: 2.038512\n",
            "Train Epoch: 2265 \tLoss: 2.038015\n",
            "Train Epoch: 2270 \tLoss: 2.037518\n",
            "Train Epoch: 2275 \tLoss: 2.037021\n",
            "\n",
            "Test set: Avg. loss: 2.0752, Accuracy: 270/500 (54%)\n",
            "\n",
            "Train Epoch: 2280 \tLoss: 2.036525\n",
            "Train Epoch: 2285 \tLoss: 2.036029\n",
            "Train Epoch: 2290 \tLoss: 2.035533\n",
            "Train Epoch: 2295 \tLoss: 2.035037\n",
            "Train Epoch: 2300 \tLoss: 2.034542\n",
            "\n",
            "Test set: Avg. loss: 2.0731, Accuracy: 269/500 (54%)\n",
            "\n",
            "Train Epoch: 2305 \tLoss: 2.034047\n",
            "Train Epoch: 2310 \tLoss: 2.033552\n",
            "Train Epoch: 2315 \tLoss: 2.033057\n",
            "Train Epoch: 2320 \tLoss: 2.032563\n",
            "Train Epoch: 2325 \tLoss: 2.032068\n",
            "\n",
            "Test set: Avg. loss: 2.0710, Accuracy: 270/500 (54%)\n",
            "\n",
            "Train Epoch: 2330 \tLoss: 2.031575\n",
            "Train Epoch: 2335 \tLoss: 2.031081\n",
            "Train Epoch: 2340 \tLoss: 2.030587\n",
            "Train Epoch: 2345 \tLoss: 2.030094\n",
            "Train Epoch: 2350 \tLoss: 2.029601\n",
            "\n",
            "Test set: Avg. loss: 2.0689, Accuracy: 270/500 (54%)\n",
            "\n",
            "Train Epoch: 2355 \tLoss: 2.029109\n",
            "Train Epoch: 2360 \tLoss: 2.028616\n",
            "Train Epoch: 2365 \tLoss: 2.028124\n",
            "Train Epoch: 2370 \tLoss: 2.027632\n",
            "Train Epoch: 2375 \tLoss: 2.027140\n",
            "\n",
            "Test set: Avg. loss: 2.0669, Accuracy: 271/500 (54%)\n",
            "\n",
            "Train Epoch: 2380 \tLoss: 2.026649\n",
            "Train Epoch: 2385 \tLoss: 2.026157\n",
            "Train Epoch: 2390 \tLoss: 2.025666\n",
            "Train Epoch: 2395 \tLoss: 2.025175\n",
            "Train Epoch: 2400 \tLoss: 2.024685\n",
            "\n",
            "Test set: Avg. loss: 2.0648, Accuracy: 271/500 (54%)\n",
            "\n",
            "Train Epoch: 2405 \tLoss: 2.024194\n",
            "Train Epoch: 2410 \tLoss: 2.023704\n",
            "Train Epoch: 2415 \tLoss: 2.023214\n",
            "Train Epoch: 2420 \tLoss: 2.022725\n",
            "Train Epoch: 2425 \tLoss: 2.022235\n",
            "\n",
            "Test set: Avg. loss: 2.0628, Accuracy: 271/500 (54%)\n",
            "\n",
            "Train Epoch: 2430 \tLoss: 2.021746\n",
            "Train Epoch: 2435 \tLoss: 2.021257\n",
            "Train Epoch: 2440 \tLoss: 2.020769\n",
            "Train Epoch: 2445 \tLoss: 2.020280\n",
            "Train Epoch: 2450 \tLoss: 2.019792\n",
            "\n",
            "Test set: Avg. loss: 2.0607, Accuracy: 271/500 (54%)\n",
            "\n",
            "Train Epoch: 2455 \tLoss: 2.019304\n",
            "Train Epoch: 2460 \tLoss: 2.018816\n",
            "Train Epoch: 2465 \tLoss: 2.018329\n",
            "Train Epoch: 2470 \tLoss: 2.017841\n",
            "Train Epoch: 2475 \tLoss: 2.017355\n",
            "\n",
            "Test set: Avg. loss: 2.0587, Accuracy: 273/500 (55%)\n",
            "\n",
            "Train Epoch: 2480 \tLoss: 2.016868\n",
            "Train Epoch: 2485 \tLoss: 2.016381\n",
            "Train Epoch: 2490 \tLoss: 2.015895\n",
            "Train Epoch: 2495 \tLoss: 2.015409\n",
            "Train Epoch: 2500 \tLoss: 2.014923\n",
            "\n",
            "Test set: Avg. loss: 2.0567, Accuracy: 273/500 (55%)\n",
            "\n",
            "Train Epoch: 2505 \tLoss: 2.014438\n",
            "Train Epoch: 2510 \tLoss: 2.013952\n",
            "Train Epoch: 2515 \tLoss: 2.013467\n",
            "Train Epoch: 2520 \tLoss: 2.012982\n",
            "Train Epoch: 2525 \tLoss: 2.012498\n",
            "\n",
            "Test set: Avg. loss: 2.0546, Accuracy: 274/500 (55%)\n",
            "\n",
            "Train Epoch: 2530 \tLoss: 2.012013\n",
            "Train Epoch: 2535 \tLoss: 2.011529\n",
            "Train Epoch: 2540 \tLoss: 2.011045\n",
            "Train Epoch: 2545 \tLoss: 2.010561\n",
            "Train Epoch: 2550 \tLoss: 2.010078\n",
            "\n",
            "Test set: Avg. loss: 2.0526, Accuracy: 274/500 (55%)\n",
            "\n",
            "Train Epoch: 2555 \tLoss: 2.009595\n",
            "Train Epoch: 2560 \tLoss: 2.009112\n",
            "Train Epoch: 2565 \tLoss: 2.008629\n",
            "Train Epoch: 2570 \tLoss: 2.008147\n",
            "Train Epoch: 2575 \tLoss: 2.007664\n",
            "\n",
            "Test set: Avg. loss: 2.0506, Accuracy: 274/500 (55%)\n",
            "\n",
            "Train Epoch: 2580 \tLoss: 2.007182\n",
            "Train Epoch: 2585 \tLoss: 2.006701\n",
            "Train Epoch: 2590 \tLoss: 2.006219\n",
            "Train Epoch: 2595 \tLoss: 2.005738\n",
            "Train Epoch: 2600 \tLoss: 2.005256\n",
            "\n",
            "Test set: Avg. loss: 2.0486, Accuracy: 275/500 (55%)\n",
            "\n",
            "Train Epoch: 2605 \tLoss: 2.004776\n",
            "Train Epoch: 2610 \tLoss: 2.004295\n",
            "Train Epoch: 2615 \tLoss: 2.003815\n",
            "Train Epoch: 2620 \tLoss: 2.003335\n",
            "Train Epoch: 2625 \tLoss: 2.002855\n",
            "\n",
            "Test set: Avg. loss: 2.0466, Accuracy: 275/500 (55%)\n",
            "\n",
            "Train Epoch: 2630 \tLoss: 2.002375\n",
            "Train Epoch: 2635 \tLoss: 2.001895\n",
            "Train Epoch: 2640 \tLoss: 2.001416\n",
            "Train Epoch: 2645 \tLoss: 2.000937\n",
            "Train Epoch: 2650 \tLoss: 2.000458\n",
            "\n",
            "Test set: Avg. loss: 2.0446, Accuracy: 277/500 (55%)\n",
            "\n",
            "Train Epoch: 2655 \tLoss: 1.999980\n",
            "Train Epoch: 2660 \tLoss: 1.999502\n",
            "Train Epoch: 2665 \tLoss: 1.999024\n",
            "Train Epoch: 2670 \tLoss: 1.998546\n",
            "Train Epoch: 2675 \tLoss: 1.998068\n",
            "\n",
            "Test set: Avg. loss: 2.0426, Accuracy: 275/500 (55%)\n",
            "\n",
            "Train Epoch: 2680 \tLoss: 1.997591\n",
            "Train Epoch: 2685 \tLoss: 1.997114\n",
            "Train Epoch: 2690 \tLoss: 1.996637\n",
            "Train Epoch: 2695 \tLoss: 1.996160\n",
            "Train Epoch: 2700 \tLoss: 1.995684\n",
            "\n",
            "Test set: Avg. loss: 2.0406, Accuracy: 275/500 (55%)\n",
            "\n",
            "Train Epoch: 2705 \tLoss: 1.995208\n",
            "Train Epoch: 2710 \tLoss: 1.994732\n",
            "Train Epoch: 2715 \tLoss: 1.994256\n",
            "Train Epoch: 2720 \tLoss: 1.993781\n",
            "Train Epoch: 2725 \tLoss: 1.993305\n",
            "\n",
            "Test set: Avg. loss: 2.0386, Accuracy: 277/500 (55%)\n",
            "\n",
            "Train Epoch: 2730 \tLoss: 1.992830\n",
            "Train Epoch: 2735 \tLoss: 1.992356\n",
            "Train Epoch: 2740 \tLoss: 1.991881\n",
            "Train Epoch: 2745 \tLoss: 1.991407\n",
            "Train Epoch: 2750 \tLoss: 1.990932\n",
            "\n",
            "Test set: Avg. loss: 2.0366, Accuracy: 278/500 (56%)\n",
            "\n",
            "Train Epoch: 2755 \tLoss: 1.990459\n",
            "Train Epoch: 2760 \tLoss: 1.989985\n",
            "Train Epoch: 2765 \tLoss: 1.989512\n",
            "Train Epoch: 2770 \tLoss: 1.989039\n",
            "Train Epoch: 2775 \tLoss: 1.988566\n",
            "\n",
            "Test set: Avg. loss: 2.0346, Accuracy: 279/500 (56%)\n",
            "\n",
            "Train Epoch: 2780 \tLoss: 1.988093\n",
            "Train Epoch: 2785 \tLoss: 1.987621\n",
            "Train Epoch: 2790 \tLoss: 1.987148\n",
            "Train Epoch: 2795 \tLoss: 1.986676\n",
            "Train Epoch: 2800 \tLoss: 1.986205\n",
            "\n",
            "Test set: Avg. loss: 2.0327, Accuracy: 279/500 (56%)\n",
            "\n",
            "Train Epoch: 2805 \tLoss: 1.985733\n",
            "Train Epoch: 2810 \tLoss: 1.985262\n",
            "Train Epoch: 2815 \tLoss: 1.984791\n",
            "Train Epoch: 2820 \tLoss: 1.984320\n",
            "Train Epoch: 2825 \tLoss: 1.983849\n",
            "\n",
            "Test set: Avg. loss: 2.0307, Accuracy: 279/500 (56%)\n",
            "\n",
            "Train Epoch: 2830 \tLoss: 1.983379\n",
            "Train Epoch: 2835 \tLoss: 1.982909\n",
            "Train Epoch: 2840 \tLoss: 1.982439\n",
            "Train Epoch: 2845 \tLoss: 1.981969\n",
            "Train Epoch: 2850 \tLoss: 1.981500\n",
            "\n",
            "Test set: Avg. loss: 2.0287, Accuracy: 280/500 (56%)\n",
            "\n",
            "Train Epoch: 2855 \tLoss: 1.981031\n",
            "Train Epoch: 2860 \tLoss: 1.980562\n",
            "Train Epoch: 2865 \tLoss: 1.980093\n",
            "Train Epoch: 2870 \tLoss: 1.979624\n",
            "Train Epoch: 2875 \tLoss: 1.979156\n",
            "\n",
            "Test set: Avg. loss: 2.0268, Accuracy: 280/500 (56%)\n",
            "\n",
            "Train Epoch: 2880 \tLoss: 1.978688\n",
            "Train Epoch: 2885 \tLoss: 1.978220\n",
            "Train Epoch: 2890 \tLoss: 1.977752\n",
            "Train Epoch: 2895 \tLoss: 1.977285\n",
            "Train Epoch: 2900 \tLoss: 1.976818\n",
            "\n",
            "Test set: Avg. loss: 2.0248, Accuracy: 280/500 (56%)\n",
            "\n",
            "Train Epoch: 2905 \tLoss: 1.976351\n",
            "Train Epoch: 2910 \tLoss: 1.975884\n",
            "Train Epoch: 2915 \tLoss: 1.975418\n",
            "Train Epoch: 2920 \tLoss: 1.974951\n",
            "Train Epoch: 2925 \tLoss: 1.974486\n",
            "\n",
            "Test set: Avg. loss: 2.0229, Accuracy: 280/500 (56%)\n",
            "\n",
            "Train Epoch: 2930 \tLoss: 1.974019\n",
            "Train Epoch: 2935 \tLoss: 1.973554\n",
            "Train Epoch: 2940 \tLoss: 1.973089\n",
            "Train Epoch: 2945 \tLoss: 1.972624\n",
            "Train Epoch: 2950 \tLoss: 1.972159\n",
            "\n",
            "Test set: Avg. loss: 2.0209, Accuracy: 280/500 (56%)\n",
            "\n",
            "Train Epoch: 2955 \tLoss: 1.971694\n",
            "Train Epoch: 2960 \tLoss: 1.971230\n",
            "Train Epoch: 2965 \tLoss: 1.970765\n",
            "Train Epoch: 2970 \tLoss: 1.970302\n",
            "Train Epoch: 2975 \tLoss: 1.969838\n",
            "\n",
            "Test set: Avg. loss: 2.0190, Accuracy: 281/500 (56%)\n",
            "\n",
            "Train Epoch: 2980 \tLoss: 1.969374\n",
            "Train Epoch: 2985 \tLoss: 1.968911\n",
            "Train Epoch: 2990 \tLoss: 1.968448\n",
            "Train Epoch: 2995 \tLoss: 1.967985\n",
            "Train Epoch: 3000 \tLoss: 1.967523\n",
            "\n",
            "Test set: Avg. loss: 2.0171, Accuracy: 281/500 (56%)\n",
            "\n",
            "Train Epoch: 3005 \tLoss: 1.967060\n",
            "Train Epoch: 3010 \tLoss: 1.966598\n",
            "Train Epoch: 3015 \tLoss: 1.966136\n",
            "Train Epoch: 3020 \tLoss: 1.965674\n",
            "Train Epoch: 3025 \tLoss: 1.965213\n",
            "\n",
            "Test set: Avg. loss: 2.0151, Accuracy: 281/500 (56%)\n",
            "\n",
            "Train Epoch: 3030 \tLoss: 1.964752\n",
            "Train Epoch: 3035 \tLoss: 1.964290\n",
            "Train Epoch: 3040 \tLoss: 1.963830\n",
            "Train Epoch: 3045 \tLoss: 1.963369\n",
            "Train Epoch: 3050 \tLoss: 1.962909\n",
            "\n",
            "Test set: Avg. loss: 2.0132, Accuracy: 281/500 (56%)\n",
            "\n",
            "Train Epoch: 3055 \tLoss: 1.962449\n",
            "Train Epoch: 3060 \tLoss: 1.961989\n",
            "Train Epoch: 3065 \tLoss: 1.961529\n",
            "Train Epoch: 3070 \tLoss: 1.961070\n",
            "Train Epoch: 3075 \tLoss: 1.960611\n",
            "\n",
            "Test set: Avg. loss: 2.0113, Accuracy: 282/500 (56%)\n",
            "\n",
            "Train Epoch: 3080 \tLoss: 1.960151\n",
            "Train Epoch: 3085 \tLoss: 1.959693\n",
            "Train Epoch: 3090 \tLoss: 1.959234\n",
            "Train Epoch: 3095 \tLoss: 1.958776\n",
            "Train Epoch: 3100 \tLoss: 1.958318\n",
            "\n",
            "Test set: Avg. loss: 2.0094, Accuracy: 282/500 (56%)\n",
            "\n",
            "Train Epoch: 3105 \tLoss: 1.957860\n",
            "Train Epoch: 3110 \tLoss: 1.957402\n",
            "Train Epoch: 3115 \tLoss: 1.956945\n",
            "Train Epoch: 3120 \tLoss: 1.956488\n",
            "Train Epoch: 3125 \tLoss: 1.956030\n",
            "\n",
            "Test set: Avg. loss: 2.0075, Accuracy: 282/500 (56%)\n",
            "\n",
            "Train Epoch: 3130 \tLoss: 1.955574\n",
            "Train Epoch: 3135 \tLoss: 1.955117\n",
            "Train Epoch: 3140 \tLoss: 1.954661\n",
            "Train Epoch: 3145 \tLoss: 1.954205\n",
            "Train Epoch: 3150 \tLoss: 1.953749\n",
            "\n",
            "Test set: Avg. loss: 2.0056, Accuracy: 282/500 (56%)\n",
            "\n",
            "Train Epoch: 3155 \tLoss: 1.953293\n",
            "Train Epoch: 3160 \tLoss: 1.952838\n",
            "Train Epoch: 3165 \tLoss: 1.952383\n",
            "Train Epoch: 3170 \tLoss: 1.951928\n",
            "Train Epoch: 3175 \tLoss: 1.951473\n",
            "\n",
            "Test set: Avg. loss: 2.0037, Accuracy: 283/500 (57%)\n",
            "\n",
            "Train Epoch: 3180 \tLoss: 1.951018\n",
            "Train Epoch: 3185 \tLoss: 1.950565\n",
            "Train Epoch: 3190 \tLoss: 1.950110\n",
            "Train Epoch: 3195 \tLoss: 1.949656\n",
            "Train Epoch: 3200 \tLoss: 1.949203\n",
            "\n",
            "Test set: Avg. loss: 2.0018, Accuracy: 283/500 (57%)\n",
            "\n",
            "Train Epoch: 3205 \tLoss: 1.948749\n",
            "Train Epoch: 3210 \tLoss: 1.948296\n",
            "Train Epoch: 3215 \tLoss: 1.947843\n",
            "Train Epoch: 3220 \tLoss: 1.947391\n",
            "Train Epoch: 3225 \tLoss: 1.946938\n",
            "\n",
            "Test set: Avg. loss: 1.9999, Accuracy: 283/500 (57%)\n",
            "\n",
            "Train Epoch: 3230 \tLoss: 1.946486\n",
            "Train Epoch: 3235 \tLoss: 1.946034\n",
            "Train Epoch: 3240 \tLoss: 1.945582\n",
            "Train Epoch: 3245 \tLoss: 1.945130\n",
            "Train Epoch: 3250 \tLoss: 1.944679\n",
            "\n",
            "Test set: Avg. loss: 1.9980, Accuracy: 283/500 (57%)\n",
            "\n",
            "Train Epoch: 3255 \tLoss: 1.944228\n",
            "Train Epoch: 3260 \tLoss: 1.943777\n",
            "Train Epoch: 3265 \tLoss: 1.943326\n",
            "Train Epoch: 3270 \tLoss: 1.942875\n",
            "Train Epoch: 3275 \tLoss: 1.942425\n",
            "\n",
            "Test set: Avg. loss: 1.9962, Accuracy: 284/500 (57%)\n",
            "\n",
            "Train Epoch: 3280 \tLoss: 1.941975\n",
            "Train Epoch: 3285 \tLoss: 1.941525\n",
            "Train Epoch: 3290 \tLoss: 1.941075\n",
            "Train Epoch: 3295 \tLoss: 1.940626\n",
            "Train Epoch: 3300 \tLoss: 1.940177\n",
            "\n",
            "Test set: Avg. loss: 1.9943, Accuracy: 284/500 (57%)\n",
            "\n",
            "Train Epoch: 3305 \tLoss: 1.939728\n",
            "Train Epoch: 3310 \tLoss: 1.939279\n",
            "Train Epoch: 3315 \tLoss: 1.938830\n",
            "Train Epoch: 3320 \tLoss: 1.938382\n",
            "Train Epoch: 3325 \tLoss: 1.937934\n",
            "\n",
            "Test set: Avg. loss: 1.9924, Accuracy: 284/500 (57%)\n",
            "\n",
            "Train Epoch: 3330 \tLoss: 1.937486\n",
            "Train Epoch: 3335 \tLoss: 1.937039\n",
            "Train Epoch: 3340 \tLoss: 1.936591\n",
            "Train Epoch: 3345 \tLoss: 1.936144\n",
            "Train Epoch: 3350 \tLoss: 1.935697\n",
            "\n",
            "Test set: Avg. loss: 1.9906, Accuracy: 284/500 (57%)\n",
            "\n",
            "Train Epoch: 3355 \tLoss: 1.935250\n",
            "Train Epoch: 3360 \tLoss: 1.934804\n",
            "Train Epoch: 3365 \tLoss: 1.934357\n",
            "Train Epoch: 3370 \tLoss: 1.933911\n",
            "Train Epoch: 3375 \tLoss: 1.933465\n",
            "\n",
            "Test set: Avg. loss: 1.9887, Accuracy: 284/500 (57%)\n",
            "\n",
            "Train Epoch: 3380 \tLoss: 1.933019\n",
            "Train Epoch: 3385 \tLoss: 1.932574\n",
            "Train Epoch: 3390 \tLoss: 1.932129\n",
            "Train Epoch: 3395 \tLoss: 1.931684\n",
            "Train Epoch: 3400 \tLoss: 1.931239\n",
            "\n",
            "Test set: Avg. loss: 1.9868, Accuracy: 285/500 (57%)\n",
            "\n",
            "Train Epoch: 3405 \tLoss: 1.930794\n",
            "Train Epoch: 3410 \tLoss: 1.930350\n",
            "Train Epoch: 3415 \tLoss: 1.929906\n",
            "Train Epoch: 3420 \tLoss: 1.929462\n",
            "Train Epoch: 3425 \tLoss: 1.929018\n",
            "\n",
            "Test set: Avg. loss: 1.9850, Accuracy: 285/500 (57%)\n",
            "\n",
            "Train Epoch: 3430 \tLoss: 1.928575\n",
            "Train Epoch: 3435 \tLoss: 1.928131\n",
            "Train Epoch: 3440 \tLoss: 1.927688\n",
            "Train Epoch: 3445 \tLoss: 1.927245\n",
            "Train Epoch: 3450 \tLoss: 1.926803\n",
            "\n",
            "Test set: Avg. loss: 1.9832, Accuracy: 286/500 (57%)\n",
            "\n",
            "Train Epoch: 3455 \tLoss: 1.926360\n",
            "Train Epoch: 3460 \tLoss: 1.925918\n",
            "Train Epoch: 3465 \tLoss: 1.925476\n",
            "Train Epoch: 3470 \tLoss: 1.925034\n",
            "Train Epoch: 3475 \tLoss: 1.924593\n",
            "\n",
            "Test set: Avg. loss: 1.9813, Accuracy: 287/500 (57%)\n",
            "\n",
            "Train Epoch: 3480 \tLoss: 1.924151\n",
            "Train Epoch: 3485 \tLoss: 1.923710\n",
            "Train Epoch: 3490 \tLoss: 1.923269\n",
            "Train Epoch: 3495 \tLoss: 1.922829\n",
            "Train Epoch: 3500 \tLoss: 1.922388\n",
            "\n",
            "Test set: Avg. loss: 1.9795, Accuracy: 287/500 (57%)\n",
            "\n",
            "Train Epoch: 3505 \tLoss: 1.921948\n",
            "Train Epoch: 3510 \tLoss: 1.921508\n",
            "Train Epoch: 3515 \tLoss: 1.921068\n",
            "Train Epoch: 3520 \tLoss: 1.920629\n",
            "Train Epoch: 3525 \tLoss: 1.920189\n",
            "\n",
            "Test set: Avg. loss: 1.9777, Accuracy: 289/500 (58%)\n",
            "\n",
            "Train Epoch: 3530 \tLoss: 1.919750\n",
            "Train Epoch: 3535 \tLoss: 1.919311\n",
            "Train Epoch: 3540 \tLoss: 1.918872\n",
            "Train Epoch: 3545 \tLoss: 1.918434\n",
            "Train Epoch: 3550 \tLoss: 1.917995\n",
            "\n",
            "Test set: Avg. loss: 1.9758, Accuracy: 289/500 (58%)\n",
            "\n",
            "Train Epoch: 3555 \tLoss: 1.917557\n",
            "Train Epoch: 3560 \tLoss: 1.917119\n",
            "Train Epoch: 3565 \tLoss: 1.916682\n",
            "Train Epoch: 3570 \tLoss: 1.916244\n",
            "Train Epoch: 3575 \tLoss: 1.915807\n",
            "\n",
            "Test set: Avg. loss: 1.9740, Accuracy: 289/500 (58%)\n",
            "\n",
            "Train Epoch: 3580 \tLoss: 1.915370\n",
            "Train Epoch: 3585 \tLoss: 1.914933\n",
            "Train Epoch: 3590 \tLoss: 1.914496\n",
            "Train Epoch: 3595 \tLoss: 1.914060\n",
            "Train Epoch: 3600 \tLoss: 1.913624\n",
            "\n",
            "Test set: Avg. loss: 1.9722, Accuracy: 289/500 (58%)\n",
            "\n",
            "Train Epoch: 3605 \tLoss: 1.913188\n",
            "Train Epoch: 3610 \tLoss: 1.912752\n",
            "Train Epoch: 3615 \tLoss: 1.912317\n",
            "Train Epoch: 3620 \tLoss: 1.911881\n",
            "Train Epoch: 3625 \tLoss: 1.911446\n",
            "\n",
            "Test set: Avg. loss: 1.9704, Accuracy: 289/500 (58%)\n",
            "\n",
            "Train Epoch: 3630 \tLoss: 1.911011\n",
            "Train Epoch: 3635 \tLoss: 1.910577\n",
            "Train Epoch: 3640 \tLoss: 1.910142\n",
            "Train Epoch: 3645 \tLoss: 1.909708\n",
            "Train Epoch: 3650 \tLoss: 1.909274\n",
            "\n",
            "Test set: Avg. loss: 1.9686, Accuracy: 289/500 (58%)\n",
            "\n",
            "Train Epoch: 3655 \tLoss: 1.908840\n",
            "Train Epoch: 3660 \tLoss: 1.908406\n",
            "Train Epoch: 3665 \tLoss: 1.907973\n",
            "Train Epoch: 3670 \tLoss: 1.907540\n",
            "Train Epoch: 3675 \tLoss: 1.907107\n",
            "\n",
            "Test set: Avg. loss: 1.9668, Accuracy: 289/500 (58%)\n",
            "\n",
            "Train Epoch: 3680 \tLoss: 1.906674\n",
            "Train Epoch: 3685 \tLoss: 1.906242\n",
            "Train Epoch: 3690 \tLoss: 1.905809\n",
            "Train Epoch: 3695 \tLoss: 1.905377\n",
            "Train Epoch: 3700 \tLoss: 1.904945\n",
            "\n",
            "Test set: Avg. loss: 1.9650, Accuracy: 289/500 (58%)\n",
            "\n",
            "Train Epoch: 3705 \tLoss: 1.904513\n",
            "Train Epoch: 3710 \tLoss: 1.904082\n",
            "Train Epoch: 3715 \tLoss: 1.903651\n",
            "Train Epoch: 3720 \tLoss: 1.903220\n",
            "Train Epoch: 3725 \tLoss: 1.902788\n",
            "\n",
            "Test set: Avg. loss: 1.9632, Accuracy: 289/500 (58%)\n",
            "\n",
            "Train Epoch: 3730 \tLoss: 1.902358\n",
            "Train Epoch: 3735 \tLoss: 1.901928\n",
            "Train Epoch: 3740 \tLoss: 1.901497\n",
            "Train Epoch: 3745 \tLoss: 1.901067\n",
            "Train Epoch: 3750 \tLoss: 1.900637\n",
            "\n",
            "Test set: Avg. loss: 1.9614, Accuracy: 289/500 (58%)\n",
            "\n",
            "Train Epoch: 3755 \tLoss: 1.900208\n",
            "Train Epoch: 3760 \tLoss: 1.899778\n",
            "Train Epoch: 3765 \tLoss: 1.899349\n",
            "Train Epoch: 3770 \tLoss: 1.898920\n",
            "Train Epoch: 3775 \tLoss: 1.898492\n",
            "\n",
            "Test set: Avg. loss: 1.9596, Accuracy: 290/500 (58%)\n",
            "\n",
            "Train Epoch: 3780 \tLoss: 1.898063\n",
            "Train Epoch: 3785 \tLoss: 1.897635\n",
            "Train Epoch: 3790 \tLoss: 1.897206\n",
            "Train Epoch: 3795 \tLoss: 1.896778\n",
            "Train Epoch: 3800 \tLoss: 1.896351\n",
            "\n",
            "Test set: Avg. loss: 1.9579, Accuracy: 290/500 (58%)\n",
            "\n",
            "Train Epoch: 3805 \tLoss: 1.895923\n",
            "Train Epoch: 3810 \tLoss: 1.895496\n",
            "Train Epoch: 3815 \tLoss: 1.895069\n",
            "Train Epoch: 3820 \tLoss: 1.894642\n",
            "Train Epoch: 3825 \tLoss: 1.894215\n",
            "\n",
            "Test set: Avg. loss: 1.9561, Accuracy: 290/500 (58%)\n",
            "\n",
            "Train Epoch: 3830 \tLoss: 1.893789\n",
            "Train Epoch: 3835 \tLoss: 1.893363\n",
            "Train Epoch: 3840 \tLoss: 1.892937\n",
            "Train Epoch: 3845 \tLoss: 1.892511\n",
            "Train Epoch: 3850 \tLoss: 1.892085\n",
            "\n",
            "Test set: Avg. loss: 1.9543, Accuracy: 290/500 (58%)\n",
            "\n",
            "Train Epoch: 3855 \tLoss: 1.891660\n",
            "Train Epoch: 3860 \tLoss: 1.891235\n",
            "Train Epoch: 3865 \tLoss: 1.890810\n",
            "Train Epoch: 3870 \tLoss: 1.890385\n",
            "Train Epoch: 3875 \tLoss: 1.889960\n",
            "\n",
            "Test set: Avg. loss: 1.9526, Accuracy: 290/500 (58%)\n",
            "\n",
            "Train Epoch: 3880 \tLoss: 1.889536\n",
            "Train Epoch: 3885 \tLoss: 1.889112\n",
            "Train Epoch: 3890 \tLoss: 1.888688\n",
            "Train Epoch: 3895 \tLoss: 1.888264\n",
            "Train Epoch: 3900 \tLoss: 1.887840\n",
            "\n",
            "Test set: Avg. loss: 1.9508, Accuracy: 291/500 (58%)\n",
            "\n",
            "Train Epoch: 3905 \tLoss: 1.887417\n",
            "Train Epoch: 3910 \tLoss: 1.886994\n",
            "Train Epoch: 3915 \tLoss: 1.886571\n",
            "Train Epoch: 3920 \tLoss: 1.886148\n",
            "Train Epoch: 3925 \tLoss: 1.885726\n",
            "\n",
            "Test set: Avg. loss: 1.9490, Accuracy: 291/500 (58%)\n",
            "\n",
            "Train Epoch: 3930 \tLoss: 1.885303\n",
            "Train Epoch: 3935 \tLoss: 1.884881\n",
            "Train Epoch: 3940 \tLoss: 1.884459\n",
            "Train Epoch: 3945 \tLoss: 1.884038\n",
            "Train Epoch: 3950 \tLoss: 1.883616\n",
            "\n",
            "Test set: Avg. loss: 1.9473, Accuracy: 291/500 (58%)\n",
            "\n",
            "Train Epoch: 3955 \tLoss: 1.883195\n",
            "Train Epoch: 3960 \tLoss: 1.882774\n",
            "Train Epoch: 3965 \tLoss: 1.882353\n",
            "Train Epoch: 3970 \tLoss: 1.881932\n",
            "Train Epoch: 3975 \tLoss: 1.881512\n",
            "\n",
            "Test set: Avg. loss: 1.9456, Accuracy: 291/500 (58%)\n",
            "\n",
            "Train Epoch: 3980 \tLoss: 1.881092\n",
            "Train Epoch: 3985 \tLoss: 1.880672\n",
            "Train Epoch: 3990 \tLoss: 1.880252\n",
            "Train Epoch: 3995 \tLoss: 1.879832\n",
            "Train Epoch: 4000 \tLoss: 1.879413\n",
            "\n",
            "Test set: Avg. loss: 1.9438, Accuracy: 291/500 (58%)\n",
            "\n",
            "Train Epoch: 4005 \tLoss: 1.878994\n",
            "Train Epoch: 4010 \tLoss: 1.878574\n",
            "Train Epoch: 4015 \tLoss: 1.878156\n",
            "Train Epoch: 4020 \tLoss: 1.877737\n",
            "Train Epoch: 4025 \tLoss: 1.877319\n",
            "\n",
            "Test set: Avg. loss: 1.9421, Accuracy: 291/500 (58%)\n",
            "\n",
            "Train Epoch: 4030 \tLoss: 1.876901\n",
            "Train Epoch: 4035 \tLoss: 1.876482\n",
            "Train Epoch: 4040 \tLoss: 1.876065\n",
            "Train Epoch: 4045 \tLoss: 1.875647\n",
            "Train Epoch: 4050 \tLoss: 1.875230\n",
            "\n",
            "Test set: Avg. loss: 1.9403, Accuracy: 292/500 (58%)\n",
            "\n",
            "Train Epoch: 4055 \tLoss: 1.874812\n",
            "Train Epoch: 4060 \tLoss: 1.874396\n",
            "Train Epoch: 4065 \tLoss: 1.873979\n",
            "Train Epoch: 4070 \tLoss: 1.873562\n",
            "Train Epoch: 4075 \tLoss: 1.873146\n",
            "\n",
            "Test set: Avg. loss: 1.9386, Accuracy: 292/500 (58%)\n",
            "\n",
            "Train Epoch: 4080 \tLoss: 1.872730\n",
            "Train Epoch: 4085 \tLoss: 1.872314\n",
            "Train Epoch: 4090 \tLoss: 1.871898\n",
            "Train Epoch: 4095 \tLoss: 1.871482\n",
            "Train Epoch: 4100 \tLoss: 1.871067\n",
            "\n",
            "Test set: Avg. loss: 1.9369, Accuracy: 292/500 (58%)\n",
            "\n",
            "Train Epoch: 4105 \tLoss: 1.870652\n",
            "Train Epoch: 4110 \tLoss: 1.870237\n",
            "Train Epoch: 4115 \tLoss: 1.869822\n",
            "Train Epoch: 4120 \tLoss: 1.869408\n",
            "Train Epoch: 4125 \tLoss: 1.868994\n",
            "\n",
            "Test set: Avg. loss: 1.9352, Accuracy: 293/500 (59%)\n",
            "\n",
            "Train Epoch: 4130 \tLoss: 1.868579\n",
            "Train Epoch: 4135 \tLoss: 1.868165\n",
            "Train Epoch: 4140 \tLoss: 1.867752\n",
            "Train Epoch: 4145 \tLoss: 1.867338\n",
            "Train Epoch: 4150 \tLoss: 1.866925\n",
            "\n",
            "Test set: Avg. loss: 1.9335, Accuracy: 293/500 (59%)\n",
            "\n",
            "Train Epoch: 4155 \tLoss: 1.866512\n",
            "Train Epoch: 4160 \tLoss: 1.866099\n",
            "Train Epoch: 4165 \tLoss: 1.865686\n",
            "Train Epoch: 4170 \tLoss: 1.865274\n",
            "Train Epoch: 4175 \tLoss: 1.864861\n",
            "\n",
            "Test set: Avg. loss: 1.9318, Accuracy: 293/500 (59%)\n",
            "\n",
            "Train Epoch: 4180 \tLoss: 1.864449\n",
            "Train Epoch: 4185 \tLoss: 1.864037\n",
            "Train Epoch: 4190 \tLoss: 1.863626\n",
            "Train Epoch: 4195 \tLoss: 1.863214\n",
            "Train Epoch: 4200 \tLoss: 1.862803\n",
            "\n",
            "Test set: Avg. loss: 1.9301, Accuracy: 293/500 (59%)\n",
            "\n",
            "Train Epoch: 4205 \tLoss: 1.862392\n",
            "Train Epoch: 4210 \tLoss: 1.861981\n",
            "Train Epoch: 4215 \tLoss: 1.861570\n",
            "Train Epoch: 4220 \tLoss: 1.861160\n",
            "Train Epoch: 4225 \tLoss: 1.860749\n",
            "\n",
            "Test set: Avg. loss: 1.9284, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4230 \tLoss: 1.860339\n",
            "Train Epoch: 4235 \tLoss: 1.859929\n",
            "Train Epoch: 4240 \tLoss: 1.859519\n",
            "Train Epoch: 4245 \tLoss: 1.859110\n",
            "Train Epoch: 4250 \tLoss: 1.858701\n",
            "\n",
            "Test set: Avg. loss: 1.9267, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4255 \tLoss: 1.858292\n",
            "Train Epoch: 4260 \tLoss: 1.857883\n",
            "Train Epoch: 4265 \tLoss: 1.857474\n",
            "Train Epoch: 4270 \tLoss: 1.857066\n",
            "Train Epoch: 4275 \tLoss: 1.856657\n",
            "\n",
            "Test set: Avg. loss: 1.9250, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4280 \tLoss: 1.856249\n",
            "Train Epoch: 4285 \tLoss: 1.855841\n",
            "Train Epoch: 4290 \tLoss: 1.855433\n",
            "Train Epoch: 4295 \tLoss: 1.855026\n",
            "Train Epoch: 4300 \tLoss: 1.854619\n",
            "\n",
            "Test set: Avg. loss: 1.9233, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4305 \tLoss: 1.854212\n",
            "Train Epoch: 4310 \tLoss: 1.853805\n",
            "Train Epoch: 4315 \tLoss: 1.853398\n",
            "Train Epoch: 4320 \tLoss: 1.852991\n",
            "Train Epoch: 4325 \tLoss: 1.852585\n",
            "\n",
            "Test set: Avg. loss: 1.9216, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4330 \tLoss: 1.852179\n",
            "Train Epoch: 4335 \tLoss: 1.851773\n",
            "Train Epoch: 4340 \tLoss: 1.851367\n",
            "Train Epoch: 4345 \tLoss: 1.850962\n",
            "Train Epoch: 4350 \tLoss: 1.850556\n",
            "\n",
            "Test set: Avg. loss: 1.9199, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4355 \tLoss: 1.850152\n",
            "Train Epoch: 4360 \tLoss: 1.849746\n",
            "Train Epoch: 4365 \tLoss: 1.849342\n",
            "Train Epoch: 4370 \tLoss: 1.848937\n",
            "Train Epoch: 4375 \tLoss: 1.848533\n",
            "\n",
            "Test set: Avg. loss: 1.9182, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4380 \tLoss: 1.848129\n",
            "Train Epoch: 4385 \tLoss: 1.847725\n",
            "Train Epoch: 4390 \tLoss: 1.847321\n",
            "Train Epoch: 4395 \tLoss: 1.846918\n",
            "Train Epoch: 4400 \tLoss: 1.846514\n",
            "\n",
            "Test set: Avg. loss: 1.9166, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4405 \tLoss: 1.846111\n",
            "Train Epoch: 4410 \tLoss: 1.845708\n",
            "Train Epoch: 4415 \tLoss: 1.845305\n",
            "Train Epoch: 4420 \tLoss: 1.844903\n",
            "Train Epoch: 4425 \tLoss: 1.844500\n",
            "\n",
            "Test set: Avg. loss: 1.9149, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4430 \tLoss: 1.844098\n",
            "Train Epoch: 4435 \tLoss: 1.843696\n",
            "Train Epoch: 4440 \tLoss: 1.843294\n",
            "Train Epoch: 4445 \tLoss: 1.842893\n",
            "Train Epoch: 4450 \tLoss: 1.842491\n",
            "\n",
            "Test set: Avg. loss: 1.9132, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4455 \tLoss: 1.842090\n",
            "Train Epoch: 4460 \tLoss: 1.841689\n",
            "Train Epoch: 4465 \tLoss: 1.841288\n",
            "Train Epoch: 4470 \tLoss: 1.840888\n",
            "Train Epoch: 4475 \tLoss: 1.840487\n",
            "\n",
            "Test set: Avg. loss: 1.9116, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4480 \tLoss: 1.840087\n",
            "Train Epoch: 4485 \tLoss: 1.839687\n",
            "Train Epoch: 4490 \tLoss: 1.839287\n",
            "Train Epoch: 4495 \tLoss: 1.838887\n",
            "Train Epoch: 4500 \tLoss: 1.838488\n",
            "\n",
            "Test set: Avg. loss: 1.9099, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 4505 \tLoss: 1.838089\n",
            "Train Epoch: 4510 \tLoss: 1.837690\n",
            "Train Epoch: 4515 \tLoss: 1.837291\n",
            "Train Epoch: 4520 \tLoss: 1.836892\n",
            "Train Epoch: 4525 \tLoss: 1.836494\n",
            "\n",
            "Test set: Avg. loss: 1.9083, Accuracy: 295/500 (59%)\n",
            "\n",
            "Train Epoch: 4530 \tLoss: 1.836095\n",
            "Train Epoch: 4535 \tLoss: 1.835697\n",
            "Train Epoch: 4540 \tLoss: 1.835299\n",
            "Train Epoch: 4545 \tLoss: 1.834902\n",
            "Train Epoch: 4550 \tLoss: 1.834504\n",
            "\n",
            "Test set: Avg. loss: 1.9066, Accuracy: 295/500 (59%)\n",
            "\n",
            "Train Epoch: 4555 \tLoss: 1.834107\n",
            "Train Epoch: 4560 \tLoss: 1.833710\n",
            "Train Epoch: 4565 \tLoss: 1.833313\n",
            "Train Epoch: 4570 \tLoss: 1.832916\n",
            "Train Epoch: 4575 \tLoss: 1.832519\n",
            "\n",
            "Test set: Avg. loss: 1.9050, Accuracy: 295/500 (59%)\n",
            "\n",
            "Train Epoch: 4580 \tLoss: 1.832123\n",
            "Train Epoch: 4585 \tLoss: 1.831727\n",
            "Train Epoch: 4590 \tLoss: 1.831331\n",
            "Train Epoch: 4595 \tLoss: 1.830935\n",
            "Train Epoch: 4600 \tLoss: 1.830540\n",
            "\n",
            "Test set: Avg. loss: 1.9034, Accuracy: 295/500 (59%)\n",
            "\n",
            "Train Epoch: 4605 \tLoss: 1.830144\n",
            "Train Epoch: 4610 \tLoss: 1.829749\n",
            "Train Epoch: 4615 \tLoss: 1.829354\n",
            "Train Epoch: 4620 \tLoss: 1.828959\n",
            "Train Epoch: 4625 \tLoss: 1.828565\n",
            "\n",
            "Test set: Avg. loss: 1.9017, Accuracy: 295/500 (59%)\n",
            "\n",
            "Train Epoch: 4630 \tLoss: 1.828170\n",
            "Train Epoch: 4635 \tLoss: 1.827776\n",
            "Train Epoch: 4640 \tLoss: 1.827382\n",
            "Train Epoch: 4645 \tLoss: 1.826988\n",
            "Train Epoch: 4650 \tLoss: 1.826595\n",
            "\n",
            "Test set: Avg. loss: 1.9001, Accuracy: 295/500 (59%)\n",
            "\n",
            "Train Epoch: 4655 \tLoss: 1.826201\n",
            "Train Epoch: 4660 \tLoss: 1.825808\n",
            "Train Epoch: 4665 \tLoss: 1.825415\n",
            "Train Epoch: 4670 \tLoss: 1.825022\n",
            "Train Epoch: 4675 \tLoss: 1.824629\n",
            "\n",
            "Test set: Avg. loss: 1.8985, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 4680 \tLoss: 1.824237\n",
            "Train Epoch: 4685 \tLoss: 1.823844\n",
            "Train Epoch: 4690 \tLoss: 1.823452\n",
            "Train Epoch: 4695 \tLoss: 1.823060\n",
            "Train Epoch: 4700 \tLoss: 1.822668\n",
            "\n",
            "Test set: Avg. loss: 1.8969, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 4705 \tLoss: 1.822277\n",
            "Train Epoch: 4710 \tLoss: 1.821885\n",
            "Train Epoch: 4715 \tLoss: 1.821494\n",
            "Train Epoch: 4720 \tLoss: 1.821103\n",
            "Train Epoch: 4725 \tLoss: 1.820713\n",
            "\n",
            "Test set: Avg. loss: 1.8953, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 4730 \tLoss: 1.820322\n",
            "Train Epoch: 4735 \tLoss: 1.819932\n",
            "Train Epoch: 4740 \tLoss: 1.819541\n",
            "Train Epoch: 4745 \tLoss: 1.819151\n",
            "Train Epoch: 4750 \tLoss: 1.818761\n",
            "\n",
            "Test set: Avg. loss: 1.8936, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 4755 \tLoss: 1.818372\n",
            "Train Epoch: 4760 \tLoss: 1.817982\n",
            "Train Epoch: 4765 \tLoss: 1.817593\n",
            "Train Epoch: 4770 \tLoss: 1.817204\n",
            "Train Epoch: 4775 \tLoss: 1.816815\n",
            "\n",
            "Test set: Avg. loss: 1.8920, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 4780 \tLoss: 1.816426\n",
            "Train Epoch: 4785 \tLoss: 1.816038\n",
            "Train Epoch: 4790 \tLoss: 1.815649\n",
            "Train Epoch: 4795 \tLoss: 1.815261\n",
            "Train Epoch: 4800 \tLoss: 1.814873\n",
            "\n",
            "Test set: Avg. loss: 1.8904, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 4805 \tLoss: 1.814485\n",
            "Train Epoch: 4810 \tLoss: 1.814098\n",
            "Train Epoch: 4815 \tLoss: 1.813710\n",
            "Train Epoch: 4820 \tLoss: 1.813323\n",
            "Train Epoch: 4825 \tLoss: 1.812936\n",
            "\n",
            "Test set: Avg. loss: 1.8888, Accuracy: 297/500 (59%)\n",
            "\n",
            "Train Epoch: 4830 \tLoss: 1.812549\n",
            "Train Epoch: 4835 \tLoss: 1.812163\n",
            "Train Epoch: 4840 \tLoss: 1.811776\n",
            "Train Epoch: 4845 \tLoss: 1.811390\n",
            "Train Epoch: 4850 \tLoss: 1.811004\n",
            "\n",
            "Test set: Avg. loss: 1.8872, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 4855 \tLoss: 1.810618\n",
            "Train Epoch: 4860 \tLoss: 1.810232\n",
            "Train Epoch: 4865 \tLoss: 1.809847\n",
            "Train Epoch: 4870 \tLoss: 1.809461\n",
            "Train Epoch: 4875 \tLoss: 1.809076\n",
            "\n",
            "Test set: Avg. loss: 1.8857, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 4880 \tLoss: 1.808691\n",
            "Train Epoch: 4885 \tLoss: 1.808306\n",
            "Train Epoch: 4890 \tLoss: 1.807922\n",
            "Train Epoch: 4895 \tLoss: 1.807537\n",
            "Train Epoch: 4900 \tLoss: 1.807153\n",
            "\n",
            "Test set: Avg. loss: 1.8841, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 4905 \tLoss: 1.806769\n",
            "Train Epoch: 4910 \tLoss: 1.806386\n",
            "Train Epoch: 4915 \tLoss: 1.806002\n",
            "Train Epoch: 4920 \tLoss: 1.805618\n",
            "Train Epoch: 4925 \tLoss: 1.805235\n",
            "\n",
            "Test set: Avg. loss: 1.8825, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 4930 \tLoss: 1.804852\n",
            "Train Epoch: 4935 \tLoss: 1.804469\n",
            "Train Epoch: 4940 \tLoss: 1.804086\n",
            "Train Epoch: 4945 \tLoss: 1.803704\n",
            "Train Epoch: 4950 \tLoss: 1.803321\n",
            "\n",
            "Test set: Avg. loss: 1.8809, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 4955 \tLoss: 1.802939\n",
            "Train Epoch: 4960 \tLoss: 1.802557\n",
            "Train Epoch: 4965 \tLoss: 1.802175\n",
            "Train Epoch: 4970 \tLoss: 1.801794\n",
            "Train Epoch: 4975 \tLoss: 1.801412\n",
            "\n",
            "Test set: Avg. loss: 1.8793, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 4980 \tLoss: 1.801031\n",
            "Train Epoch: 4985 \tLoss: 1.800650\n",
            "Train Epoch: 4990 \tLoss: 1.800269\n",
            "Train Epoch: 4995 \tLoss: 1.799888\n",
            "Train Epoch: 5000 \tLoss: 1.799508\n",
            "\n",
            "Test set: Avg. loss: 1.8778, Accuracy: 299/500 (60%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#train only fc2:\n",
        "network = Net()\n",
        "train_losses.clear()\n",
        "test_losses.clear()\n",
        "#count=[]\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
        "\n",
        "#freeze the other layers:\n",
        "network.fc1.weight.requires_grad=False\n",
        "network.fc1.bias.requires_grad=False\n",
        "\n",
        "network.conv2.weight.requires_grad=False\n",
        "network.conv2.bias.requires_grad=False\n",
        "\n",
        "network.conv1.weight.requires_grad=False\n",
        "network.conv1.bias.requires_grad=False\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, network.parameters()), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "\n",
        "# save the initial weights to measure later their contribution:\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()\n",
        "\n",
        "#train\n",
        "test_n = 25\n",
        "test()\n",
        "count = []\n",
        "n_epochs=5000\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  if epoch % test_n == 0:\n",
        "    test()\n",
        "    count.append(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.arange(0,n_epochs)\n",
        "count = np.arange(0,n_epochs+test_n,test_n)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(x, train_losses, color='blue', zorder=1)\n",
        "plt.plot(count, test_losses, color='red', zorder=2)\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.xlabel('number of training examples seen')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.2955, Accuracy: 79/500 (16%)\n",
            "\n",
            "Train Epoch: 5 \tLoss: 2.287640\n",
            "Train Epoch: 10 \tLoss: 2.284153\n",
            "Train Epoch: 15 \tLoss: 2.280697\n",
            "Train Epoch: 20 \tLoss: 2.277290\n",
            "Train Epoch: 25 \tLoss: 2.273932\n",
            "\n",
            "Test set: Avg. loss: 2.2816, Accuracy: 98/500 (20%)\n",
            "\n",
            "Train Epoch: 30 \tLoss: 2.270606\n",
            "Train Epoch: 35 \tLoss: 2.267331\n",
            "Train Epoch: 40 \tLoss: 2.264103\n",
            "Train Epoch: 45 \tLoss: 2.260919\n",
            "Train Epoch: 50 \tLoss: 2.257784\n",
            "\n",
            "Test set: Avg. loss: 2.2684, Accuracy: 111/500 (22%)\n",
            "\n",
            "Train Epoch: 55 \tLoss: 2.254695\n",
            "Train Epoch: 60 \tLoss: 2.251647\n",
            "Train Epoch: 65 \tLoss: 2.248640\n",
            "Train Epoch: 70 \tLoss: 2.245671\n",
            "Train Epoch: 75 \tLoss: 2.242734\n",
            "\n",
            "Test set: Avg. loss: 2.2559, Accuracy: 137/500 (27%)\n",
            "\n",
            "Train Epoch: 80 \tLoss: 2.239828\n",
            "Train Epoch: 85 \tLoss: 2.236959\n",
            "Train Epoch: 90 \tLoss: 2.234127\n",
            "Train Epoch: 95 \tLoss: 2.231333\n",
            "Train Epoch: 100 \tLoss: 2.228579\n",
            "\n",
            "Test set: Avg. loss: 2.2441, Accuracy: 157/500 (31%)\n",
            "\n",
            "Train Epoch: 105 \tLoss: 2.225866\n",
            "Train Epoch: 110 \tLoss: 2.223182\n",
            "Train Epoch: 115 \tLoss: 2.220532\n",
            "Train Epoch: 120 \tLoss: 2.217921\n",
            "Train Epoch: 125 \tLoss: 2.215338\n",
            "\n",
            "Test set: Avg. loss: 2.2331, Accuracy: 168/500 (34%)\n",
            "\n",
            "Train Epoch: 130 \tLoss: 2.212789\n",
            "Train Epoch: 135 \tLoss: 2.210285\n",
            "Train Epoch: 140 \tLoss: 2.207817\n",
            "Train Epoch: 145 \tLoss: 2.205383\n",
            "Train Epoch: 150 \tLoss: 2.202968\n",
            "\n",
            "Test set: Avg. loss: 2.2226, Accuracy: 196/500 (39%)\n",
            "\n",
            "Train Epoch: 155 \tLoss: 2.200579\n",
            "Train Epoch: 160 \tLoss: 2.198224\n",
            "Train Epoch: 165 \tLoss: 2.195907\n",
            "Train Epoch: 170 \tLoss: 2.193620\n",
            "Train Epoch: 175 \tLoss: 2.191361\n",
            "\n",
            "Test set: Avg. loss: 2.2128, Accuracy: 209/500 (42%)\n",
            "\n",
            "Train Epoch: 180 \tLoss: 2.189133\n",
            "Train Epoch: 185 \tLoss: 2.186931\n",
            "Train Epoch: 190 \tLoss: 2.184752\n",
            "Train Epoch: 195 \tLoss: 2.182606\n",
            "Train Epoch: 200 \tLoss: 2.180492\n",
            "\n",
            "Test set: Avg. loss: 2.2036, Accuracy: 220/500 (44%)\n",
            "\n",
            "Train Epoch: 205 \tLoss: 2.178408\n",
            "Train Epoch: 210 \tLoss: 2.176354\n",
            "Train Epoch: 215 \tLoss: 2.174324\n",
            "Train Epoch: 220 \tLoss: 2.172312\n",
            "Train Epoch: 225 \tLoss: 2.170328\n",
            "\n",
            "Test set: Avg. loss: 2.1950, Accuracy: 229/500 (46%)\n",
            "\n",
            "Train Epoch: 230 \tLoss: 2.168366\n",
            "Train Epoch: 235 \tLoss: 2.166425\n",
            "Train Epoch: 240 \tLoss: 2.164501\n",
            "Train Epoch: 245 \tLoss: 2.162600\n",
            "Train Epoch: 250 \tLoss: 2.160717\n",
            "\n",
            "Test set: Avg. loss: 2.1868, Accuracy: 238/500 (48%)\n",
            "\n",
            "Train Epoch: 255 \tLoss: 2.158848\n",
            "Train Epoch: 260 \tLoss: 2.156995\n",
            "Train Epoch: 265 \tLoss: 2.155163\n",
            "Train Epoch: 270 \tLoss: 2.153349\n",
            "Train Epoch: 275 \tLoss: 2.151560\n",
            "\n",
            "Test set: Avg. loss: 2.1791, Accuracy: 244/500 (49%)\n",
            "\n",
            "Train Epoch: 280 \tLoss: 2.149795\n",
            "Train Epoch: 285 \tLoss: 2.148055\n",
            "Train Epoch: 290 \tLoss: 2.146335\n",
            "Train Epoch: 295 \tLoss: 2.144629\n",
            "Train Epoch: 300 \tLoss: 2.142939\n",
            "\n",
            "Test set: Avg. loss: 2.1718, Accuracy: 250/500 (50%)\n",
            "\n",
            "Train Epoch: 305 \tLoss: 2.141265\n",
            "Train Epoch: 310 \tLoss: 2.139613\n",
            "Train Epoch: 315 \tLoss: 2.137975\n",
            "Train Epoch: 320 \tLoss: 2.136349\n",
            "Train Epoch: 325 \tLoss: 2.134735\n",
            "\n",
            "Test set: Avg. loss: 2.1649, Accuracy: 255/500 (51%)\n",
            "\n",
            "Train Epoch: 330 \tLoss: 2.133134\n",
            "Train Epoch: 335 \tLoss: 2.131553\n",
            "Train Epoch: 340 \tLoss: 2.129990\n",
            "Train Epoch: 345 \tLoss: 2.128440\n",
            "Train Epoch: 350 \tLoss: 2.126905\n",
            "\n",
            "Test set: Avg. loss: 2.1583, Accuracy: 259/500 (52%)\n",
            "\n",
            "Train Epoch: 355 \tLoss: 2.125385\n",
            "Train Epoch: 360 \tLoss: 2.123879\n",
            "Train Epoch: 365 \tLoss: 2.122388\n",
            "Train Epoch: 370 \tLoss: 2.120911\n",
            "Train Epoch: 375 \tLoss: 2.119450\n",
            "\n",
            "Test set: Avg. loss: 2.1519, Accuracy: 261/500 (52%)\n",
            "\n",
            "Train Epoch: 380 \tLoss: 2.118001\n",
            "Train Epoch: 385 \tLoss: 2.116566\n",
            "Train Epoch: 390 \tLoss: 2.115149\n",
            "Train Epoch: 395 \tLoss: 2.113745\n",
            "Train Epoch: 400 \tLoss: 2.112354\n",
            "\n",
            "Test set: Avg. loss: 2.1459, Accuracy: 268/500 (54%)\n",
            "\n",
            "Train Epoch: 405 \tLoss: 2.110975\n",
            "Train Epoch: 410 \tLoss: 2.109608\n",
            "Train Epoch: 415 \tLoss: 2.108254\n",
            "Train Epoch: 420 \tLoss: 2.106913\n",
            "Train Epoch: 425 \tLoss: 2.105582\n",
            "\n",
            "Test set: Avg. loss: 2.1402, Accuracy: 269/500 (54%)\n",
            "\n",
            "Train Epoch: 430 \tLoss: 2.104261\n",
            "Train Epoch: 435 \tLoss: 2.102947\n",
            "Train Epoch: 440 \tLoss: 2.101641\n",
            "Train Epoch: 445 \tLoss: 2.100344\n",
            "Train Epoch: 450 \tLoss: 2.099060\n",
            "\n",
            "Test set: Avg. loss: 2.1347, Accuracy: 269/500 (54%)\n",
            "\n",
            "Train Epoch: 455 \tLoss: 2.097788\n",
            "Train Epoch: 460 \tLoss: 2.096527\n",
            "Train Epoch: 465 \tLoss: 2.095276\n",
            "Train Epoch: 470 \tLoss: 2.094034\n",
            "Train Epoch: 475 \tLoss: 2.092802\n",
            "\n",
            "Test set: Avg. loss: 2.1294, Accuracy: 268/500 (54%)\n",
            "\n",
            "Train Epoch: 480 \tLoss: 2.091578\n",
            "Train Epoch: 485 \tLoss: 2.090364\n",
            "Train Epoch: 490 \tLoss: 2.089159\n",
            "Train Epoch: 495 \tLoss: 2.087965\n",
            "Train Epoch: 500 \tLoss: 2.086780\n",
            "\n",
            "Test set: Avg. loss: 2.1243, Accuracy: 271/500 (54%)\n",
            "\n",
            "Train Epoch: 505 \tLoss: 2.085601\n",
            "Train Epoch: 510 \tLoss: 2.084428\n",
            "Train Epoch: 515 \tLoss: 2.083263\n",
            "Train Epoch: 520 \tLoss: 2.082109\n",
            "Train Epoch: 525 \tLoss: 2.080963\n",
            "\n",
            "Test set: Avg. loss: 2.1195, Accuracy: 272/500 (54%)\n",
            "\n",
            "Train Epoch: 530 \tLoss: 2.079827\n",
            "Train Epoch: 535 \tLoss: 2.078698\n",
            "Train Epoch: 540 \tLoss: 2.077578\n",
            "Train Epoch: 545 \tLoss: 2.076465\n",
            "Train Epoch: 550 \tLoss: 2.075360\n",
            "\n",
            "Test set: Avg. loss: 2.1148, Accuracy: 275/500 (55%)\n",
            "\n",
            "Train Epoch: 555 \tLoss: 2.074263\n",
            "Train Epoch: 560 \tLoss: 2.073173\n",
            "Train Epoch: 565 \tLoss: 2.072091\n",
            "Train Epoch: 570 \tLoss: 2.071016\n",
            "Train Epoch: 575 \tLoss: 2.069947\n",
            "\n",
            "Test set: Avg. loss: 2.1103, Accuracy: 276/500 (55%)\n",
            "\n",
            "Train Epoch: 580 \tLoss: 2.068885\n",
            "Train Epoch: 585 \tLoss: 2.067831\n",
            "Train Epoch: 590 \tLoss: 2.066783\n",
            "Train Epoch: 595 \tLoss: 2.065743\n",
            "Train Epoch: 600 \tLoss: 2.064711\n",
            "\n",
            "Test set: Avg. loss: 2.1060, Accuracy: 275/500 (55%)\n",
            "\n",
            "Train Epoch: 605 \tLoss: 2.063687\n",
            "Train Epoch: 610 \tLoss: 2.062669\n",
            "Train Epoch: 615 \tLoss: 2.061659\n",
            "Train Epoch: 620 \tLoss: 2.060653\n",
            "Train Epoch: 625 \tLoss: 2.059655\n",
            "\n",
            "Test set: Avg. loss: 2.1018, Accuracy: 276/500 (55%)\n",
            "\n",
            "Train Epoch: 630 \tLoss: 2.058662\n",
            "Train Epoch: 635 \tLoss: 2.057676\n",
            "Train Epoch: 640 \tLoss: 2.056696\n",
            "Train Epoch: 645 \tLoss: 2.055722\n",
            "Train Epoch: 650 \tLoss: 2.054756\n",
            "\n",
            "Test set: Avg. loss: 2.0977, Accuracy: 278/500 (56%)\n",
            "\n",
            "Train Epoch: 655 \tLoss: 2.053794\n",
            "Train Epoch: 660 \tLoss: 2.052839\n",
            "Train Epoch: 665 \tLoss: 2.051890\n",
            "Train Epoch: 670 \tLoss: 2.050948\n",
            "Train Epoch: 675 \tLoss: 2.050011\n",
            "\n",
            "Test set: Avg. loss: 2.0938, Accuracy: 278/500 (56%)\n",
            "\n",
            "Train Epoch: 680 \tLoss: 2.049082\n",
            "Train Epoch: 685 \tLoss: 2.048158\n",
            "Train Epoch: 690 \tLoss: 2.047242\n",
            "Train Epoch: 695 \tLoss: 2.046330\n",
            "Train Epoch: 700 \tLoss: 2.045424\n",
            "\n",
            "Test set: Avg. loss: 2.0900, Accuracy: 281/500 (56%)\n",
            "\n",
            "Train Epoch: 705 \tLoss: 2.044526\n",
            "Train Epoch: 710 \tLoss: 2.043633\n",
            "Train Epoch: 715 \tLoss: 2.042746\n",
            "Train Epoch: 720 \tLoss: 2.041865\n",
            "Train Epoch: 725 \tLoss: 2.040988\n",
            "\n",
            "Test set: Avg. loss: 2.0864, Accuracy: 284/500 (57%)\n",
            "\n",
            "Train Epoch: 730 \tLoss: 2.040119\n",
            "Train Epoch: 735 \tLoss: 2.039254\n",
            "Train Epoch: 740 \tLoss: 2.038395\n",
            "Train Epoch: 745 \tLoss: 2.037540\n",
            "Train Epoch: 750 \tLoss: 2.036689\n",
            "\n",
            "Test set: Avg. loss: 2.0829, Accuracy: 283/500 (57%)\n",
            "\n",
            "Train Epoch: 755 \tLoss: 2.035842\n",
            "Train Epoch: 760 \tLoss: 2.035002\n",
            "Train Epoch: 765 \tLoss: 2.034168\n",
            "Train Epoch: 770 \tLoss: 2.033338\n",
            "Train Epoch: 775 \tLoss: 2.032515\n",
            "\n",
            "Test set: Avg. loss: 2.0794, Accuracy: 284/500 (57%)\n",
            "\n",
            "Train Epoch: 780 \tLoss: 2.031698\n",
            "Train Epoch: 785 \tLoss: 2.030885\n",
            "Train Epoch: 790 \tLoss: 2.030077\n",
            "Train Epoch: 795 \tLoss: 2.029274\n",
            "Train Epoch: 800 \tLoss: 2.028476\n",
            "\n",
            "Test set: Avg. loss: 2.0761, Accuracy: 283/500 (57%)\n",
            "\n",
            "Train Epoch: 805 \tLoss: 2.027683\n",
            "Train Epoch: 810 \tLoss: 2.026894\n",
            "Train Epoch: 815 \tLoss: 2.026110\n",
            "Train Epoch: 820 \tLoss: 2.025330\n",
            "Train Epoch: 825 \tLoss: 2.024556\n",
            "\n",
            "Test set: Avg. loss: 2.0729, Accuracy: 283/500 (57%)\n",
            "\n",
            "Train Epoch: 830 \tLoss: 2.023786\n",
            "Train Epoch: 835 \tLoss: 2.023021\n",
            "Train Epoch: 840 \tLoss: 2.022260\n",
            "Train Epoch: 845 \tLoss: 2.021503\n",
            "Train Epoch: 850 \tLoss: 2.020751\n",
            "\n",
            "Test set: Avg. loss: 2.0698, Accuracy: 284/500 (57%)\n",
            "\n",
            "Train Epoch: 855 \tLoss: 2.020001\n",
            "Train Epoch: 860 \tLoss: 2.019255\n",
            "Train Epoch: 865 \tLoss: 2.018514\n",
            "Train Epoch: 870 \tLoss: 2.017776\n",
            "Train Epoch: 875 \tLoss: 2.017041\n",
            "\n",
            "Test set: Avg. loss: 2.0668, Accuracy: 285/500 (57%)\n",
            "\n",
            "Train Epoch: 880 \tLoss: 2.016311\n",
            "Train Epoch: 885 \tLoss: 2.015585\n",
            "Train Epoch: 890 \tLoss: 2.014863\n",
            "Train Epoch: 895 \tLoss: 2.014145\n",
            "Train Epoch: 900 \tLoss: 2.013431\n",
            "\n",
            "Test set: Avg. loss: 2.0639, Accuracy: 287/500 (57%)\n",
            "\n",
            "Train Epoch: 905 \tLoss: 2.012722\n",
            "Train Epoch: 910 \tLoss: 2.012017\n",
            "Train Epoch: 915 \tLoss: 2.011315\n",
            "Train Epoch: 920 \tLoss: 2.010618\n",
            "Train Epoch: 925 \tLoss: 2.009925\n",
            "\n",
            "Test set: Avg. loss: 2.0610, Accuracy: 287/500 (57%)\n",
            "\n",
            "Train Epoch: 930 \tLoss: 2.009234\n",
            "Train Epoch: 935 \tLoss: 2.008547\n",
            "Train Epoch: 940 \tLoss: 2.007862\n",
            "Train Epoch: 945 \tLoss: 2.007181\n",
            "Train Epoch: 950 \tLoss: 2.006504\n",
            "\n",
            "Test set: Avg. loss: 2.0582, Accuracy: 287/500 (57%)\n",
            "\n",
            "Train Epoch: 955 \tLoss: 2.005830\n",
            "Train Epoch: 960 \tLoss: 2.005158\n",
            "Train Epoch: 965 \tLoss: 2.004490\n",
            "Train Epoch: 970 \tLoss: 2.003826\n",
            "Train Epoch: 975 \tLoss: 2.003165\n",
            "\n",
            "Test set: Avg. loss: 2.0555, Accuracy: 288/500 (58%)\n",
            "\n",
            "Train Epoch: 980 \tLoss: 2.002508\n",
            "Train Epoch: 985 \tLoss: 2.001854\n",
            "Train Epoch: 990 \tLoss: 2.001204\n",
            "Train Epoch: 995 \tLoss: 2.000556\n",
            "Train Epoch: 1000 \tLoss: 1.999912\n",
            "\n",
            "Test set: Avg. loss: 2.0529, Accuracy: 287/500 (57%)\n",
            "\n",
            "Train Epoch: 1005 \tLoss: 1.999271\n",
            "Train Epoch: 1010 \tLoss: 1.998633\n",
            "Train Epoch: 1015 \tLoss: 1.997998\n",
            "Train Epoch: 1020 \tLoss: 1.997365\n",
            "Train Epoch: 1025 \tLoss: 1.996736\n",
            "\n",
            "Test set: Avg. loss: 2.0503, Accuracy: 286/500 (57%)\n",
            "\n",
            "Train Epoch: 1030 \tLoss: 1.996110\n",
            "Train Epoch: 1035 \tLoss: 1.995488\n",
            "Train Epoch: 1040 \tLoss: 1.994870\n",
            "Train Epoch: 1045 \tLoss: 1.994253\n",
            "Train Epoch: 1050 \tLoss: 1.993639\n",
            "\n",
            "Test set: Avg. loss: 2.0478, Accuracy: 286/500 (57%)\n",
            "\n",
            "Train Epoch: 1055 \tLoss: 1.993028\n",
            "Train Epoch: 1060 \tLoss: 1.992419\n",
            "Train Epoch: 1065 \tLoss: 1.991813\n",
            "Train Epoch: 1070 \tLoss: 1.991210\n",
            "Train Epoch: 1075 \tLoss: 1.990610\n",
            "\n",
            "Test set: Avg. loss: 2.0453, Accuracy: 287/500 (57%)\n",
            "\n",
            "Train Epoch: 1080 \tLoss: 1.990014\n",
            "Train Epoch: 1085 \tLoss: 1.989420\n",
            "Train Epoch: 1090 \tLoss: 1.988830\n",
            "Train Epoch: 1095 \tLoss: 1.988243\n",
            "Train Epoch: 1100 \tLoss: 1.987658\n",
            "\n",
            "Test set: Avg. loss: 2.0429, Accuracy: 287/500 (57%)\n",
            "\n",
            "Train Epoch: 1105 \tLoss: 1.987077\n",
            "Train Epoch: 1110 \tLoss: 1.986497\n",
            "Train Epoch: 1115 \tLoss: 1.985920\n",
            "Train Epoch: 1120 \tLoss: 1.985346\n",
            "Train Epoch: 1125 \tLoss: 1.984774\n",
            "\n",
            "Test set: Avg. loss: 2.0406, Accuracy: 287/500 (57%)\n",
            "\n",
            "Train Epoch: 1130 \tLoss: 1.984206\n",
            "Train Epoch: 1135 \tLoss: 1.983640\n",
            "Train Epoch: 1140 \tLoss: 1.983077\n",
            "Train Epoch: 1145 \tLoss: 1.982515\n",
            "Train Epoch: 1150 \tLoss: 1.981956\n",
            "\n",
            "Test set: Avg. loss: 2.0383, Accuracy: 286/500 (57%)\n",
            "\n",
            "Train Epoch: 1155 \tLoss: 1.981399\n",
            "Train Epoch: 1160 \tLoss: 1.980844\n",
            "Train Epoch: 1165 \tLoss: 1.980292\n",
            "Train Epoch: 1170 \tLoss: 1.979742\n",
            "Train Epoch: 1175 \tLoss: 1.979194\n",
            "\n",
            "Test set: Avg. loss: 2.0361, Accuracy: 287/500 (57%)\n",
            "\n",
            "Train Epoch: 1180 \tLoss: 1.978649\n",
            "Train Epoch: 1185 \tLoss: 1.978106\n",
            "Train Epoch: 1190 \tLoss: 1.977567\n",
            "Train Epoch: 1195 \tLoss: 1.977030\n",
            "Train Epoch: 1200 \tLoss: 1.976494\n",
            "\n",
            "Test set: Avg. loss: 2.0339, Accuracy: 288/500 (58%)\n",
            "\n",
            "Train Epoch: 1205 \tLoss: 1.975961\n",
            "Train Epoch: 1210 \tLoss: 1.975431\n",
            "Train Epoch: 1215 \tLoss: 1.974903\n",
            "Train Epoch: 1220 \tLoss: 1.974378\n",
            "Train Epoch: 1225 \tLoss: 1.973855\n",
            "\n",
            "Test set: Avg. loss: 2.0317, Accuracy: 288/500 (58%)\n",
            "\n",
            "Train Epoch: 1230 \tLoss: 1.973334\n",
            "Train Epoch: 1235 \tLoss: 1.972815\n",
            "Train Epoch: 1240 \tLoss: 1.972299\n",
            "Train Epoch: 1245 \tLoss: 1.971785\n",
            "Train Epoch: 1250 \tLoss: 1.971273\n",
            "\n",
            "Test set: Avg. loss: 2.0296, Accuracy: 291/500 (58%)\n",
            "\n",
            "Train Epoch: 1255 \tLoss: 1.970764\n",
            "Train Epoch: 1260 \tLoss: 1.970256\n",
            "Train Epoch: 1265 \tLoss: 1.969750\n",
            "Train Epoch: 1270 \tLoss: 1.969246\n",
            "Train Epoch: 1275 \tLoss: 1.968745\n",
            "\n",
            "Test set: Avg. loss: 2.0276, Accuracy: 292/500 (58%)\n",
            "\n",
            "Train Epoch: 1280 \tLoss: 1.968245\n",
            "Train Epoch: 1285 \tLoss: 1.967748\n",
            "Train Epoch: 1290 \tLoss: 1.967253\n",
            "Train Epoch: 1295 \tLoss: 1.966760\n",
            "Train Epoch: 1300 \tLoss: 1.966268\n",
            "\n",
            "Test set: Avg. loss: 2.0256, Accuracy: 291/500 (58%)\n",
            "\n",
            "Train Epoch: 1305 \tLoss: 1.965779\n",
            "Train Epoch: 1310 \tLoss: 1.965292\n",
            "Train Epoch: 1315 \tLoss: 1.964806\n",
            "Train Epoch: 1320 \tLoss: 1.964323\n",
            "Train Epoch: 1325 \tLoss: 1.963842\n",
            "\n",
            "Test set: Avg. loss: 2.0236, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 1330 \tLoss: 1.963362\n",
            "Train Epoch: 1335 \tLoss: 1.962885\n",
            "Train Epoch: 1340 \tLoss: 1.962409\n",
            "Train Epoch: 1345 \tLoss: 1.961935\n",
            "Train Epoch: 1350 \tLoss: 1.961462\n",
            "\n",
            "Test set: Avg. loss: 2.0217, Accuracy: 293/500 (59%)\n",
            "\n",
            "Train Epoch: 1355 \tLoss: 1.960991\n",
            "Train Epoch: 1360 \tLoss: 1.960523\n",
            "Train Epoch: 1365 \tLoss: 1.960056\n",
            "Train Epoch: 1370 \tLoss: 1.959591\n",
            "Train Epoch: 1375 \tLoss: 1.959128\n",
            "\n",
            "Test set: Avg. loss: 2.0198, Accuracy: 293/500 (59%)\n",
            "\n",
            "Train Epoch: 1380 \tLoss: 1.958666\n",
            "Train Epoch: 1385 \tLoss: 1.958206\n",
            "Train Epoch: 1390 \tLoss: 1.957748\n",
            "Train Epoch: 1395 \tLoss: 1.957291\n",
            "Train Epoch: 1400 \tLoss: 1.956836\n",
            "\n",
            "Test set: Avg. loss: 2.0180, Accuracy: 294/500 (59%)\n",
            "\n",
            "Train Epoch: 1405 \tLoss: 1.956382\n",
            "Train Epoch: 1410 \tLoss: 1.955930\n",
            "Train Epoch: 1415 \tLoss: 1.955480\n",
            "Train Epoch: 1420 \tLoss: 1.955031\n",
            "Train Epoch: 1425 \tLoss: 1.954584\n",
            "\n",
            "Test set: Avg. loss: 2.0162, Accuracy: 295/500 (59%)\n",
            "\n",
            "Train Epoch: 1430 \tLoss: 1.954140\n",
            "Train Epoch: 1435 \tLoss: 1.953696\n",
            "Train Epoch: 1440 \tLoss: 1.953254\n",
            "Train Epoch: 1445 \tLoss: 1.952814\n",
            "Train Epoch: 1450 \tLoss: 1.952375\n",
            "\n",
            "Test set: Avg. loss: 2.0144, Accuracy: 295/500 (59%)\n",
            "\n",
            "Train Epoch: 1455 \tLoss: 1.951938\n",
            "Train Epoch: 1460 \tLoss: 1.951503\n",
            "Train Epoch: 1465 \tLoss: 1.951069\n",
            "Train Epoch: 1470 \tLoss: 1.950637\n",
            "Train Epoch: 1475 \tLoss: 1.950206\n",
            "\n",
            "Test set: Avg. loss: 2.0127, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 1480 \tLoss: 1.949777\n",
            "Train Epoch: 1485 \tLoss: 1.949349\n",
            "Train Epoch: 1490 \tLoss: 1.948923\n",
            "Train Epoch: 1495 \tLoss: 1.948499\n",
            "Train Epoch: 1500 \tLoss: 1.948077\n",
            "\n",
            "Test set: Avg. loss: 2.0110, Accuracy: 297/500 (59%)\n",
            "\n",
            "Train Epoch: 1505 \tLoss: 1.947656\n",
            "Train Epoch: 1510 \tLoss: 1.947237\n",
            "Train Epoch: 1515 \tLoss: 1.946820\n",
            "Train Epoch: 1520 \tLoss: 1.946404\n",
            "Train Epoch: 1525 \tLoss: 1.945989\n",
            "\n",
            "Test set: Avg. loss: 2.0093, Accuracy: 297/500 (59%)\n",
            "\n",
            "Train Epoch: 1530 \tLoss: 1.945576\n",
            "Train Epoch: 1535 \tLoss: 1.945165\n",
            "Train Epoch: 1540 \tLoss: 1.944754\n",
            "Train Epoch: 1545 \tLoss: 1.944345\n",
            "Train Epoch: 1550 \tLoss: 1.943937\n",
            "\n",
            "Test set: Avg. loss: 2.0077, Accuracy: 297/500 (59%)\n",
            "\n",
            "Train Epoch: 1555 \tLoss: 1.943531\n",
            "Train Epoch: 1560 \tLoss: 1.943127\n",
            "Train Epoch: 1565 \tLoss: 1.942725\n",
            "Train Epoch: 1570 \tLoss: 1.942324\n",
            "Train Epoch: 1575 \tLoss: 1.941924\n",
            "\n",
            "Test set: Avg. loss: 2.0061, Accuracy: 297/500 (59%)\n",
            "\n",
            "Train Epoch: 1580 \tLoss: 1.941526\n",
            "Train Epoch: 1585 \tLoss: 1.941129\n",
            "Train Epoch: 1590 \tLoss: 1.940733\n",
            "Train Epoch: 1595 \tLoss: 1.940339\n",
            "Train Epoch: 1600 \tLoss: 1.939946\n",
            "\n",
            "Test set: Avg. loss: 2.0045, Accuracy: 297/500 (59%)\n",
            "\n",
            "Train Epoch: 1605 \tLoss: 1.939554\n",
            "Train Epoch: 1610 \tLoss: 1.939164\n",
            "Train Epoch: 1615 \tLoss: 1.938775\n",
            "Train Epoch: 1620 \tLoss: 1.938386\n",
            "Train Epoch: 1625 \tLoss: 1.937999\n",
            "\n",
            "Test set: Avg. loss: 2.0029, Accuracy: 297/500 (59%)\n",
            "\n",
            "Train Epoch: 1630 \tLoss: 1.937614\n",
            "Train Epoch: 1635 \tLoss: 1.937230\n",
            "Train Epoch: 1640 \tLoss: 1.936847\n",
            "Train Epoch: 1645 \tLoss: 1.936465\n",
            "Train Epoch: 1650 \tLoss: 1.936085\n",
            "\n",
            "Test set: Avg. loss: 2.0014, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 1655 \tLoss: 1.935705\n",
            "Train Epoch: 1660 \tLoss: 1.935327\n",
            "Train Epoch: 1665 \tLoss: 1.934950\n",
            "Train Epoch: 1670 \tLoss: 1.934574\n",
            "Train Epoch: 1675 \tLoss: 1.934199\n",
            "\n",
            "Test set: Avg. loss: 1.9999, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 1680 \tLoss: 1.933826\n",
            "Train Epoch: 1685 \tLoss: 1.933453\n",
            "Train Epoch: 1690 \tLoss: 1.933082\n",
            "Train Epoch: 1695 \tLoss: 1.932712\n",
            "Train Epoch: 1700 \tLoss: 1.932343\n",
            "\n",
            "Test set: Avg. loss: 1.9984, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 1705 \tLoss: 1.931976\n",
            "Train Epoch: 1710 \tLoss: 1.931609\n",
            "Train Epoch: 1715 \tLoss: 1.931244\n",
            "Train Epoch: 1720 \tLoss: 1.930879\n",
            "Train Epoch: 1725 \tLoss: 1.930516\n",
            "\n",
            "Test set: Avg. loss: 1.9970, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 1730 \tLoss: 1.930154\n",
            "Train Epoch: 1735 \tLoss: 1.929793\n",
            "Train Epoch: 1740 \tLoss: 1.929433\n",
            "Train Epoch: 1745 \tLoss: 1.929073\n",
            "Train Epoch: 1750 \tLoss: 1.928715\n",
            "\n",
            "Test set: Avg. loss: 1.9956, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 1755 \tLoss: 1.928357\n",
            "Train Epoch: 1760 \tLoss: 1.928001\n",
            "Train Epoch: 1765 \tLoss: 1.927646\n",
            "Train Epoch: 1770 \tLoss: 1.927292\n",
            "Train Epoch: 1775 \tLoss: 1.926939\n",
            "\n",
            "Test set: Avg. loss: 1.9942, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 1780 \tLoss: 1.926588\n",
            "Train Epoch: 1785 \tLoss: 1.926237\n",
            "Train Epoch: 1790 \tLoss: 1.925887\n",
            "Train Epoch: 1795 \tLoss: 1.925538\n",
            "Train Epoch: 1800 \tLoss: 1.925190\n",
            "\n",
            "Test set: Avg. loss: 1.9928, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 1805 \tLoss: 1.924844\n",
            "Train Epoch: 1810 \tLoss: 1.924499\n",
            "Train Epoch: 1815 \tLoss: 1.924155\n",
            "Train Epoch: 1820 \tLoss: 1.923811\n",
            "Train Epoch: 1825 \tLoss: 1.923469\n",
            "\n",
            "Test set: Avg. loss: 1.9915, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 1830 \tLoss: 1.923127\n",
            "Train Epoch: 1835 \tLoss: 1.922787\n",
            "Train Epoch: 1840 \tLoss: 1.922448\n",
            "Train Epoch: 1845 \tLoss: 1.922109\n",
            "Train Epoch: 1850 \tLoss: 1.921771\n",
            "\n",
            "Test set: Avg. loss: 1.9902, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 1855 \tLoss: 1.921434\n",
            "Train Epoch: 1860 \tLoss: 1.921098\n",
            "Train Epoch: 1865 \tLoss: 1.920763\n",
            "Train Epoch: 1870 \tLoss: 1.920429\n",
            "Train Epoch: 1875 \tLoss: 1.920096\n",
            "\n",
            "Test set: Avg. loss: 1.9888, Accuracy: 297/500 (59%)\n",
            "\n",
            "Train Epoch: 1880 \tLoss: 1.919764\n",
            "Train Epoch: 1885 \tLoss: 1.919433\n",
            "Train Epoch: 1890 \tLoss: 1.919102\n",
            "Train Epoch: 1895 \tLoss: 1.918772\n",
            "Train Epoch: 1900 \tLoss: 1.918444\n",
            "\n",
            "Test set: Avg. loss: 1.9876, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 1905 \tLoss: 1.918116\n",
            "Train Epoch: 1910 \tLoss: 1.917788\n",
            "Train Epoch: 1915 \tLoss: 1.917461\n",
            "Train Epoch: 1920 \tLoss: 1.917136\n",
            "Train Epoch: 1925 \tLoss: 1.916811\n",
            "\n",
            "Test set: Avg. loss: 1.9863, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 1930 \tLoss: 1.916487\n",
            "Train Epoch: 1935 \tLoss: 1.916164\n",
            "Train Epoch: 1940 \tLoss: 1.915842\n",
            "Train Epoch: 1945 \tLoss: 1.915521\n",
            "Train Epoch: 1950 \tLoss: 1.915201\n",
            "\n",
            "Test set: Avg. loss: 1.9850, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 1955 \tLoss: 1.914882\n",
            "Train Epoch: 1960 \tLoss: 1.914563\n",
            "Train Epoch: 1965 \tLoss: 1.914245\n",
            "Train Epoch: 1970 \tLoss: 1.913928\n",
            "Train Epoch: 1975 \tLoss: 1.913611\n",
            "\n",
            "Test set: Avg. loss: 1.9838, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 1980 \tLoss: 1.913296\n",
            "Train Epoch: 1985 \tLoss: 1.912981\n",
            "Train Epoch: 1990 \tLoss: 1.912666\n",
            "Train Epoch: 1995 \tLoss: 1.912352\n",
            "Train Epoch: 2000 \tLoss: 1.912039\n",
            "\n",
            "Test set: Avg. loss: 1.9826, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 2005 \tLoss: 1.911727\n",
            "Train Epoch: 2010 \tLoss: 1.911416\n",
            "Train Epoch: 2015 \tLoss: 1.911106\n",
            "Train Epoch: 2020 \tLoss: 1.910796\n",
            "Train Epoch: 2025 \tLoss: 1.910488\n",
            "\n",
            "Test set: Avg. loss: 1.9814, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 2030 \tLoss: 1.910180\n",
            "Train Epoch: 2035 \tLoss: 1.909874\n",
            "Train Epoch: 2040 \tLoss: 1.909568\n",
            "Train Epoch: 2045 \tLoss: 1.909263\n",
            "Train Epoch: 2050 \tLoss: 1.908959\n",
            "\n",
            "Test set: Avg. loss: 1.9802, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 2055 \tLoss: 1.908656\n",
            "Train Epoch: 2060 \tLoss: 1.908353\n",
            "Train Epoch: 2065 \tLoss: 1.908052\n",
            "Train Epoch: 2070 \tLoss: 1.907751\n",
            "Train Epoch: 2075 \tLoss: 1.907451\n",
            "\n",
            "Test set: Avg. loss: 1.9790, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 2080 \tLoss: 1.907152\n",
            "Train Epoch: 2085 \tLoss: 1.906855\n",
            "Train Epoch: 2090 \tLoss: 1.906557\n",
            "Train Epoch: 2095 \tLoss: 1.906261\n",
            "Train Epoch: 2100 \tLoss: 1.905965\n",
            "\n",
            "Test set: Avg. loss: 1.9779, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 2105 \tLoss: 1.905670\n",
            "Train Epoch: 2110 \tLoss: 1.905375\n",
            "Train Epoch: 2115 \tLoss: 1.905082\n",
            "Train Epoch: 2120 \tLoss: 1.904789\n",
            "Train Epoch: 2125 \tLoss: 1.904496\n",
            "\n",
            "Test set: Avg. loss: 1.9767, Accuracy: 296/500 (59%)\n",
            "\n",
            "Train Epoch: 2130 \tLoss: 1.904205\n",
            "Train Epoch: 2135 \tLoss: 1.903913\n",
            "Train Epoch: 2140 \tLoss: 1.903623\n",
            "Train Epoch: 2145 \tLoss: 1.903333\n",
            "Train Epoch: 2150 \tLoss: 1.903044\n",
            "\n",
            "Test set: Avg. loss: 1.9756, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 2155 \tLoss: 1.902756\n",
            "Train Epoch: 2160 \tLoss: 1.902469\n",
            "Train Epoch: 2165 \tLoss: 1.902182\n",
            "Train Epoch: 2170 \tLoss: 1.901896\n",
            "Train Epoch: 2175 \tLoss: 1.901611\n",
            "\n",
            "Test set: Avg. loss: 1.9745, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 2180 \tLoss: 1.901326\n",
            "Train Epoch: 2185 \tLoss: 1.901042\n",
            "Train Epoch: 2190 \tLoss: 1.900759\n",
            "Train Epoch: 2195 \tLoss: 1.900476\n",
            "Train Epoch: 2200 \tLoss: 1.900193\n",
            "\n",
            "Test set: Avg. loss: 1.9734, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 2205 \tLoss: 1.899911\n",
            "Train Epoch: 2210 \tLoss: 1.899630\n",
            "Train Epoch: 2215 \tLoss: 1.899350\n",
            "Train Epoch: 2220 \tLoss: 1.899070\n",
            "Train Epoch: 2225 \tLoss: 1.898791\n",
            "\n",
            "Test set: Avg. loss: 1.9723, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 2230 \tLoss: 1.898513\n",
            "Train Epoch: 2235 \tLoss: 1.898236\n",
            "Train Epoch: 2240 \tLoss: 1.897960\n",
            "Train Epoch: 2245 \tLoss: 1.897685\n",
            "Train Epoch: 2250 \tLoss: 1.897410\n",
            "\n",
            "Test set: Avg. loss: 1.9712, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 2255 \tLoss: 1.897136\n",
            "Train Epoch: 2260 \tLoss: 1.896864\n",
            "Train Epoch: 2265 \tLoss: 1.896591\n",
            "Train Epoch: 2270 \tLoss: 1.896320\n",
            "Train Epoch: 2275 \tLoss: 1.896049\n",
            "\n",
            "Test set: Avg. loss: 1.9702, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 2280 \tLoss: 1.895779\n",
            "Train Epoch: 2285 \tLoss: 1.895510\n",
            "Train Epoch: 2290 \tLoss: 1.895241\n",
            "Train Epoch: 2295 \tLoss: 1.894973\n",
            "Train Epoch: 2300 \tLoss: 1.894705\n",
            "\n",
            "Test set: Avg. loss: 1.9692, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 2305 \tLoss: 1.894439\n",
            "Train Epoch: 2310 \tLoss: 1.894172\n",
            "Train Epoch: 2315 \tLoss: 1.893906\n",
            "Train Epoch: 2320 \tLoss: 1.893641\n",
            "Train Epoch: 2325 \tLoss: 1.893376\n",
            "\n",
            "Test set: Avg. loss: 1.9681, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 2330 \tLoss: 1.893112\n",
            "Train Epoch: 2335 \tLoss: 1.892849\n",
            "Train Epoch: 2340 \tLoss: 1.892585\n",
            "Train Epoch: 2345 \tLoss: 1.892323\n",
            "Train Epoch: 2350 \tLoss: 1.892060\n",
            "\n",
            "Test set: Avg. loss: 1.9671, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 2355 \tLoss: 1.891799\n",
            "Train Epoch: 2360 \tLoss: 1.891537\n",
            "Train Epoch: 2365 \tLoss: 1.891277\n",
            "Train Epoch: 2370 \tLoss: 1.891017\n",
            "Train Epoch: 2375 \tLoss: 1.890758\n",
            "\n",
            "Test set: Avg. loss: 1.9661, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 2380 \tLoss: 1.890499\n",
            "Train Epoch: 2385 \tLoss: 1.890241\n",
            "Train Epoch: 2390 \tLoss: 1.889984\n",
            "Train Epoch: 2395 \tLoss: 1.889727\n",
            "Train Epoch: 2400 \tLoss: 1.889471\n",
            "\n",
            "Test set: Avg. loss: 1.9651, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 2405 \tLoss: 1.889216\n",
            "Train Epoch: 2410 \tLoss: 1.888962\n",
            "Train Epoch: 2415 \tLoss: 1.888708\n",
            "Train Epoch: 2420 \tLoss: 1.888454\n",
            "Train Epoch: 2425 \tLoss: 1.888201\n",
            "\n",
            "Test set: Avg. loss: 1.9642, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 2430 \tLoss: 1.887949\n",
            "Train Epoch: 2435 \tLoss: 1.887697\n",
            "Train Epoch: 2440 \tLoss: 1.887446\n",
            "Train Epoch: 2445 \tLoss: 1.887195\n",
            "Train Epoch: 2450 \tLoss: 1.886945\n",
            "\n",
            "Test set: Avg. loss: 1.9632, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 2455 \tLoss: 1.886696\n",
            "Train Epoch: 2460 \tLoss: 1.886447\n",
            "Train Epoch: 2465 \tLoss: 1.886199\n",
            "Train Epoch: 2470 \tLoss: 1.885951\n",
            "Train Epoch: 2475 \tLoss: 1.885703\n",
            "\n",
            "Test set: Avg. loss: 1.9623, Accuracy: 298/500 (60%)\n",
            "\n",
            "Train Epoch: 2480 \tLoss: 1.885457\n",
            "Train Epoch: 2485 \tLoss: 1.885210\n",
            "Train Epoch: 2490 \tLoss: 1.884965\n",
            "Train Epoch: 2495 \tLoss: 1.884720\n",
            "Train Epoch: 2500 \tLoss: 1.884475\n",
            "\n",
            "Test set: Avg. loss: 1.9613, Accuracy: 299/500 (60%)\n",
            "\n",
            "Train Epoch: 2505 \tLoss: 1.884230\n",
            "Train Epoch: 2510 \tLoss: 1.883987\n",
            "Train Epoch: 2515 \tLoss: 1.883743\n",
            "Train Epoch: 2520 \tLoss: 1.883500\n",
            "Train Epoch: 2525 \tLoss: 1.883258\n",
            "\n",
            "Test set: Avg. loss: 1.9604, Accuracy: 300/500 (60%)\n",
            "\n",
            "Train Epoch: 2530 \tLoss: 1.883017\n",
            "Train Epoch: 2535 \tLoss: 1.882776\n",
            "Train Epoch: 2540 \tLoss: 1.882536\n",
            "Train Epoch: 2545 \tLoss: 1.882296\n",
            "Train Epoch: 2550 \tLoss: 1.882057\n",
            "\n",
            "Test set: Avg. loss: 1.9595, Accuracy: 300/500 (60%)\n",
            "\n",
            "Train Epoch: 2555 \tLoss: 1.881818\n",
            "Train Epoch: 2560 \tLoss: 1.881580\n",
            "Train Epoch: 2565 \tLoss: 1.881343\n",
            "Train Epoch: 2570 \tLoss: 1.881106\n",
            "Train Epoch: 2575 \tLoss: 1.880870\n",
            "\n",
            "Test set: Avg. loss: 1.9586, Accuracy: 300/500 (60%)\n",
            "\n",
            "Train Epoch: 2580 \tLoss: 1.880634\n",
            "Train Epoch: 2585 \tLoss: 1.880399\n",
            "Train Epoch: 2590 \tLoss: 1.880165\n",
            "Train Epoch: 2595 \tLoss: 1.879930\n",
            "Train Epoch: 2600 \tLoss: 1.879696\n",
            "\n",
            "Test set: Avg. loss: 1.9577, Accuracy: 300/500 (60%)\n",
            "\n",
            "Train Epoch: 2605 \tLoss: 1.879463\n",
            "Train Epoch: 2610 \tLoss: 1.879231\n",
            "Train Epoch: 2615 \tLoss: 1.878999\n",
            "Train Epoch: 2620 \tLoss: 1.878767\n",
            "Train Epoch: 2625 \tLoss: 1.878536\n",
            "\n",
            "Test set: Avg. loss: 1.9568, Accuracy: 301/500 (60%)\n",
            "\n",
            "Train Epoch: 2630 \tLoss: 1.878305\n",
            "Train Epoch: 2635 \tLoss: 1.878075\n",
            "Train Epoch: 2640 \tLoss: 1.877844\n",
            "Train Epoch: 2645 \tLoss: 1.877615\n",
            "Train Epoch: 2650 \tLoss: 1.877386\n",
            "\n",
            "Test set: Avg. loss: 1.9559, Accuracy: 301/500 (60%)\n",
            "\n",
            "Train Epoch: 2655 \tLoss: 1.877157\n",
            "Train Epoch: 2660 \tLoss: 1.876929\n",
            "Train Epoch: 2665 \tLoss: 1.876702\n",
            "Train Epoch: 2670 \tLoss: 1.876474\n",
            "Train Epoch: 2675 \tLoss: 1.876247\n",
            "\n",
            "Test set: Avg. loss: 1.9551, Accuracy: 301/500 (60%)\n",
            "\n",
            "Train Epoch: 2680 \tLoss: 1.876021\n",
            "Train Epoch: 2685 \tLoss: 1.875794\n",
            "Train Epoch: 2690 \tLoss: 1.875569\n",
            "Train Epoch: 2695 \tLoss: 1.875343\n",
            "Train Epoch: 2700 \tLoss: 1.875118\n",
            "\n",
            "Test set: Avg. loss: 1.9542, Accuracy: 303/500 (61%)\n",
            "\n",
            "Train Epoch: 2705 \tLoss: 1.874894\n",
            "Train Epoch: 2710 \tLoss: 1.874671\n",
            "Train Epoch: 2715 \tLoss: 1.874447\n",
            "Train Epoch: 2720 \tLoss: 1.874224\n",
            "Train Epoch: 2725 \tLoss: 1.874002\n",
            "\n",
            "Test set: Avg. loss: 1.9534, Accuracy: 304/500 (61%)\n",
            "\n",
            "Train Epoch: 2730 \tLoss: 1.873780\n",
            "Train Epoch: 2735 \tLoss: 1.873558\n",
            "Train Epoch: 2740 \tLoss: 1.873337\n",
            "Train Epoch: 2745 \tLoss: 1.873116\n",
            "Train Epoch: 2750 \tLoss: 1.872895\n",
            "\n",
            "Test set: Avg. loss: 1.9526, Accuracy: 304/500 (61%)\n",
            "\n",
            "Train Epoch: 2755 \tLoss: 1.872676\n",
            "Train Epoch: 2760 \tLoss: 1.872456\n",
            "Train Epoch: 2765 \tLoss: 1.872237\n",
            "Train Epoch: 2770 \tLoss: 1.872018\n",
            "Train Epoch: 2775 \tLoss: 1.871800\n",
            "\n",
            "Test set: Avg. loss: 1.9517, Accuracy: 304/500 (61%)\n",
            "\n",
            "Train Epoch: 2780 \tLoss: 1.871583\n",
            "Train Epoch: 2785 \tLoss: 1.871365\n",
            "Train Epoch: 2790 \tLoss: 1.871149\n",
            "Train Epoch: 2795 \tLoss: 1.870932\n",
            "Train Epoch: 2800 \tLoss: 1.870717\n",
            "\n",
            "Test set: Avg. loss: 1.9509, Accuracy: 304/500 (61%)\n",
            "\n",
            "Train Epoch: 2805 \tLoss: 1.870501\n",
            "Train Epoch: 2810 \tLoss: 1.870286\n",
            "Train Epoch: 2815 \tLoss: 1.870072\n",
            "Train Epoch: 2820 \tLoss: 1.869858\n",
            "Train Epoch: 2825 \tLoss: 1.869645\n",
            "\n",
            "Test set: Avg. loss: 1.9501, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 2830 \tLoss: 1.869432\n",
            "Train Epoch: 2835 \tLoss: 1.869220\n",
            "Train Epoch: 2840 \tLoss: 1.869007\n",
            "Train Epoch: 2845 \tLoss: 1.868796\n",
            "Train Epoch: 2850 \tLoss: 1.868585\n",
            "\n",
            "Test set: Avg. loss: 1.9493, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 2855 \tLoss: 1.868374\n",
            "Train Epoch: 2860 \tLoss: 1.868163\n",
            "Train Epoch: 2865 \tLoss: 1.867953\n",
            "Train Epoch: 2870 \tLoss: 1.867743\n",
            "Train Epoch: 2875 \tLoss: 1.867534\n",
            "\n",
            "Test set: Avg. loss: 1.9485, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 2880 \tLoss: 1.867326\n",
            "Train Epoch: 2885 \tLoss: 1.867117\n",
            "Train Epoch: 2890 \tLoss: 1.866909\n",
            "Train Epoch: 2895 \tLoss: 1.866702\n",
            "Train Epoch: 2900 \tLoss: 1.866495\n",
            "\n",
            "Test set: Avg. loss: 1.9477, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 2905 \tLoss: 1.866289\n",
            "Train Epoch: 2910 \tLoss: 1.866083\n",
            "Train Epoch: 2915 \tLoss: 1.865877\n",
            "Train Epoch: 2920 \tLoss: 1.865671\n",
            "Train Epoch: 2925 \tLoss: 1.865466\n",
            "\n",
            "Test set: Avg. loss: 1.9470, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 2930 \tLoss: 1.865261\n",
            "Train Epoch: 2935 \tLoss: 1.865057\n",
            "Train Epoch: 2940 \tLoss: 1.864854\n",
            "Train Epoch: 2945 \tLoss: 1.864650\n",
            "Train Epoch: 2950 \tLoss: 1.864447\n",
            "\n",
            "Test set: Avg. loss: 1.9462, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 2955 \tLoss: 1.864244\n",
            "Train Epoch: 2960 \tLoss: 1.864042\n",
            "Train Epoch: 2965 \tLoss: 1.863841\n",
            "Train Epoch: 2970 \tLoss: 1.863639\n",
            "Train Epoch: 2975 \tLoss: 1.863438\n",
            "\n",
            "Test set: Avg. loss: 1.9454, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 2980 \tLoss: 1.863237\n",
            "Train Epoch: 2985 \tLoss: 1.863036\n",
            "Train Epoch: 2990 \tLoss: 1.862836\n",
            "Train Epoch: 2995 \tLoss: 1.862636\n",
            "Train Epoch: 3000 \tLoss: 1.862437\n",
            "\n",
            "Test set: Avg. loss: 1.9447, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 3005 \tLoss: 1.862238\n",
            "Train Epoch: 3010 \tLoss: 1.862040\n",
            "Train Epoch: 3015 \tLoss: 1.861842\n",
            "Train Epoch: 3020 \tLoss: 1.861644\n",
            "Train Epoch: 3025 \tLoss: 1.861447\n",
            "\n",
            "Test set: Avg. loss: 1.9439, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 3030 \tLoss: 1.861250\n",
            "Train Epoch: 3035 \tLoss: 1.861054\n",
            "Train Epoch: 3040 \tLoss: 1.860858\n",
            "Train Epoch: 3045 \tLoss: 1.860662\n",
            "Train Epoch: 3050 \tLoss: 1.860467\n",
            "\n",
            "Test set: Avg. loss: 1.9432, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 3055 \tLoss: 1.860272\n",
            "Train Epoch: 3060 \tLoss: 1.860078\n",
            "Train Epoch: 3065 \tLoss: 1.859884\n",
            "Train Epoch: 3070 \tLoss: 1.859690\n",
            "Train Epoch: 3075 \tLoss: 1.859497\n",
            "\n",
            "Test set: Avg. loss: 1.9425, Accuracy: 306/500 (61%)\n",
            "\n",
            "Train Epoch: 3080 \tLoss: 1.859304\n",
            "Train Epoch: 3085 \tLoss: 1.859111\n",
            "Train Epoch: 3090 \tLoss: 1.858918\n",
            "Train Epoch: 3095 \tLoss: 1.858726\n",
            "Train Epoch: 3100 \tLoss: 1.858534\n",
            "\n",
            "Test set: Avg. loss: 1.9418, Accuracy: 307/500 (61%)\n",
            "\n",
            "Train Epoch: 3105 \tLoss: 1.858342\n",
            "Train Epoch: 3110 \tLoss: 1.858151\n",
            "Train Epoch: 3115 \tLoss: 1.857960\n",
            "Train Epoch: 3120 \tLoss: 1.857769\n",
            "Train Epoch: 3125 \tLoss: 1.857579\n",
            "\n",
            "Test set: Avg. loss: 1.9410, Accuracy: 307/500 (61%)\n",
            "\n",
            "Train Epoch: 3130 \tLoss: 1.857390\n",
            "Train Epoch: 3135 \tLoss: 1.857200\n",
            "Train Epoch: 3140 \tLoss: 1.857011\n",
            "Train Epoch: 3145 \tLoss: 1.856823\n",
            "Train Epoch: 3150 \tLoss: 1.856635\n",
            "\n",
            "Test set: Avg. loss: 1.9403, Accuracy: 307/500 (61%)\n",
            "\n",
            "Train Epoch: 3155 \tLoss: 1.856447\n",
            "Train Epoch: 3160 \tLoss: 1.856260\n",
            "Train Epoch: 3165 \tLoss: 1.856072\n",
            "Train Epoch: 3170 \tLoss: 1.855885\n",
            "Train Epoch: 3175 \tLoss: 1.855699\n",
            "\n",
            "Test set: Avg. loss: 1.9396, Accuracy: 307/500 (61%)\n",
            "\n",
            "Train Epoch: 3180 \tLoss: 1.855512\n",
            "Train Epoch: 3185 \tLoss: 1.855326\n",
            "Train Epoch: 3190 \tLoss: 1.855140\n",
            "Train Epoch: 3195 \tLoss: 1.854954\n",
            "Train Epoch: 3200 \tLoss: 1.854769\n",
            "\n",
            "Test set: Avg. loss: 1.9390, Accuracy: 306/500 (61%)\n",
            "\n",
            "Train Epoch: 3205 \tLoss: 1.854584\n",
            "Train Epoch: 3210 \tLoss: 1.854400\n",
            "Train Epoch: 3215 \tLoss: 1.854216\n",
            "Train Epoch: 3220 \tLoss: 1.854032\n",
            "Train Epoch: 3225 \tLoss: 1.853849\n",
            "\n",
            "Test set: Avg. loss: 1.9383, Accuracy: 306/500 (61%)\n",
            "\n",
            "Train Epoch: 3230 \tLoss: 1.853666\n",
            "Train Epoch: 3235 \tLoss: 1.853483\n",
            "Train Epoch: 3240 \tLoss: 1.853301\n",
            "Train Epoch: 3245 \tLoss: 1.853119\n",
            "Train Epoch: 3250 \tLoss: 1.852937\n",
            "\n",
            "Test set: Avg. loss: 1.9376, Accuracy: 306/500 (61%)\n",
            "\n",
            "Train Epoch: 3255 \tLoss: 1.852756\n",
            "Train Epoch: 3260 \tLoss: 1.852575\n",
            "Train Epoch: 3265 \tLoss: 1.852395\n",
            "Train Epoch: 3270 \tLoss: 1.852215\n",
            "Train Epoch: 3275 \tLoss: 1.852034\n",
            "\n",
            "Test set: Avg. loss: 1.9369, Accuracy: 306/500 (61%)\n",
            "\n",
            "Train Epoch: 3280 \tLoss: 1.851855\n",
            "Train Epoch: 3285 \tLoss: 1.851675\n",
            "Train Epoch: 3290 \tLoss: 1.851496\n",
            "Train Epoch: 3295 \tLoss: 1.851317\n",
            "Train Epoch: 3300 \tLoss: 1.851138\n",
            "\n",
            "Test set: Avg. loss: 1.9362, Accuracy: 306/500 (61%)\n",
            "\n",
            "Train Epoch: 3305 \tLoss: 1.850960\n",
            "Train Epoch: 3310 \tLoss: 1.850782\n",
            "Train Epoch: 3315 \tLoss: 1.850604\n",
            "Train Epoch: 3320 \tLoss: 1.850426\n",
            "Train Epoch: 3325 \tLoss: 1.850249\n",
            "\n",
            "Test set: Avg. loss: 1.9356, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 3330 \tLoss: 1.850072\n",
            "Train Epoch: 3335 \tLoss: 1.849895\n",
            "Train Epoch: 3340 \tLoss: 1.849718\n",
            "Train Epoch: 3345 \tLoss: 1.849542\n",
            "Train Epoch: 3350 \tLoss: 1.849366\n",
            "\n",
            "Test set: Avg. loss: 1.9349, Accuracy: 305/500 (61%)\n",
            "\n",
            "Train Epoch: 3355 \tLoss: 1.849191\n",
            "Train Epoch: 3360 \tLoss: 1.849016\n",
            "Train Epoch: 3365 \tLoss: 1.848841\n",
            "Train Epoch: 3370 \tLoss: 1.848666\n",
            "Train Epoch: 3375 \tLoss: 1.848492\n",
            "\n",
            "Test set: Avg. loss: 1.9343, Accuracy: 307/500 (61%)\n",
            "\n",
            "Train Epoch: 3380 \tLoss: 1.848318\n",
            "Train Epoch: 3385 \tLoss: 1.848144\n",
            "Train Epoch: 3390 \tLoss: 1.847970\n",
            "Train Epoch: 3395 \tLoss: 1.847797\n",
            "Train Epoch: 3400 \tLoss: 1.847625\n",
            "\n",
            "Test set: Avg. loss: 1.9336, Accuracy: 307/500 (61%)\n",
            "\n",
            "Train Epoch: 3405 \tLoss: 1.847452\n",
            "Train Epoch: 3410 \tLoss: 1.847279\n",
            "Train Epoch: 3415 \tLoss: 1.847107\n",
            "Train Epoch: 3420 \tLoss: 1.846935\n",
            "Train Epoch: 3425 \tLoss: 1.846763\n",
            "\n",
            "Test set: Avg. loss: 1.9330, Accuracy: 307/500 (61%)\n",
            "\n",
            "Train Epoch: 3430 \tLoss: 1.846592\n",
            "Train Epoch: 3435 \tLoss: 1.846421\n",
            "Train Epoch: 3440 \tLoss: 1.846250\n",
            "Train Epoch: 3445 \tLoss: 1.846080\n",
            "Train Epoch: 3450 \tLoss: 1.845910\n",
            "\n",
            "Test set: Avg. loss: 1.9324, Accuracy: 307/500 (61%)\n",
            "\n",
            "Train Epoch: 3455 \tLoss: 1.845740\n",
            "Train Epoch: 3460 \tLoss: 1.845571\n",
            "Train Epoch: 3465 \tLoss: 1.845402\n",
            "Train Epoch: 3470 \tLoss: 1.845232\n",
            "Train Epoch: 3475 \tLoss: 1.845063\n",
            "\n",
            "Test set: Avg. loss: 1.9317, Accuracy: 307/500 (61%)\n",
            "\n",
            "Train Epoch: 3480 \tLoss: 1.844895\n",
            "Train Epoch: 3485 \tLoss: 1.844726\n",
            "Train Epoch: 3490 \tLoss: 1.844559\n",
            "Train Epoch: 3495 \tLoss: 1.844391\n",
            "Train Epoch: 3500 \tLoss: 1.844224\n",
            "\n",
            "Test set: Avg. loss: 1.9311, Accuracy: 307/500 (61%)\n",
            "\n",
            "Train Epoch: 3505 \tLoss: 1.844057\n",
            "Train Epoch: 3510 \tLoss: 1.843890\n",
            "Train Epoch: 3515 \tLoss: 1.843724\n",
            "Train Epoch: 3520 \tLoss: 1.843557\n",
            "Train Epoch: 3525 \tLoss: 1.843391\n",
            "\n",
            "Test set: Avg. loss: 1.9305, Accuracy: 308/500 (62%)\n",
            "\n",
            "Train Epoch: 3530 \tLoss: 1.843225\n",
            "Train Epoch: 3535 \tLoss: 1.843060\n",
            "Train Epoch: 3540 \tLoss: 1.842895\n",
            "Train Epoch: 3545 \tLoss: 1.842730\n",
            "Train Epoch: 3550 \tLoss: 1.842566\n",
            "\n",
            "Test set: Avg. loss: 1.9299, Accuracy: 308/500 (62%)\n",
            "\n",
            "Train Epoch: 3555 \tLoss: 1.842401\n",
            "Train Epoch: 3560 \tLoss: 1.842237\n",
            "Train Epoch: 3565 \tLoss: 1.842073\n",
            "Train Epoch: 3570 \tLoss: 1.841909\n",
            "Train Epoch: 3575 \tLoss: 1.841746\n",
            "\n",
            "Test set: Avg. loss: 1.9293, Accuracy: 308/500 (62%)\n",
            "\n",
            "Train Epoch: 3580 \tLoss: 1.841583\n",
            "Train Epoch: 3585 \tLoss: 1.841420\n",
            "Train Epoch: 3590 \tLoss: 1.841257\n",
            "Train Epoch: 3595 \tLoss: 1.841095\n",
            "Train Epoch: 3600 \tLoss: 1.840932\n",
            "\n",
            "Test set: Avg. loss: 1.9287, Accuracy: 308/500 (62%)\n",
            "\n",
            "Train Epoch: 3605 \tLoss: 1.840771\n",
            "Train Epoch: 3610 \tLoss: 1.840609\n",
            "Train Epoch: 3615 \tLoss: 1.840448\n",
            "Train Epoch: 3620 \tLoss: 1.840287\n",
            "Train Epoch: 3625 \tLoss: 1.840127\n",
            "\n",
            "Test set: Avg. loss: 1.9281, Accuracy: 308/500 (62%)\n",
            "\n",
            "Train Epoch: 3630 \tLoss: 1.839966\n",
            "Train Epoch: 3635 \tLoss: 1.839806\n",
            "Train Epoch: 3640 \tLoss: 1.839646\n",
            "Train Epoch: 3645 \tLoss: 1.839486\n",
            "Train Epoch: 3650 \tLoss: 1.839327\n",
            "\n",
            "Test set: Avg. loss: 1.9275, Accuracy: 308/500 (62%)\n",
            "\n",
            "Train Epoch: 3655 \tLoss: 1.839168\n",
            "Train Epoch: 3660 \tLoss: 1.839009\n",
            "Train Epoch: 3665 \tLoss: 1.838851\n",
            "Train Epoch: 3670 \tLoss: 1.838693\n",
            "Train Epoch: 3675 \tLoss: 1.838535\n",
            "\n",
            "Test set: Avg. loss: 1.9269, Accuracy: 309/500 (62%)\n",
            "\n",
            "Train Epoch: 3680 \tLoss: 1.838378\n",
            "Train Epoch: 3685 \tLoss: 1.838220\n",
            "Train Epoch: 3690 \tLoss: 1.838063\n",
            "Train Epoch: 3695 \tLoss: 1.837906\n",
            "Train Epoch: 3700 \tLoss: 1.837750\n",
            "\n",
            "Test set: Avg. loss: 1.9264, Accuracy: 310/500 (62%)\n",
            "\n",
            "Train Epoch: 3705 \tLoss: 1.837593\n",
            "Train Epoch: 3710 \tLoss: 1.837437\n",
            "Train Epoch: 3715 \tLoss: 1.837281\n",
            "Train Epoch: 3720 \tLoss: 1.837125\n",
            "Train Epoch: 3725 \tLoss: 1.836970\n",
            "\n",
            "Test set: Avg. loss: 1.9258, Accuracy: 310/500 (62%)\n",
            "\n",
            "Train Epoch: 3730 \tLoss: 1.836814\n",
            "Train Epoch: 3735 \tLoss: 1.836660\n",
            "Train Epoch: 3740 \tLoss: 1.836505\n",
            "Train Epoch: 3745 \tLoss: 1.836350\n",
            "Train Epoch: 3750 \tLoss: 1.836196\n",
            "\n",
            "Test set: Avg. loss: 1.9252, Accuracy: 310/500 (62%)\n",
            "\n",
            "Train Epoch: 3755 \tLoss: 1.836042\n",
            "Train Epoch: 3760 \tLoss: 1.835888\n",
            "Train Epoch: 3765 \tLoss: 1.835734\n",
            "Train Epoch: 3770 \tLoss: 1.835581\n",
            "Train Epoch: 3775 \tLoss: 1.835428\n",
            "\n",
            "Test set: Avg. loss: 1.9247, Accuracy: 312/500 (62%)\n",
            "\n",
            "Train Epoch: 3780 \tLoss: 1.835275\n",
            "Train Epoch: 3785 \tLoss: 1.835123\n",
            "Train Epoch: 3790 \tLoss: 1.834970\n",
            "Train Epoch: 3795 \tLoss: 1.834818\n",
            "Train Epoch: 3800 \tLoss: 1.834666\n",
            "\n",
            "Test set: Avg. loss: 1.9241, Accuracy: 312/500 (62%)\n",
            "\n",
            "Train Epoch: 3805 \tLoss: 1.834514\n",
            "Train Epoch: 3810 \tLoss: 1.834363\n",
            "Train Epoch: 3815 \tLoss: 1.834211\n",
            "Train Epoch: 3820 \tLoss: 1.834060\n",
            "Train Epoch: 3825 \tLoss: 1.833910\n",
            "\n",
            "Test set: Avg. loss: 1.9235, Accuracy: 312/500 (62%)\n",
            "\n",
            "Train Epoch: 3830 \tLoss: 1.833759\n",
            "Train Epoch: 3835 \tLoss: 1.833609\n",
            "Train Epoch: 3840 \tLoss: 1.833459\n",
            "Train Epoch: 3845 \tLoss: 1.833309\n",
            "Train Epoch: 3850 \tLoss: 1.833159\n",
            "\n",
            "Test set: Avg. loss: 1.9230, Accuracy: 312/500 (62%)\n",
            "\n",
            "Train Epoch: 3855 \tLoss: 1.833010\n",
            "Train Epoch: 3860 \tLoss: 1.832861\n",
            "Train Epoch: 3865 \tLoss: 1.832712\n",
            "Train Epoch: 3870 \tLoss: 1.832563\n",
            "Train Epoch: 3875 \tLoss: 1.832415\n",
            "\n",
            "Test set: Avg. loss: 1.9224, Accuracy: 314/500 (63%)\n",
            "\n",
            "Train Epoch: 3880 \tLoss: 1.832267\n",
            "Train Epoch: 3885 \tLoss: 1.832119\n",
            "Train Epoch: 3890 \tLoss: 1.831971\n",
            "Train Epoch: 3895 \tLoss: 1.831824\n",
            "Train Epoch: 3900 \tLoss: 1.831677\n",
            "\n",
            "Test set: Avg. loss: 1.9219, Accuracy: 314/500 (63%)\n",
            "\n",
            "Train Epoch: 3905 \tLoss: 1.831530\n",
            "Train Epoch: 3910 \tLoss: 1.831383\n",
            "Train Epoch: 3915 \tLoss: 1.831237\n",
            "Train Epoch: 3920 \tLoss: 1.831090\n",
            "Train Epoch: 3925 \tLoss: 1.830944\n",
            "\n",
            "Test set: Avg. loss: 1.9214, Accuracy: 314/500 (63%)\n",
            "\n",
            "Train Epoch: 3930 \tLoss: 1.830798\n",
            "Train Epoch: 3935 \tLoss: 1.830653\n",
            "Train Epoch: 3940 \tLoss: 1.830507\n",
            "Train Epoch: 3945 \tLoss: 1.830362\n",
            "Train Epoch: 3950 \tLoss: 1.830217\n",
            "\n",
            "Test set: Avg. loss: 1.9208, Accuracy: 313/500 (63%)\n",
            "\n",
            "Train Epoch: 3955 \tLoss: 1.830072\n",
            "Train Epoch: 3960 \tLoss: 1.829927\n",
            "Train Epoch: 3965 \tLoss: 1.829783\n",
            "Train Epoch: 3970 \tLoss: 1.829639\n",
            "Train Epoch: 3975 \tLoss: 1.829495\n",
            "\n",
            "Test set: Avg. loss: 1.9203, Accuracy: 313/500 (63%)\n",
            "\n",
            "Train Epoch: 3980 \tLoss: 1.829351\n",
            "Train Epoch: 3985 \tLoss: 1.829207\n",
            "Train Epoch: 3990 \tLoss: 1.829064\n",
            "Train Epoch: 3995 \tLoss: 1.828921\n",
            "Train Epoch: 4000 \tLoss: 1.828778\n",
            "\n",
            "Test set: Avg. loss: 1.9198, Accuracy: 313/500 (63%)\n",
            "\n",
            "Train Epoch: 4005 \tLoss: 1.828635\n",
            "Train Epoch: 4010 \tLoss: 1.828492\n",
            "Train Epoch: 4015 \tLoss: 1.828350\n",
            "Train Epoch: 4020 \tLoss: 1.828207\n",
            "Train Epoch: 4025 \tLoss: 1.828065\n",
            "\n",
            "Test set: Avg. loss: 1.9193, Accuracy: 313/500 (63%)\n",
            "\n",
            "Train Epoch: 4030 \tLoss: 1.827923\n",
            "Train Epoch: 4035 \tLoss: 1.827781\n",
            "Train Epoch: 4040 \tLoss: 1.827640\n",
            "Train Epoch: 4045 \tLoss: 1.827498\n",
            "Train Epoch: 4050 \tLoss: 1.827356\n",
            "\n",
            "Test set: Avg. loss: 1.9188, Accuracy: 313/500 (63%)\n",
            "\n",
            "Train Epoch: 4055 \tLoss: 1.827215\n",
            "Train Epoch: 4060 \tLoss: 1.827074\n",
            "Train Epoch: 4065 \tLoss: 1.826933\n",
            "Train Epoch: 4070 \tLoss: 1.826792\n",
            "Train Epoch: 4075 \tLoss: 1.826652\n",
            "\n",
            "Test set: Avg. loss: 1.9182, Accuracy: 313/500 (63%)\n",
            "\n",
            "Train Epoch: 4080 \tLoss: 1.826512\n",
            "Train Epoch: 4085 \tLoss: 1.826371\n",
            "Train Epoch: 4090 \tLoss: 1.826232\n",
            "Train Epoch: 4095 \tLoss: 1.826092\n",
            "Train Epoch: 4100 \tLoss: 1.825953\n",
            "\n",
            "Test set: Avg. loss: 1.9177, Accuracy: 313/500 (63%)\n",
            "\n",
            "Train Epoch: 4105 \tLoss: 1.825813\n",
            "Train Epoch: 4110 \tLoss: 1.825674\n",
            "Train Epoch: 4115 \tLoss: 1.825535\n",
            "Train Epoch: 4120 \tLoss: 1.825396\n",
            "Train Epoch: 4125 \tLoss: 1.825257\n",
            "\n",
            "Test set: Avg. loss: 1.9172, Accuracy: 314/500 (63%)\n",
            "\n",
            "Train Epoch: 4130 \tLoss: 1.825118\n",
            "Train Epoch: 4135 \tLoss: 1.824980\n",
            "Train Epoch: 4140 \tLoss: 1.824842\n",
            "Train Epoch: 4145 \tLoss: 1.824704\n",
            "Train Epoch: 4150 \tLoss: 1.824566\n",
            "\n",
            "Test set: Avg. loss: 1.9167, Accuracy: 314/500 (63%)\n",
            "\n",
            "Train Epoch: 4155 \tLoss: 1.824429\n",
            "Train Epoch: 4160 \tLoss: 1.824291\n",
            "Train Epoch: 4165 \tLoss: 1.824154\n",
            "Train Epoch: 4170 \tLoss: 1.824018\n",
            "Train Epoch: 4175 \tLoss: 1.823881\n",
            "\n",
            "Test set: Avg. loss: 1.9162, Accuracy: 315/500 (63%)\n",
            "\n",
            "Train Epoch: 4180 \tLoss: 1.823744\n",
            "Train Epoch: 4185 \tLoss: 1.823608\n",
            "Train Epoch: 4190 \tLoss: 1.823471\n",
            "Train Epoch: 4195 \tLoss: 1.823335\n",
            "Train Epoch: 4200 \tLoss: 1.823199\n",
            "\n",
            "Test set: Avg. loss: 1.9157, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4205 \tLoss: 1.823063\n",
            "Train Epoch: 4210 \tLoss: 1.822927\n",
            "Train Epoch: 4215 \tLoss: 1.822792\n",
            "Train Epoch: 4220 \tLoss: 1.822657\n",
            "Train Epoch: 4225 \tLoss: 1.822522\n",
            "\n",
            "Test set: Avg. loss: 1.9152, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4230 \tLoss: 1.822387\n",
            "Train Epoch: 4235 \tLoss: 1.822252\n",
            "Train Epoch: 4240 \tLoss: 1.822117\n",
            "Train Epoch: 4245 \tLoss: 1.821983\n",
            "Train Epoch: 4250 \tLoss: 1.821849\n",
            "\n",
            "Test set: Avg. loss: 1.9148, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4255 \tLoss: 1.821715\n",
            "Train Epoch: 4260 \tLoss: 1.821581\n",
            "Train Epoch: 4265 \tLoss: 1.821447\n",
            "Train Epoch: 4270 \tLoss: 1.821314\n",
            "Train Epoch: 4275 \tLoss: 1.821181\n",
            "\n",
            "Test set: Avg. loss: 1.9143, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4280 \tLoss: 1.821048\n",
            "Train Epoch: 4285 \tLoss: 1.820915\n",
            "Train Epoch: 4290 \tLoss: 1.820782\n",
            "Train Epoch: 4295 \tLoss: 1.820649\n",
            "Train Epoch: 4300 \tLoss: 1.820517\n",
            "\n",
            "Test set: Avg. loss: 1.9138, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4305 \tLoss: 1.820385\n",
            "Train Epoch: 4310 \tLoss: 1.820253\n",
            "Train Epoch: 4315 \tLoss: 1.820121\n",
            "Train Epoch: 4320 \tLoss: 1.819989\n",
            "Train Epoch: 4325 \tLoss: 1.819857\n",
            "\n",
            "Test set: Avg. loss: 1.9133, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4330 \tLoss: 1.819726\n",
            "Train Epoch: 4335 \tLoss: 1.819595\n",
            "Train Epoch: 4340 \tLoss: 1.819463\n",
            "Train Epoch: 4345 \tLoss: 1.819333\n",
            "Train Epoch: 4350 \tLoss: 1.819202\n",
            "\n",
            "Test set: Avg. loss: 1.9128, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4355 \tLoss: 1.819072\n",
            "Train Epoch: 4360 \tLoss: 1.818941\n",
            "Train Epoch: 4365 \tLoss: 1.818812\n",
            "Train Epoch: 4370 \tLoss: 1.818682\n",
            "Train Epoch: 4375 \tLoss: 1.818552\n",
            "\n",
            "Test set: Avg. loss: 1.9124, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4380 \tLoss: 1.818422\n",
            "Train Epoch: 4385 \tLoss: 1.818293\n",
            "Train Epoch: 4390 \tLoss: 1.818164\n",
            "Train Epoch: 4395 \tLoss: 1.818036\n",
            "Train Epoch: 4400 \tLoss: 1.817907\n",
            "\n",
            "Test set: Avg. loss: 1.9119, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4405 \tLoss: 1.817779\n",
            "Train Epoch: 4410 \tLoss: 1.817650\n",
            "Train Epoch: 4415 \tLoss: 1.817522\n",
            "Train Epoch: 4420 \tLoss: 1.817394\n",
            "Train Epoch: 4425 \tLoss: 1.817266\n",
            "\n",
            "Test set: Avg. loss: 1.9114, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4430 \tLoss: 1.817139\n",
            "Train Epoch: 4435 \tLoss: 1.817011\n",
            "Train Epoch: 4440 \tLoss: 1.816883\n",
            "Train Epoch: 4445 \tLoss: 1.816756\n",
            "Train Epoch: 4450 \tLoss: 1.816629\n",
            "\n",
            "Test set: Avg. loss: 1.9110, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4455 \tLoss: 1.816502\n",
            "Train Epoch: 4460 \tLoss: 1.816375\n",
            "Train Epoch: 4465 \tLoss: 1.816249\n",
            "Train Epoch: 4470 \tLoss: 1.816123\n",
            "Train Epoch: 4475 \tLoss: 1.815996\n",
            "\n",
            "Test set: Avg. loss: 1.9105, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4480 \tLoss: 1.815870\n",
            "Train Epoch: 4485 \tLoss: 1.815744\n",
            "Train Epoch: 4490 \tLoss: 1.815618\n",
            "Train Epoch: 4495 \tLoss: 1.815492\n",
            "Train Epoch: 4500 \tLoss: 1.815367\n",
            "\n",
            "Test set: Avg. loss: 1.9100, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4505 \tLoss: 1.815241\n",
            "Train Epoch: 4510 \tLoss: 1.815116\n",
            "Train Epoch: 4515 \tLoss: 1.814991\n",
            "Train Epoch: 4520 \tLoss: 1.814866\n",
            "Train Epoch: 4525 \tLoss: 1.814741\n",
            "\n",
            "Test set: Avg. loss: 1.9096, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4530 \tLoss: 1.814617\n",
            "Train Epoch: 4535 \tLoss: 1.814492\n",
            "Train Epoch: 4540 \tLoss: 1.814368\n",
            "Train Epoch: 4545 \tLoss: 1.814244\n",
            "Train Epoch: 4550 \tLoss: 1.814120\n",
            "\n",
            "Test set: Avg. loss: 1.9091, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4555 \tLoss: 1.813996\n",
            "Train Epoch: 4560 \tLoss: 1.813873\n",
            "Train Epoch: 4565 \tLoss: 1.813749\n",
            "Train Epoch: 4570 \tLoss: 1.813625\n",
            "Train Epoch: 4575 \tLoss: 1.813502\n",
            "\n",
            "Test set: Avg. loss: 1.9087, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4580 \tLoss: 1.813380\n",
            "Train Epoch: 4585 \tLoss: 1.813257\n",
            "Train Epoch: 4590 \tLoss: 1.813134\n",
            "Train Epoch: 4595 \tLoss: 1.813011\n",
            "Train Epoch: 4600 \tLoss: 1.812888\n",
            "\n",
            "Test set: Avg. loss: 1.9082, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4605 \tLoss: 1.812766\n",
            "Train Epoch: 4610 \tLoss: 1.812644\n",
            "Train Epoch: 4615 \tLoss: 1.812522\n",
            "Train Epoch: 4620 \tLoss: 1.812400\n",
            "Train Epoch: 4625 \tLoss: 1.812278\n",
            "\n",
            "Test set: Avg. loss: 1.9078, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4630 \tLoss: 1.812156\n",
            "Train Epoch: 4635 \tLoss: 1.812035\n",
            "Train Epoch: 4640 \tLoss: 1.811913\n",
            "Train Epoch: 4645 \tLoss: 1.811792\n",
            "Train Epoch: 4650 \tLoss: 1.811671\n",
            "\n",
            "Test set: Avg. loss: 1.9074, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4655 \tLoss: 1.811550\n",
            "Train Epoch: 4660 \tLoss: 1.811429\n",
            "Train Epoch: 4665 \tLoss: 1.811309\n",
            "Train Epoch: 4670 \tLoss: 1.811188\n",
            "Train Epoch: 4675 \tLoss: 1.811067\n",
            "\n",
            "Test set: Avg. loss: 1.9069, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4680 \tLoss: 1.810947\n",
            "Train Epoch: 4685 \tLoss: 1.810827\n",
            "Train Epoch: 4690 \tLoss: 1.810706\n",
            "Train Epoch: 4695 \tLoss: 1.810587\n",
            "Train Epoch: 4700 \tLoss: 1.810467\n",
            "\n",
            "Test set: Avg. loss: 1.9065, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4705 \tLoss: 1.810347\n",
            "Train Epoch: 4710 \tLoss: 1.810228\n",
            "Train Epoch: 4715 \tLoss: 1.810108\n",
            "Train Epoch: 4720 \tLoss: 1.809989\n",
            "Train Epoch: 4725 \tLoss: 1.809870\n",
            "\n",
            "Test set: Avg. loss: 1.9061, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4730 \tLoss: 1.809752\n",
            "Train Epoch: 4735 \tLoss: 1.809633\n",
            "Train Epoch: 4740 \tLoss: 1.809514\n",
            "Train Epoch: 4745 \tLoss: 1.809396\n",
            "Train Epoch: 4750 \tLoss: 1.809278\n",
            "\n",
            "Test set: Avg. loss: 1.9056, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4755 \tLoss: 1.809160\n",
            "Train Epoch: 4760 \tLoss: 1.809042\n",
            "Train Epoch: 4765 \tLoss: 1.808924\n",
            "Train Epoch: 4770 \tLoss: 1.808806\n",
            "Train Epoch: 4775 \tLoss: 1.808689\n",
            "\n",
            "Test set: Avg. loss: 1.9052, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4780 \tLoss: 1.808571\n",
            "Train Epoch: 4785 \tLoss: 1.808453\n",
            "Train Epoch: 4790 \tLoss: 1.808336\n",
            "Train Epoch: 4795 \tLoss: 1.808219\n",
            "Train Epoch: 4800 \tLoss: 1.808102\n",
            "\n",
            "Test set: Avg. loss: 1.9048, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4805 \tLoss: 1.807985\n",
            "Train Epoch: 4810 \tLoss: 1.807868\n",
            "Train Epoch: 4815 \tLoss: 1.807752\n",
            "Train Epoch: 4820 \tLoss: 1.807636\n",
            "Train Epoch: 4825 \tLoss: 1.807519\n",
            "\n",
            "Test set: Avg. loss: 1.9044, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4830 \tLoss: 1.807403\n",
            "Train Epoch: 4835 \tLoss: 1.807287\n",
            "Train Epoch: 4840 \tLoss: 1.807171\n",
            "Train Epoch: 4845 \tLoss: 1.807056\n",
            "Train Epoch: 4850 \tLoss: 1.806940\n",
            "\n",
            "Test set: Avg. loss: 1.9040, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4855 \tLoss: 1.806825\n",
            "Train Epoch: 4860 \tLoss: 1.806710\n",
            "Train Epoch: 4865 \tLoss: 1.806594\n",
            "Train Epoch: 4870 \tLoss: 1.806479\n",
            "Train Epoch: 4875 \tLoss: 1.806364\n",
            "\n",
            "Test set: Avg. loss: 1.9035, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4880 \tLoss: 1.806249\n",
            "Train Epoch: 4885 \tLoss: 1.806135\n",
            "Train Epoch: 4890 \tLoss: 1.806020\n",
            "Train Epoch: 4895 \tLoss: 1.805906\n",
            "Train Epoch: 4900 \tLoss: 1.805791\n",
            "\n",
            "Test set: Avg. loss: 1.9031, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4905 \tLoss: 1.805677\n",
            "Train Epoch: 4910 \tLoss: 1.805563\n",
            "Train Epoch: 4915 \tLoss: 1.805449\n",
            "Train Epoch: 4920 \tLoss: 1.805335\n",
            "Train Epoch: 4925 \tLoss: 1.805222\n",
            "\n",
            "Test set: Avg. loss: 1.9027, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4930 \tLoss: 1.805108\n",
            "Train Epoch: 4935 \tLoss: 1.804995\n",
            "Train Epoch: 4940 \tLoss: 1.804881\n",
            "Train Epoch: 4945 \tLoss: 1.804768\n",
            "Train Epoch: 4950 \tLoss: 1.804655\n",
            "\n",
            "Test set: Avg. loss: 1.9023, Accuracy: 317/500 (63%)\n",
            "\n",
            "Train Epoch: 4955 \tLoss: 1.804542\n",
            "Train Epoch: 4960 \tLoss: 1.804428\n",
            "Train Epoch: 4965 \tLoss: 1.804316\n",
            "Train Epoch: 4970 \tLoss: 1.804203\n",
            "Train Epoch: 4975 \tLoss: 1.804090\n",
            "\n",
            "Test set: Avg. loss: 1.9019, Accuracy: 316/500 (63%)\n",
            "\n",
            "Train Epoch: 4980 \tLoss: 1.803978\n",
            "Train Epoch: 4985 \tLoss: 1.803866\n",
            "Train Epoch: 4990 \tLoss: 1.803754\n",
            "Train Epoch: 4995 \tLoss: 1.803641\n",
            "Train Epoch: 5000 \tLoss: 1.803530\n",
            "\n",
            "Test set: Avg. loss: 1.9015, Accuracy: 316/500 (63%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#train only conv2:\n",
        "network = Net()\n",
        "train_losses.clear()\n",
        "test_losses.clear()\n",
        "#count=[]\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
        "\n",
        "#freeze the other layers:\n",
        "network.fc2.weight.requires_grad=False\n",
        "network.fc2.bias.requires_grad=False\n",
        "\n",
        "network.fc1.weight.requires_grad=False\n",
        "network.fc1.bias.requires_grad=False\n",
        "\n",
        "network.conv1.weight.requires_grad=False\n",
        "network.conv1.bias.requires_grad=False\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, network.parameters()), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "\n",
        "# save the initial weights to measure later their contribution:\n",
        "fc1_init = network.fc1.weight.clone()\n",
        "fc2_init = network.fc2.weight.clone()\n",
        "conv1_init = network.conv1.weight.clone()\n",
        "conv2_init = network.conv2.weight.clone()\n",
        "\n",
        "#train\n",
        "test_n = 25\n",
        "test()\n",
        "count = []\n",
        "n_epochs=5000\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  if epoch % test_n == 0:\n",
        "    test()\n",
        "    count.append(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.arange(0,n_epochs)\n",
        "count = np.arange(0,n_epochs+test_n,test_n)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(x, train_losses, color='blue', zorder=1)\n",
        "plt.plot(count, test_losses, color='red', zorder=2)\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.xlabel('number of training examples seen')\n",
        "plt.ylabel('loss')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
